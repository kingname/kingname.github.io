<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Kingname</title>
  <subtitle>给时光以生命。</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.kingname.info/"/>
  <updated>2019-02-12T12:51:18.450Z</updated>
  <id>https://www.kingname.info/</id>
  
  <author>
    <name>Kingname</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>一行js代码识别Selenium+Webdriver及其应对方案</title>
    <link href="https://www.kingname.info/2019/02/12/hide-webdriver/"/>
    <id>https://www.kingname.info/2019/02/12/hide-webdriver/</id>
    <published>2019-02-12T07:11:14.000Z</published>
    <updated>2019-02-12T12:51:18.450Z</updated>
    
    <content type="html"><![CDATA[<p>有不少朋友在开发爬虫的过程中喜欢使用Selenium + Chromedriver，以为这样就能做到不被网站的反爬虫机制发现。</p>
<p>先不说淘宝这种基于用户行为的反爬虫策略，仅仅是一个普通的小网站，使用一行Javascript代码，就能轻轻松松识别你是否使用了Selenium + Chromedriver模拟浏览器。</p>
<p>我们来看一个例子。</p>
<a id="more"></a>
<p>使用下面这一段代码启动Chrome窗口：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> selenium.webdriver <span class="keyword">import</span> Chrome</div><div class="line"></div><div class="line">driver = Chrome()</div></pre></td></tr></table></figure>
<p>现在，在这个窗口中打开开发者工具，并定位到Console选项卡，如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/15499558287238.jpg" alt=""></p>
<p>现在，在这个窗口输入如下的js代码并按下回车键：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">window</span>.navigator.webdriver</div></pre></td></tr></table></figure>
<p>可以看到，开发者工具返回了<code>true</code>。如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/15499559010932.jpg" alt=""></p>
<p>但是，如果你打开一个普通的Chrome窗口，执行相同的命令，可以发现这行代码的返回值为<code>undefined</code>，如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/15499560533146.jpg" alt=""></p>
<p>所以，如果网站通过js代码获取这个参数，返回值为<code>undefined</code>说明是正常的浏览器，返回<code>true</code>说明用的是Selenium模拟浏览器。一抓一个准。这里给出一个检测Selenium的js代码例子：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">webdriver = <span class="built_in">window</span>.navigator.webdriver;</div><div class="line"><span class="keyword">if</span>(webdriver)&#123;</div><div class="line">	<span class="built_in">console</span>.log(<span class="string">'你这个傻逼你以为使用Selenium模拟浏览器就可以了？'</span>)</div><div class="line">&#125; <span class="keyword">else</span> &#123;</div><div class="line">	<span class="built_in">console</span>.log(<span class="string">'正常浏览器'</span>)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>网站只要在页面加载的时候运行这个js代码，就可以识别访问者是不是用的Selenium模拟浏览器。如果是，就禁止访问或者触发其他反爬虫的机制。</p>
<p>那么对于这种情况，在爬虫开发的过程中如何防止这个参数告诉网站你在模拟浏览器呢？</p>
<p>可能有一些会js的朋友觉得可以通过覆盖这个参数从而隐藏自己，但实际上这个值是不能被覆盖的：</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/15499566165239.jpg" alt=""></p>
<p>对js更精通的朋友，可能会使用下面这一段代码来实现：</p>
<figure class="highlight js"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">Object</span>.defineProperties(navigator, &#123;<span class="attr">webdriver</span>:&#123;<span class="attr">get</span>:<span class="function"><span class="params">()</span>=&gt;</span><span class="literal">undefined</span>&#125;&#125;);</div></pre></td></tr></table></figure>
<p>运行效果如下图所示：</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/15499575706517.jpg" alt=""></p>
<p>确实修改成功了。这种写法就万无一失了吗？并不是这样的，如果此时你在模拟浏览器中通过点击链接、输入网址进入另一个页面，或者开启新的窗口，你会发现，<code>window.navigator.webdriver</code>又变成了<code>true</code>。如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/15499577743175.jpg" alt=""></p>
<p>那么是不是可以在每一个页面都打开以后，再次通过webdriver执行上面的js代码，从而实现在每个页面都把<code>window.navigator.webdriver</code>设置为<code>undefined</code>呢？也不行。</p>
<p>因为当你执行：<code>driver.get(网址)</code>的时候，浏览器会打开网站，加载页面并运行网站自带的js代码。所以在你重设<code>window.navigator.webdriver</code>之前，实际上网站早就已经知道你是模拟浏览器了。</p>
<p>接下来，又有朋友提出，可以通过编写Chrome插件来解决这个问题，让插件里面的js代码在网站自带的所有js代码之前执行。</p>
<p>这样做当然可以，不过有更简单的办法，只需要设置Chromedriver的启动参数即可解决问题。</p>
<p>在启动Chromedriver之前，为Chrome开启实验性功能参数<code>excludeSwitches</code>，它的值为<code>[&#39;enable-automation&#39;]</code>，完整代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> selenium.webdriver <span class="keyword">import</span> Chrome</div><div class="line"><span class="keyword">from</span> selenium.webdriver <span class="keyword">import</span> ChromeOptions</div><div class="line"></div><div class="line">option = ChromeOptions()</div><div class="line">option.add_experimental_option(<span class="string">'excludeSwitches'</span>, [<span class="string">'enable-automation'</span>])</div><div class="line">driver = Chrome(options=option)</div></pre></td></tr></table></figure>
<p>此时启动的Chrome窗口，在右上角会弹出一个提示，不用管它，不要点击<code>停用</code>按钮。</p>
<p>再次在开发者工具的Console选项卡中查询<code>window.navigator.webdriver</code>，可以发现这个值已经自动变成<code>undefined</code>了。并且无论你打开新的网页，开启新的窗口还是点击链接进入其他页面，都不会让它变成<code>true</code>。运行效果如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/15499583523223.jpg" alt=""></p>
<p>截至2019年02月12日20:46分，本文所讲的方法可以用来登录知乎。如果使用 Selenium 直接登录知乎，会弹出验证码；先使用本文的方法再登录知乎，能够成功伪装成真实的浏览器，不会弹出验证码。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;有不少朋友在开发爬虫的过程中喜欢使用Selenium + Chromedriver，以为这样就能做到不被网站的反爬虫机制发现。&lt;/p&gt;
&lt;p&gt;先不说淘宝这种基于用户行为的反爬虫策略，仅仅是一个普通的小网站，使用一行Javascript代码，就能轻轻松松识别你是否使用了Selenium + Chromedriver模拟浏览器。&lt;/p&gt;
&lt;p&gt;我们来看一个例子。&lt;/p&gt;
    
    </summary>
    
      <category term="Python" scheme="https://www.kingname.info/categories/Python/"/>
    
    
      <category term="Python" scheme="https://www.kingname.info/tags/Python/"/>
    
      <category term="Selenium" scheme="https://www.kingname.info/tags/Selenium/"/>
    
      <category term="Chromedriver" scheme="https://www.kingname.info/tags/Chromedriver/"/>
    
  </entry>
  
  <entry>
    <title>在Python中，a += b并不总是等价于a = a + b</title>
    <link href="https://www.kingname.info/2019/01/29/iadd/"/>
    <id>https://www.kingname.info/2019/01/29/iadd/</id>
    <published>2019-01-29T13:19:55.000Z</published>
    <updated>2019-01-29T13:24:43.546Z</updated>
    
    <content type="html"><![CDATA[<p>大家经常在一些博客中看到这样的说法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">a += 1</div></pre></td></tr></table></figure>
<p>等价于</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">a = a + 1</div></pre></td></tr></table></figure>
<p>这种说法实际上并不准确。</p>
<p>我们来看一个例子：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; a = [1, 2, 3]</div><div class="line">&gt;&gt;&gt; a += (4,)</div><div class="line">&gt;&gt;&gt; a</div><div class="line">[1, 2, 3, 4]</div><div class="line"></div><div class="line">&gt;&gt;&gt; a = [1, 2, 3]</div><div class="line">&gt;&gt;&gt; a = a + (4,)</div><div class="line">Traceback (most recent call last):</div><div class="line">  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;</div><div class="line">TypeError: can only concatenate list (not &quot;tuple&quot;) to list</div></pre></td></tr></table></figure>
<p>这里报错了，说明<code>a += b</code>和<code>a = a + b</code>并不是完全等价的。</p>
<a id="more"></a>
<p>实际上，这是由于<code>+=</code>会首先调用左边这个对象的<code>__iadd__</code>方法，如果没有<code>__iadd__</code>方法，就会调用<code>__add__</code>方法。但是如果直接使用<code>+</code>号，就会直接调用<code>__add__</code>方法。而对于字符串、数字、浮点数这种不可变对象，他们没有<code>__iadd__</code>方法，所以对他们来说，<code>a += b</code> 与 <code>a = a + b</code>是等价的。</p>
<p>但是列表是一个可变的容器，它内部是有<code>__iadd__</code>这个方法。对于列表来说，它的<code>__iadd__</code>方法的原型如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">def __iadd__(self, values):</div><div class="line">    self.extend(values)</div><div class="line">    return self</div></pre></td></tr></table></figure>
<p>这一段代码你可以在这里看到：<a href="https://github.com/python/cpython/blob/1b5f9c9653f348b0aa8b7ca39f8a9361150f7dfc/Lib/_collections_abc.py" target="_blank" rel="external">https://github.com/python/cpython/blob/1b5f9c9653f348b0aa8b7ca39f8a9361150f7dfc/Lib/_collections_abc.py</a></p>
<p>所以说，当你使用<code>+=</code>连接列表和元组的时候，本质上是列表使用<code>extend</code>把元组的内容添加进去。这样是不会报错的：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>a = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>a.extend((<span class="number">4</span>,))</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>a</div><div class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;大家经常在一些博客中看到这样的说法：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;a += 1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;等价于&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;a = a + 1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;这种说法实际上并不准确。&lt;/p&gt;
&lt;p&gt;我们来看一个例子：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;&amp;gt;&amp;gt;&amp;gt; a = [1, 2, 3]&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;gt;&amp;gt;&amp;gt; a += (4,)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;gt;&amp;gt;&amp;gt; a&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[1, 2, 3, 4]&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;gt;&amp;gt;&amp;gt; a = [1, 2, 3]&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;gt;&amp;gt;&amp;gt; a = a + (4,)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;Traceback (most recent call last):&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;  File &amp;quot;&amp;lt;stdin&amp;gt;&amp;quot;, line 1, in &amp;lt;module&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;TypeError: can only concatenate list (not &amp;quot;tuple&amp;quot;) to list&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;这里报错了，说明&lt;code&gt;a += b&lt;/code&gt;和&lt;code&gt;a = a + b&lt;/code&gt;并不是完全等价的。&lt;/p&gt;
    
    </summary>
    
      <category term="Python" scheme="https://www.kingname.info/categories/Python/"/>
    
    
      <category term="Python" scheme="https://www.kingname.info/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>在Airtest中如何使用无线模式控制手机</title>
    <link href="https://www.kingname.info/2019/01/28/wireless-mode-of-poco/"/>
    <id>https://www.kingname.info/2019/01/28/wireless-mode-of-poco/</id>
    <published>2019-01-28T13:48:20.000Z</published>
    <updated>2019-01-28T14:08:30.839Z</updated>
    
    <content type="html"><![CDATA[<p>在<a href="https://www.kingname.info/2019/01/19/use-airtest/">使用Airtest超快速开发App爬虫</a>文章的最后，我们留了一个尾巴：如何启动Airtest的无线模式，不用USB线就能控制手机？</p>
<p>本文将会讲到具体的做法。做法分为两种：第一种是在Airtest的IDE中控制手机。第二种是在Python代码里面控制远程手机。</p>
<a id="more"></a>
<h2 id="启动开启手机上的adb端口"><a href="#启动开启手机上的adb端口" class="headerlink" title="启动开启手机上的adb端口"></a>启动开启手机上的adb端口</h2><p>无论使用哪种方式，要远程控制手机，就需要首先把手机上的adb端口打开。这一步必需先用USB线把手机连上电脑。</p>
<p>在终端里面执行命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">adb tcpip 48887</div></pre></td></tr></table></figure>
<p>其中的端口号48887你可以自行设定为其他的端口号，但不能和已有的端口冲突。</p>
<p>命令执行完成以后，你就可以拔下USB线了。接下来就是远程控制手机。</p>
<h2 id="在AirtestIDE中无线遥控手机"><a href="#在AirtestIDE中无线遥控手机" class="headerlink" title="在AirtestIDE中无线遥控手机"></a>在AirtestIDE中无线遥控手机</h2><p>打开Airtest，点击下图红框框住的 remote connection:</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2019-01-28-21-56-01.png" alt=""></p>
<p>在弹出来的输入框中，输入：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">adb connect 手机IP:端口</div></pre></td></tr></table></figure>
<p>其中手机的IP你可以在无线路由器中找到，也可以在手机的系统设置中找到。端口就是上一条命令设定的端口。</p>
<p>例如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">adb connect 192.168.0.102:48887</div></pre></td></tr></table></figure>
<p>如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2019-01-28-21-57-21.png" alt=""></p>
<p>点击<code>connect</code>，此时手机就会在上方的 Device列表中出现。双击它就可以无线连接手机并看到手机屏幕了。</p>
<h2 id="在Python中控制手机"><a href="#在Python中控制手机" class="headerlink" title="在Python中控制手机"></a>在Python中控制手机</h2><p>首先说明，Airtest的官方文档有问题，如果你跟着文档来写代码，一定会失败。</p>
<p>官方文档中，在<a href="https://airtest.readthedocs.io/zh_CN/latest/README_MORE.html#connect-android-device" target="_blank" rel="external">https://airtest.readthedocs.io/zh_CN/latest/README_MORE.html#connect-android-device</a>有一段介绍如何连接远程安卓手机的例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">本地设备</div><div class="line"><span class="comment"># connect a remote device using custom params</span></div><div class="line">connect_device(<span class="string">"android://adbhost:adbport/1234566?cap_method=javacap&amp;touch_method=adb"</span>)</div></pre></td></tr></table></figure>
<p>这个代码看起来，你可能会把Python代码写为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> airtest.core.api <span class="keyword">import</span> *</div><div class="line">device_1 = connect_device(<span class="string">'android://192.168.0.100:48887/手机串号?cap_method=javacap&amp;touch_method=adb'</span>)</div></pre></td></tr></table></figure>
<p>如果你这样写，<strong>你一定无法连上手机</strong>。</p>
<p>正确的代码为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">from airtest.core.api import *</div><div class="line"></div><div class="line">device_1 = connect_device(&apos;android:///192.168.0.100:48887?cap_method=javacap&amp;touch_method=adb&apos;)</div></pre></td></tr></table></figure>
<p>只有按我这里的写法才能正确控制手机。如下面的gif所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/correct_method_of_connect.gif" alt=""></p>
<p>动图中涉及到的完整代码为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> airtest.core.api <span class="keyword">import</span> *</div><div class="line"><span class="keyword">import</span> time</div><div class="line"><span class="keyword">from</span> poco.drivers.android.uiautomation <span class="keyword">import</span> AndroidUiautomationPoco</div><div class="line"></div><div class="line">device_1 = connect_device(<span class="string">'android:///192.168.0.100:48887?cap_method=javacap&amp;touch_method=adb'</span>)</div><div class="line"></div><div class="line">poco = AndroidUiautomationPoco(device_1, use_airtest_input=<span class="keyword">True</span>, screenshot_each_action=<span class="keyword">False</span>)</div><div class="line"></div><div class="line"></div><div class="line">poco(text=<span class="string">"知乎"</span>).click()</div><div class="line">poco(name=<span class="string">"com.zhihu.android:id/input"</span>).click()</div><div class="line">poco(name=<span class="string">"com.zhihu.android:id/input"</span>).set_text(<span class="string">'古剑奇谭三'</span>)</div><div class="line"></div><div class="line">time.sleep(<span class="number">2</span>)</div><div class="line"></div><div class="line"></div><div class="line">poco(name=<span class="string">'com.zhihu.android:id/magi_title'</span>, textMatches=<span class="string">'^古剑奇谭三.*$'</span>).click()</div><div class="line">poco.swipe([<span class="number">0.5</span>, <span class="number">0.8</span>], [<span class="number">0.5</span>, <span class="number">0.2</span>])</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在&lt;a href=&quot;https://www.kingname.info/2019/01/19/use-airtest/&quot;&gt;使用Airtest超快速开发App爬虫&lt;/a&gt;文章的最后，我们留了一个尾巴：如何启动Airtest的无线模式，不用USB线就能控制手机？&lt;/p&gt;
&lt;p&gt;本文将会讲到具体的做法。做法分为两种：第一种是在Airtest的IDE中控制手机。第二种是在Python代码里面控制远程手机。&lt;/p&gt;
    
    </summary>
    
      <category term="Python" scheme="https://www.kingname.info/categories/Python/"/>
    
    
      <category term="Python" scheme="https://www.kingname.info/tags/Python/"/>
    
      <category term="爬虫" scheme="https://www.kingname.info/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="Airtest" scheme="https://www.kingname.info/tags/Airtest/"/>
    
  </entry>
  
  <entry>
    <title>使用Airtest超快速开发App爬虫</title>
    <link href="https://www.kingname.info/2019/01/19/use-airtest/"/>
    <id>https://www.kingname.info/2019/01/19/use-airtest/</id>
    <published>2019-01-19T04:46:41.000Z</published>
    <updated>2019-01-19T12:04:42.140Z</updated>
    
    <content type="html"><![CDATA[<p>想开发网页爬虫，发现被反爬了？想对 App 抓包，发现数据被加密了？不要担心，使用 Airtest 开发 App 爬虫，只要人眼能看到，你就能抓到，最快只需要2分钟，兼容 Unity3D、Cocos2dx-*、Android 原生 App、iOS App、Windows Mobile……。</p>
<a id="more"></a>
<p>Airtest是网易开发的手机UI界面自动化测试工具，它原本的目的是通过所见即所得，截图点击等等功能，简化手机App图形界面测试代码编写工作。</p>
<p>爬虫开发本着天下工具为我所用，能让我获取数据的工具都能用来开发爬虫这一信念，决定使用Airtest来开发手机App爬虫。</p>
<h2 id="安装和使用"><a href="#安装和使用" class="headerlink" title="安装和使用"></a>安装和使用</h2><p>由于本文的目的是介绍如何使用Airtest来开发App爬虫，那么Airtest作为测试开发工具的方法介绍将会一带而过，仅仅说明如何安装并进行基本的操作。</p>
<h3 id="安装Airtest"><a href="#安装Airtest" class="headerlink" title="安装Airtest"></a>安装Airtest</h3><p>从Airtest官网：<a href="https://airtest.netease.com" target="_blank" rel="external">https://airtest.netease.com</a>下载Airtest，然后像安装普通软件一样安装即可。安装过程没有什么需要特别说明的地方。Airtest已经帮你打包好了开发需要的全部环境，所以安装完成Airtest以后就能够直接使用了。</p>
<p>Airtest运行以后的界面如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2019-01-19-13-10-30.png" alt=""></p>
<h3 id="连接手机"><a href="#连接手机" class="headerlink" title="连接手机"></a>连接手机</h3><p>以Android手机为例，由于Airtest会通过adb命令安装两个辅助App到手机上，再用adb命令通过控制这两个辅助App进而控制手机，因此首先需要确保手机的<code>adb调试</code>功能是打开的，并允许通过adb命令安装App到手机上。</p>
<p>启动Airtest以后，把Android手机连接到电脑上，点击下图方框中的<code>refresh ADB</code>：</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2019-01-19-13-16-45.png" alt=""></p>
<p>此时在Airtest界面右上角应该能够看到手机的信息，如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2019-01-19-13-17-51.png" alt=""></p>
<p>点击<code>connect</code>按钮，此时可以在界面上看到手机的界面，并且当你手动操作手机屏幕时，Airtest中的手机画面实时更新。如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2019-01-19-13-21-40.png" alt=""></p>
<p>对于某些手机，例如小米，在第一次使用Airtest时，请注意手机上将会弹出提示，询问你是否允许安装App，此时需要点击允许按钮。</p>
<h3 id="打开微信"><a href="#打开微信" class="headerlink" title="打开微信"></a>打开微信</h3><p>先通过一个简单的例子，来看看如何快速上手Airtest，稍后再来详解。</p>
<p>例如我现在想使用电脑控制手机，打开微信。</p>
<p>此时，点击下图中方框框住的<code>touch</code>按钮：</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2019-01-19-13-27-32.png" alt=""></p>
<p>此时，把鼠标移动到Airtest右边的手机屏幕区域，鼠标会变成十字型。在微信图标的左上角按下鼠标左键不放，并拖到微信右下角松开鼠标。此时请注意中间代码区域发生了什么变化，如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2019-01-19-13-30-15.png" alt=""></p>
<p>好了。以上就是你需要使用电脑打开微信所要进行的全部操作。</p>
<p>点击上方工具栏中的三角形图标，运行代码，如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2019-01-19-13-32-29.png" alt=""></p>
<p>代码运行完成以后，微信被打开了。</p>
<h3 id="界面介绍"><a href="#界面介绍" class="headerlink" title="界面介绍"></a>界面介绍</h3><p>在有了一个直观的使用以后，我们再来介绍一下Airtest的界面，将会更加有针对性。</p>
<p>Airtest的界面如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2019-01-19-14-04-37.png" alt=""></p>
<p>这里，我把Airtest分成了A-F6个区域，他们的功能如下：</p>
<ul>
<li>A区：常用操作功能区</li>
<li>B区：Python代码编写区</li>
<li>C区：运行日志区</li>
<li>D区：手机屏幕区</li>
<li>E区：App页面布局信息查看区</li>
<li>F区：工具栏</li>
</ul>
<p>A区是常用的<code>基于图像识别</code>的屏幕操作功能，例如：</p>
<ul>
<li><code>touch</code>: 点击屏幕元素</li>
<li><code>swipe</code>: 滑动屏幕</li>
<li><code>exists</code>: 判断屏幕元素是否存在</li>
<li><code>text</code>: 在输入框中输入文字</li>
<li><code>snashot</code>: 截图</li>
<li>……</li>
</ul>
<p>一般来说，是点击A区里面的某一个功能，然后在D区屏幕上进行框选操作，B区就会自动生成相应的操作代码。</p>
<p>B区用来显示和编写Python代码。在多数情况下，不需要手动写代码，因为代码会根据你在手机屏幕上面的操作自动生成。只有一些需要特别定制化的动作才需要修改代码。</p>
<p>D区显示了手机屏幕，当你操作手机真机时，这个屏幕会实时刷新。你也可以直接在D区屏幕上使用鼠标操作手机，你的操作动作会被自动在真机上执行。</p>
<p>F区是一些常用工具，从左到右，依次为：</p>
<ol>
<li>新建项目</li>
<li>打开项目</li>
<li>保存项目</li>
<li>运行代码</li>
<li>停止代码</li>
<li>查看运行报告</li>
</ol>
<p>其中1-5很好理解，那么什么是查看运行报告呢？</p>
<p>当你至少运行了一次以后，点击这个功能，会自动给你打开一个网页。网页如下图所示，这是你的代码的运行报告，详细到每一步操作了什么元素。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/launch_report.png" alt=""></p>
<p>通过截图功能操作手机虽然方便，但是截图涉及到分辨率的问题，代码不能在不同的手机上通用。所以对于A区的功能，做点简单操作即可，不用深入了解。</p>
<p>更高级的功能，需要通过E区实现。</p>
<h2 id="基于App布局信息操作手机"><a href="#基于App布局信息操作手机" class="headerlink" title="基于App布局信息操作手机"></a>基于App布局信息操作手机</h2><h3 id="初始化代码"><a href="#初始化代码" class="headerlink" title="初始化代码"></a>初始化代码</h3><p>App的布局信息就像网页的HTML一样，保存了App上面各个元素的相对位置和各个参数。对于一个App而言，在不同分辨率的手机上，可能相同的元素有着不同的坐标点，但是这个元素的属性参数一般是不会变的。因此，如果使用元素的属性参数来寻找并控制这个元素，就能实现在不同分辨率手机上的精确定位。</p>
<p>App的布局信息的格式与App的开发环境有关。点击F区的下拉菜单，可以看到这里能够指定不同的App开发环境。其中的<code>Unity</code>、<code>Cocos-*</code>等等一般是做游戏用的，<code>Android</code>是安卓原生App，<code>iOS</code>是苹果的App……如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2019-01-19-14-17-32.png" alt=""></p>
<p>以手机版知乎为例，由于它是Android原生的App，所以在F区下拉菜单选择<code>Android</code>，此时注意B区弹出提示，询问你是否要插入poco初始代码到当前输入光标的位置，点击<code>Yes</code>，如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2019-01-19-14-25-17.png" alt=""></p>
<p>此时，B区自动插入了一段代码，如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2019-01-19-14-27-11.png" alt=""></p>
<h3 id="定位并点击"><a href="#定位并点击" class="headerlink" title="定位并点击"></a>定位并点击</h3><p>现在，点击E区的锁形图标，如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2019-01-19-14-39-30.png" alt=""></p>
<p>锁形图标激活以后，你再操作D区的屏幕，点击<code>知乎</code>App下面的<code>知乎</code>两个字，会发现屏幕上被点击的App并不会打开。但E区和C区却发生了变化，如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2019-01-19-14-45-24.png" alt=""></p>
<p>其中E区显示的树状结构就是当前屏幕的布局信息，这与Chrome开发者工具里面显示的HTML结构如出一辙。C区显示的是当前被我点中的元素的信息。</p>
<p>请注意在这些元素信息中，有一个<code>text</code>属性，它的值为<code>知乎</code>。那么，这个属性就可以作为一个定位元素，于是可以在B区编写代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">poco(text=<span class="string">"知乎"</span>).click()</div></pre></td></tr></table></figure>
<p>写完代码以后运行程序，可以看到知乎App被打开了。如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2019-01-19-14-48-47.png" alt=""></p>
<blockquote>
<p>注意，如果你发现手机真机显示的界面与Airtest屏幕显示的手机界面不一致，可能是因为Airtest的屏幕被你锁定了。在F区点一下锁形图标，取消锁定，Airtest中的手机屏幕就会更新了。</p>
</blockquote>
<h3 id="定位并输入"><a href="#定位并输入" class="headerlink" title="定位并输入"></a>定位并输入</h3><p>打开知乎以后，我想使用知乎的搜索功能，那么继续，把锁形图标激活，然后点击知乎顶部的搜索框，如下图所示：</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2019-01-19-15-06-41.png" alt=""></p>
<p>继续看C区显示的搜索框属性，可以看到这里有一个<code>name</code>属性，它的值是<code>com.zhihu.android:id/input</code>，还有一个<code>text</code>属性，它的值为<code>蔡徐坤任 NBA 新春贺岁大使</code>。能不能像前面打开知乎一样，使用<code>text</code>这个属性呢？也行，也不行。说它行，是因为你这么做确实现在能工作；说它不行，因为这是知乎的热门搜索关键词，随时会改变。你今天使用这一句话成功了，明天热门关键词变化了，那么你的代码就无法使用了。所以此时需要使用<code>name</code>这个属性。</p>
<p>常见的基本上不会变化的属性包含但不限于：<code>name</code> <code>type</code> <code>resourceId</code> <code>package</code>。</p>
<p>另外还有一点，知乎首页的这个搜索框，实际上是不能输入内容的，当你点击以后，会跳转到另一个页面，如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2019-01-19-15-11-17.png" alt=""></p>
<p>因此你需要先点击一下这个输入框，跳转到真正的搜索界面：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">poco(name=&quot;com.zhihu.android:id/input&quot;).click()</div></pre></td></tr></table></figure>
<p>在真正的搜索界面如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2019-01-19-15-12-50.png" alt=""></p>
<p>可以看到，<code>name</code>属性的值依然是<code>com.zhihu.android:id/input</code>，此时就可以输入内容了。</p>
<p>输入内容使用的方法为<code>set_text</code>，用法为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">poco(name=<span class="string">"com.zhihu.android:id/input"</span>).set_text(<span class="string">'古剑奇谭三'</span>)</div></pre></td></tr></table></figure>
<h3 id="定位并筛选"><a href="#定位并筛选" class="headerlink" title="定位并筛选"></a>定位并筛选</h3><p>输入了搜索关键词以后，再来看看当前页面，搜索出现了三个结果：</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2019-01-19-15-17-58.png" alt=""></p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2019-01-19-15-18-36.png" alt=""></p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2019-01-19-15-19-14.png" alt=""></p>
<p>通过对比这三个结果的属性信息，发现他们的<code>name</code>属性都是相同的，而<code>text</code>不同。如果像下面这样写点击动作：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">poco(name=&apos;com.zhihu.android:id/magi_title&apos;).click()</div></pre></td></tr></table></figure>
<p>那么默认就会点击第一个搜索结果。</p>
<p>如果我想点击第二个搜索结果怎么办呢？可以这样写代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">poco(name=&apos;com.zhihu.android:id/magi_title&apos;, text=&apos;古剑奇谭（电视剧）&apos;).click()</div></pre></td></tr></table></figure>
<p>或者你也可以像列表一样使用索引定位：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">poco(name=<span class="string">'com.zhihu.android:id/magi_title'</span>)[<span class="number">1</span>].click()</div></pre></td></tr></table></figure>
<p>这两种写法的前提，都是我们已经知道了每个结果分别是什么。假设现在我就想搜索<code>古剑奇谭三</code>，但我不知道搜索结果是第几项，又应该怎么办呢？此时还可以使用正则表达式：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">poco(name=<span class="string">'com.zhihu.android:id/magi_title'</span>, textMatches=<span class="string">'^古剑奇谭三.*$'</span>).click()</div></pre></td></tr></table></figure>
<h3 id="滑动屏幕"><a href="#滑动屏幕" class="headerlink" title="滑动屏幕"></a>滑动屏幕</h3><p>进入搜索结果以后，需要查看下面的各种问题，此时就需要不断向上滑动屏幕。这里有一点需要特别注意，Airtest只能获取当前屏幕上的元素布局信息，不在屏幕上的内容是无法获取的。这一点和Selenium是不一样的。</p>
<p>滑动屏幕使用的命令为<code>swipe</code>，滑动屏幕需要使用坐标信息。但这种坐标和屏幕分辨率无关。这里的<code>坐标</code>定义为：(x, y)，其中x为横坐标，y为纵坐标。屏幕左上角为(0, 0)，屏幕右下角为(1, 1)，从左向右，横坐标从0逐渐增大到1，从上到下，纵坐标从0逐渐增大到1。</p>
<p>现在我要把屏幕向上滑动，那么在真机上面，我是先按住屏幕下方，然后把屏幕向上滑动，所以代码可以这样写：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"># poco.swipe(起点坐标，终点左边)</div><div class="line">poco.swipe([0.5, 0.8], [0.5, 0.2])</div></pre></td></tr></table></figure>
<p>方向示意图如下图所示：</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2019-01-19-15-42-43.png" alt=""></p>
<p>在一般情况下：</p>
<ul>
<li>向上滑动，只需要改动纵坐标，且起点值大于终点值</li>
<li>向下滑动，只需要改动纵坐标，且起点值小于终点值</li>
<li>向左滑动，只需要改动横坐标，且起点值大于终点值</li>
<li>向右滑动，只需要改动横坐标，且起点值小于终点值</li>
</ul>
<p>在爬虫开发中，涉及到的Airtest操作基本上已经介绍完毕。</p>
<h3 id="单独使用Python控制手机"><a href="#单独使用Python控制手机" class="headerlink" title="单独使用Python控制手机"></a>单独使用Python控制手机</h3><p>在Airtest操作手机虽然方便，但是不可能在每一台电脑上都安装Airtest吧。所以需要想办法把代码从Airtest这个程序中分离出来。</p>
<p>Airtest基于Python的一个开源库Poco开发，而在Airtest的B区写的Python代码，实际上就是Poco的代码。所以只要安装Poco库，就可以在Python中直接控制手机。</p>
<p>安装Poco库的命令为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pip install pocoui</div></pre></td></tr></table></figure>
<p>这个库依赖的东西有点多，安装稍稍慢一些。安装完成以后，我们把代码复制到PyCharm中，如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2019-01-19-16-59-52.png" alt=""></p>
<p>运行这段代码，如果是Linux或者macOS的用户，请注意看运行结果是不是有报错，提示adb没有运行权限。这是因为随Poco安装的adb没有运行权限，需要给它添加权限，在终端执行命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"># chmod +x 报错信息中给出的adb地址</div><div class="line"></div><div class="line">chmod +x /Users/kingname/.local/share/virtualenvs/ZhihuSpider/lib/python3.7/site-packages/airtest/core/android/static/adb/mac/adb(实际执行时请换成你的地址)</div></pre></td></tr></table></figure>
<p>命令运行完成以后再次执行代码，可以看到代码运行成功，手机被成功控制了，如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2019-01-19-17-00-50.png" alt=""></p>
<h3 id="如何获取屏幕文字"><a href="#如何获取屏幕文字" class="headerlink" title="如何获取屏幕文字"></a>如何获取屏幕文字</h3><p>由于Airtest的编辑器中的代码运行后无法正常打印出中文，因此后面的代码都直接在PyCharm中执行。</p>
<p>既然要做爬虫，就需要获取手机上的文字内容。回到搜索页面，我想知道“古剑奇谭”三这个关键字能搜索出多少条结果，每条结果有多少个讨论，如下图所示：</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2019-01-19-15-50-43.png" alt=""></p>
<p>此时我们需要做两件事情：</p>
<ol>
<li>分别查看每一个搜索结果</li>
<li>获取屏幕上的文字</li>
</ol>
<p>E区的树状结构如下图所示：</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2019-01-19-15-54-25.png" alt=""></p>
<p>每一个搜索结果的标题作为text属性的值，在<code>name=&#39;com.zhihu.android:id/magi_title&#39;</code>对应的元素中；每一个搜索结果的讨论数作为text属性的值，在<code>name=&#39;com.zhihu.android:id/magi_count&#39;</code>对应的元素中。</p>
<p>最直接的做法就是分别获取三个标题和三个讨论数，然后把它们合并在一起：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">title_obj_list = poco(name=<span class="string">'com.zhihu.android:id/magi_title'</span>)</div><div class="line">title_list = [title.get_text() <span class="keyword">for</span> title <span class="keyword">in</span> title_obj_list]</div><div class="line"></div><div class="line">discuss_obj_list = poco(name=<span class="string">'com.zhihu.android:id/magi_count'</span>)</div><div class="line">discuss_list = [discuss.get_text() <span class="keyword">for</span> discuss <span class="keyword">in</span> discuss_obj_list]</div><div class="line"></div><div class="line"><span class="keyword">for</span> title, discuss <span class="keyword">in</span> zip(title_list, discuss_list):</div><div class="line">    print(title, discuss)</div></pre></td></tr></table></figure>
<p>运行效果如下图所示：</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2019-01-19-17-05-27.png" alt=""></p>
<p>但是这种做法实际上是很危险的，假设会有某一个很生僻的搜索结果，只有标题没有讨论数，那么这样分开抓取再组合的做法，就会导致最后匹配错位。所以合理的做法是先抓大再抓小。每一组标题和讨论数，他们都有自己的父节点，如下图箭头所指向的三个<code>android.widget.LinearLayout</code>:</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2019-01-19-16-07-11.png" alt=""></p>
<p>那么现在，使用先抓大再抓小的技巧，先把每一组结果的父节点抓下来，再到每一个结果里面分别获取标题和讨论数。</p>
<p>然而这个父节点又怎么获取呢？如下图所示，这个父节点每一个属性值都没有什么特殊的，写任何一个都有可能与别的节点撞上。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2019-01-19-17-15-07.png" alt=""></p>
<p>此时，最简单的办法，就是在E区，双击父节点。定位代码就会自动添加，如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2019-01-19-17-16-51.png" alt=""></p>
<p>这个定位代码看起来非常复杂，但实际上它的内在逻辑非常简单，就是从顶层一层一层往下找而已。</p>
<p>自动生成的定位代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">poco(&quot;android.widget.LinearLayout&quot;).offspring(&quot;com.zhihu.android:id/action_bar_root&quot;).offspring(&quot;com.zhihu.android:id/parent_fragment_content_id&quot;).offspring(&quot;android.support.v7.widget.RecyclerView&quot;).child(&quot;android.widget.LinearLayout&quot;)[0]</div></pre></td></tr></table></figure>
<p>在这个自动生成的定位代码中，我们看到了<code>offspring</code>、<code>child</code>这两种方法。其中<code>child</code>代表子节点，<code>offspring</code>代表孙节点、孙节点的子节点、孙节点的孙节点……。简言之，使用<code>child</code>只会在子节点中搜索需要的内容，而使用<code>offspring</code>会像文件夹递归一样把里面的所有节点都遍历一次，直到找到符合条件的属性为止。显然，offspring速度会比child慢。</p>
<p>实际上，我们可以对这个定位代码做一些精简：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">poco(&quot;com.zhihu.android:id/parent_fragment_content_id&quot;).offspring(&quot;android.support.v7.widget.RecyclerView&quot;).child(&quot;android.widget.LinearLayout&quot;)[0]</div></pre></td></tr></table></figure>
<p>这个精简的方法，与从Chrome复制的XPath中进行精简是一样的逻辑，根本原则就是找到“独一无二”的属性值，然后用这个属性值来进行定位。</p>
<p>由于我点击的是第一个搜索结果，所以定位代码的最后有一个<code>[0]</code>。现在由于需要获得所有搜索结果的内容，所以应该去掉<code>[0]</code>而使用for循环展开，然后获取里面的内容：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">result_obj = poco(&quot;com.zhihu.android:id/parent_fragment_content_id&quot;).offspring(&quot;android.support.v7.widget.RecyclerView&quot;).child(&quot;android.widget.LinearLayout&quot;)</div><div class="line">for result in result_obj:</div><div class="line">    title = result.child(name=&apos;com.zhihu.android:id/magi_title&apos;).get_text()</div><div class="line">    count = result.child(name=&apos;com.zhihu.android:id/magi_count&apos;).get_text()</div><div class="line">    print(title, count)</div></pre></td></tr></table></figure>
<p>运行效果如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2019-01-19-17-30-30.png" alt=""></p>
<h2 id="控制多台手机"><a href="#控制多台手机" class="headerlink" title="控制多台手机"></a>控制多台手机</h2><p>当我们在电脑上插入多个Android手机时，执行命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">adb devices -l</div></pre></td></tr></table></figure>
<p>运行效果如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2019-01-19-17-37-16.png" alt=""></p>
<p>每个手机都会被列出来。在最左边的编号就是手机串号。使用这个串号可以指定多个手机：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">from airtest.core.api import auto_setup</div><div class="line">from airtest.core.android import Android</div><div class="line">from poco.drivers.android.uiautomation import AndroidUiautomationPoco</div><div class="line">auto_setup(__file__)</div><div class="line"></div><div class="line">device_1 = Android(&apos;76efadf3a7ce4&apos;)</div><div class="line">device_2 = Android(&apos;adfasdfasf23&apos;)</div><div class="line">device_3 = Android(&apos;adifu39ernla&apos;)</div><div class="line"></div><div class="line">poco_1 = AndroidUiautomationPoco(device_1, use_airtest_input=True, screenshot_each_action=False)</div><div class="line">poco_2 = AndroidUiautomationPoco(device_2, use_airtest_input=True, screenshot_each_action=False)</div><div class="line">poco_3 = AndroidUiautomationPoco(device_3, use_airtest_input=True, screenshot_each_action=False)</div></pre></td></tr></table></figure>
<p>通过这种方式，在一台电脑上使用USBHub，连上二三十台手机是完全没有问题的。</p>
<h2 id="无线模式"><a href="#无线模式" class="headerlink" title="无线模式"></a>无线模式</h2><p>Airtest支持无线模式，不需要USB，只要电脑和手机连接同一个WIFI就能控制：</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/wireless_control.gif" alt=""></p>
<p>如果大家对如何开启无线模式有兴趣，请留言，我就会继续写。</p>
<h2 id="搭建手机爬虫集群"><a href="#搭建手机爬虫集群" class="headerlink" title="搭建手机爬虫集群"></a>搭建手机爬虫集群</h2><p>一台电脑可以连接三十台手机，那么如果有很多电脑和很多手机，就可以实现手机爬虫集群，其运行效果如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2019-01-19-17-44-57.png" alt=""></p>
<p>关于如何搭建爬虫集群，已经超出本文的范围了。如果大家有兴趣，可以阅读我的书：<a href="https://item.jd.com/12436581.html?dist=jd" target="_blank" rel="external">Python爬虫开发 从入门到实战</a>第十章对于如何搭建手机爬虫集群有详细的说明和注意事项。</p>
<p>如果对我的书有兴趣，请关注我的微信公众号与我交流。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;想开发网页爬虫，发现被反爬了？想对 App 抓包，发现数据被加密了？不要担心，使用 Airtest 开发 App 爬虫，只要人眼能看到，你就能抓到，最快只需要2分钟，兼容 Unity3D、Cocos2dx-*、Android 原生 App、iOS App、Windows Mobile……。&lt;/p&gt;
    
    </summary>
    
      <category term="Airtest" scheme="https://www.kingname.info/categories/Airtest/"/>
    
    
      <category term="爬虫" scheme="https://www.kingname.info/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="Airtest" scheme="https://www.kingname.info/tags/Airtest/"/>
    
  </entry>
  
  <entry>
    <title>为什么Python中“2 == 2 &gt; 1”结果为True？</title>
    <link href="https://www.kingname.info/2019/01/10/chained-comparisons/"/>
    <id>https://www.kingname.info/2019/01/10/chained-comparisons/</id>
    <published>2019-01-10T14:00:04.000Z</published>
    <updated>2019-01-10T14:16:01.668Z</updated>
    
    <content type="html"><![CDATA[<p>在Python中，你可能会发现这样一个奇怪的现象：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">2</span> == <span class="number">2</span> &gt; <span class="number">1</span></div><div class="line"><span class="keyword">True</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>(<span class="number">2</span> == <span class="number">2</span>) &gt; <span class="number">1</span></div><div class="line"><span class="keyword">False</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">2</span> == (<span class="number">2</span> &gt; <span class="number">1</span>)</div><div class="line"><span class="keyword">False</span></div></pre></td></tr></table></figure>
<p>为什么会出现<code>2 == 2 &gt; 1</code>的结果为<code>True</code>？如果说这是运算符的优先级问题，那么后两个式子为什么又都是<code>False</code>？</p>
<p>实际上这涉及到了Python的<code>链式对比(Chained Comparisons)</code>。在其他语言中，有一个变量<code>x</code>，如果要判断x是否大于1，小于5，可能需要这样写代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">if (1 &lt; x and x &lt; 5)</div></pre></td></tr></table></figure>
<p>但是在Python中，可以这样写代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> <span class="number">1</span> &lt; x &lt; <span class="number">5</span></div></pre></td></tr></table></figure>
<p>Python能够正确处理这个链式对比的逻辑。</p>
<p>回到最开始的问题上，<code>==</code>等于符号和<code>&lt;</code>小于符号，本质没有什么区别。所以实际上<code>2==2&gt;1</code>也是一个链式对比的式子，它相当于<code>2==2 and 2&gt;1</code>。此时，这个式子就等价于<code>True and True</code>。所以返回的结果为True。</p>
<p>关于链式对比，可以看官方文档：<a href="https://docs.python.org/3/reference/expressions.html#comparisons" target="_blank" rel="external">https://docs.python.org/3/reference/expressions.html#comparisons</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在Python中，你可能会发现这样一个奇怪的现象：&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;li
    
    </summary>
    
      <category term="Python" scheme="https://www.kingname.info/categories/Python/"/>
    
    
      <category term="Python" scheme="https://www.kingname.info/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>2018 年终总结</title>
    <link href="https://www.kingname.info/2018/12/29/summary-2018/"/>
    <id>https://www.kingname.info/2018/12/29/summary-2018/</id>
    <published>2018-12-29T12:58:03.000Z</published>
    <updated>2019-01-01T06:11:49.461Z</updated>
    
    <content type="html"><![CDATA[<p>2018年，我的第一本书出版了。</p>
<p><img src="http://file.ryjiaoyu.com/SmallCover/18087823f4f8ed9ea435" alt=""></p>
<p>离开北京，来到到杭州，加入了网易游戏伏羲人工智能实验室。</p>
<p>在这一年里面，一共看完了21本书：</p>
<ul>
<li>罗贯中——《三国演义》</li>
<li>王小波——《黄金时代》</li>
<li>当年明月——《明朝那些事儿1-7》</li>
<li>瑞·达利欧《原则》</li>
<li>毛姆《月亮与六便士》</li>
<li>Robert C. Martin——《代码整洁之道》</li>
<li>John Sonmez——《软技能——代码之外的生成之道》</li>
<li>尤瓦尔·赫拉利——《今日简史》</li>
<li>汪曾祺——《生活是很好玩的》</li>
<li>孙武——《孙子兵法》</li>
<li>？？？——《战国策》</li>
<li>李鑫——《数据产品经理——从零经验到令人经验》</li>
<li>Norman Lewis——《Word Power Made Easy》</li>
<li>刘飞——《从点子到产品 : 产品经理的价值观与方法论》</li>
<li>李诞——《笑场》</li>
</ul>
<p>在LeetCode刷了九十多题：<a href="https://github.com/kingname/LeetCode" target="_blank" rel="external">https://github.com/kingname/LeetCode</a></p>
<p>写了13篇博客。</p>
<p>2019年1月，我的第二本书即将出版。</p>
<p>2019年新年目标：</p>
<ul>
<li>在2019-12-31之前，读完12本书，并为每一本书作出思维导图。</li>
<li>在2019-12-31之前，微信公众号的关注量超过5000人。</li>
<li>在2019-06-30之前，在Medium上发布3篇技术文章。</li>
<li>在2019-10-31之前，练习英语听力和复述能力，做到150词内的句子，听一次就能复述成功。</li>
<li>在2019-03-31之前，学会布鲁斯口琴吹气压音，8月31日之前脱稿演奏卡农。12月31日脱稿演奏未闻花名。</li>
<li>在2019-07-31之前，使用golang完成一个记单词的网站。</li>
<li>在2019-09-30之前，认识至少5个新朋友，并通过与他们聊天练习聊天技巧，努力成为一个会聊天的人。</li>
<li>在2019-10-01之前，累计跑步108公里。</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;2018年，我的第一本书出版了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://file.ryjiaoyu.com/SmallCover/18087823f4f8ed9ea435&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;离开北京，来到到杭州，加入了网易游戏伏羲人工智能实验室。&lt;/
    
    </summary>
    
      <category term="总结" scheme="https://www.kingname.info/categories/%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="总结" scheme="https://www.kingname.info/tags/%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>项目经理必备——使用燃尽图监控项目整体进度</title>
    <link href="https://www.kingname.info/2018/12/23/use-burndown-chart/"/>
    <id>https://www.kingname.info/2018/12/23/use-burndown-chart/</id>
    <published>2018-12-23T09:11:13.000Z</published>
    <updated>2018-12-23T10:40:25.409Z</updated>
    
    <content type="html"><![CDATA[<p>在<a href="https://www.kingname.info/2018/10/17/use-gantt-enhanced/">《跳出任务管理的泥沼，拥抱甘特图的怀抱》</a>一文中，我谈到了使用甘特图来规划任务。甘特图更多的关注每一个任务的进度上。那么如果我希望了解项目整体的进度，应该如何选择呢？此时就需要引入另一个简单又强大的工具：燃尽图（Burn down chart）。</p>
<a id="more"></a>
<h2 id="什么是燃尽图"><a href="#什么是燃尽图" class="headerlink" title="什么是燃尽图"></a>什么是燃尽图</h2><p>假设项目X有5个任务，我们在预估这些任务的时候，时间安排如下：</p>
<table>
<thead>
<tr>
<th>项目名称</th>
<th>预计用时（小时）</th>
</tr>
</thead>
<tbody>
<tr>
<td>任务1</td>
<td>5</td>
</tr>
<tr>
<td>任务2</td>
<td>6</td>
</tr>
<tr>
<td>任务3</td>
<td>7</td>
</tr>
<tr>
<td>任务4</td>
<td>4</td>
</tr>
<tr>
<td>任务5</td>
<td>3</td>
</tr>
</tbody>
</table>
<p>这个任务预计需要25小时完成，考虑到可能需要处理各种突发事件留出机动时间，因此，我需要在7天内完成这个项目，项目时间定为：2018-12-01到2018-12-07。</p>
<p>在非常理想的情况下，平均分配工作时间，到2018-12-07这一个公作日结束时刚刚好完成任务。此时的时间消耗，绘制为折线图如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-12-23-17-25-21.png" alt=""></p>
<p>纵坐标为任务剩余时间，横坐标为日期，</p>
<p>然而，在实际情况中，可能有些任务能提前完成，有些任务时间又需要延迟，实际上的剩余时间和日期的折线图可能如下图橙色曲线所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-12-23-17-28-33.png" alt=""></p>
<p>这就是<code>燃尽图</code>。非常简单又非常直观。</p>
<p>从这一幅燃尽图中，我们可以看到：在2018-12-01到2018-12-05时，我们的开发进度是领先于计划的，看起来任务应该能够提前完成，橙色曲线斜率负得越多，越陡，表示实际开发进度领先得越多。然而从2018-12-03开始，开发速度下降，到2018-12-06时进度和预期时间重合。到2018-12-07，开发进度落后于预期，任务无法如期完成。</p>
<p>我们再来看几个例子：</p>
<ul>
<li>按时完成任务：</li>
</ul>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-12-23-17-34-27.png" alt="按时完成任务"></p>
<ul>
<li>提前完成任务</li>
</ul>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-12-23-17-37-05.png" alt="提前完成任务"></p>
<ul>
<li>没有完成任务</li>
</ul>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-12-23-17-38-53.png" alt="没有完成任务"></p>
<ul>
<li>前期落后进度，后期加速赶上</li>
</ul>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-12-23-17-40-23.png" alt="前期落后进度，后期加速赶上"></p>
<h2 id="如何绘制燃尽图"><a href="#如何绘制燃尽图" class="headerlink" title="如何绘制燃尽图"></a>如何绘制燃尽图</h2><p>燃尽图是敏捷开发中的一个概念，不少敏捷开发的相关的项目管理系统中都能够生成燃尽图。由于燃尽图非常简单，使用Excel自带的画图功能，稍稍费一些功夫也能够正常生成。</p>
<p>本着使用Python提高日常办公效率的考虑，我使用macOS自带的numbers表格工具 + Python来生成燃尽图。当然你也可以使用Excel来完成。其中表格用于记录任务的剩余时间，Python用于格式化任务时间并生成燃尽图。</p>
<h3 id="表格的填写规范"><a href="#表格的填写规范" class="headerlink" title="表格的填写规范"></a>表格的填写规范</h3><p>其中表格如下图所示：</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-12-23-17-47-16.png" alt=""></p>
<p>其中，表格的第一行是任务名称，第一列是日期。表格中间填写的数字，表示任务的剩余时间。表格的填写规则如下：</p>
<ul>
<li>某一格留空，表示这一天没有做这个任务。</li>
<li>某一格为0，表示任务完成。</li>
<li>某一格为大于0的数字，表示任务剩余的时间。</li>
<li>不需要提前填写没有发生的日期。例如任务安排为2018-12-01到2018-12-07，今天是2018-12-06，那么不需要提前填写2018-12-07这一行。</li>
<li>请按照日期正序排序，不要打乱日期。</li>
</ul>
<h3 id="分析程序的使用说明"><a href="#分析程序的使用说明" class="headerlink" title="分析程序的使用说明"></a>分析程序的使用说明</h3><p>填写好表格以后，把它保存为excel的xlsx文件。假设路径为：<code>/Users/kingname/Desktop/test.xlsx</code>（或者Windows系统保存在：<code>D:\work\test.xlsx</code>）。</p>
<p>使用Anaconda中的Jupyter打开分析程序的ipynb文件，如下图所示：</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-12-23-17-58-02.png" alt=""></p>
<p>只需要修改这三行数据中，单引号里面的内容，其余内容不需要修改。</p>
<p>修改完成以后，点击工具栏的<code>Kernel-Restart &amp; Run All</code>，如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-12-23-17-59-36.png" alt=""></p>
<p>静静等待2秒钟，燃尽图将会出现在页面的最下方。如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-12-23-18-03-04.png" alt=""></p>
<h2 id="获取Excel模板和源代码"><a href="#获取Excel模板和源代码" class="headerlink" title="获取Excel模板和源代码"></a>获取Excel模板和源代码</h2><p>Excel与ipynb文件地址：<a href="https://github.com/kingname/Automatic/tree/master/burndown_chart" target="_blank" rel="external">https://github.com/kingname/Automatic/tree/master/burndown_chart</a></p>
<p>使用Jupyter打开ipynb文件可以看到分析程序。</p>
<h2 id="附言"><a href="#附言" class="headerlink" title="附言"></a>附言</h2><p>如果你不知道Jupyter是什么，或者你没有任何编程基础，但是想尝试一些燃尽图，那么你可以添加我的公众号联系我，我会告诉你如何使用Jupyter。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在&lt;a href=&quot;https://www.kingname.info/2018/10/17/use-gantt-enhanced/&quot;&gt;《跳出任务管理的泥沼，拥抱甘特图的怀抱》&lt;/a&gt;一文中，我谈到了使用甘特图来规划任务。甘特图更多的关注每一个任务的进度上。那么如果我希望了解项目整体的进度，应该如何选择呢？此时就需要引入另一个简单又强大的工具：燃尽图（Burn down chart）。&lt;/p&gt;
    
    </summary>
    
      <category term="项目管理" scheme="https://www.kingname.info/categories/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/"/>
    
    
      <category term="Python" scheme="https://www.kingname.info/tags/Python/"/>
    
      <category term="燃尽图" scheme="https://www.kingname.info/tags/%E7%87%83%E5%B0%BD%E5%9B%BE/"/>
    
      <category term="Scrum" scheme="https://www.kingname.info/tags/Scrum/"/>
    
  </entry>
  
  <entry>
    <title>彻底搞懂Scrapy的中间件（三）</title>
    <link href="https://www.kingname.info/2018/11/20/know-middleware-of-scrapy-3/"/>
    <id>https://www.kingname.info/2018/11/20/know-middleware-of-scrapy-3/</id>
    <published>2018-11-20T14:46:17.000Z</published>
    <updated>2018-11-20T15:15:31.071Z</updated>
    
    <content type="html"><![CDATA[<p>在前面两篇文章介绍了下载器中间件的使用，这篇文章将会介绍爬虫中间件（Spider Middleware）的使用。</p>
<a id="more"></a>
<h2 id="爬虫中间件"><a href="#爬虫中间件" class="headerlink" title="爬虫中间件"></a>爬虫中间件</h2><p>爬虫中间件的用法与下载器中间件非常相似，只是它们的作用对象不同。下载器中间件的作用对象是请求request和返回response；爬虫中间件的作用对象是爬虫，更具体地来说，就是写在spiders文件夹下面的各个文件。它们的关系，在Scrapy的数据流图上可以很好地区分开来，如下图所示。</p>
<p> <img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-11-20-22-49-17.png" alt=""></p>
<p>其中，4、5表示下载器中间件，6、7表示爬虫中间件。爬虫中间件会在以下几种情况被调用。</p>
<ol>
<li>当运行到<code>yield scrapy.Request()</code>或者<code>yield item</code>的时候，爬虫中间件的<code>process_spider_output()</code>方法被调用。</li>
<li>当爬虫本身的代码出现了<code>Exception</code>的时候，爬虫中间件的<code>process_spider_exception()</code>方法被调用。</li>
<li>当爬虫里面的某一个回调函数<code>parse_xxx()</code>被调用之前，爬虫中间件的<code>process_spider_input()</code>方法被调用。</li>
<li>当运行到<code>start_requests()</code>的时候，爬虫中间件的<code>process_start_requests()</code>方法被调用。</li>
</ol>
<h3 id="在中间件处理爬虫本身的异常"><a href="#在中间件处理爬虫本身的异常" class="headerlink" title="在中间件处理爬虫本身的异常"></a>在中间件处理爬虫本身的异常</h3><p>在爬虫中间件里面可以处理爬虫本身的异常。例如编写一个爬虫，爬取UA练习页面<a href="http://exercise.kingname.info/exercise_middleware_ua" target="_blank" rel="external">http://exercise.kingname.info/exercise_middleware_ua</a> ，故意在爬虫中制造一个异常，如图12-26所示。</p>
<p> <img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-11-20-22-51-03.png" alt=""></p>
<p>由于网站返回的只是一段普通的字符串，并不是JSON格式的字符串，因此使用JSON去解析，就一定会导致报错。这种报错和下载器中间件里面遇到的报错不一样。下载器中间件里面的报错一般是由于外部原因引起的，和代码层面无关。而现在的这种报错是由于代码本身的问题导致的，是代码写得不够周全引起的。</p>
<p>为了解决这个问题，除了仔细检查代码、考虑各种情况外，还可以通过开发爬虫中间件来跳过或者处理这种报错。在middlewares.py中编写一个类：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">ExceptionCheckSpider</span><span class="params">(object)</span>:</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_spider_exception</span><span class="params">(self, response, exception, spider)</span>:</span></div><div class="line">        print(f<span class="string">'返回的内容是：&#123;response.body.decode()&#125;\n报错原因：&#123;type(exception)&#125;'</span>)</div><div class="line">        <span class="keyword">return</span> <span class="keyword">None</span></div></pre></td></tr></table></figure>
<p>这个类仅仅起到记录Log的作用。在使用JSON解析网站返回内容出错的时候，将网站返回的内容打印出来。</p>
<p><code>process_spider_exception()</code>这个方法，它可以返回<code>None</code>，也可以运行<code>yield item</code>语句或者像爬虫的代码一样，使用<code>yield scrapy.Request()</code>发起新的请求。如果运行了<code>yield item</code>或者<code>yield scrapy.Request()</code>，程序就会绕过爬虫里面原有的代码。</p>
<p>例如，对于有异常的请求，不需要进行重试，但是需要记录是哪一个请求出现了异常，此时就可以在爬虫中间件里面检测异常，然后生成一个只包含标记的item。还是以抓取<a href="http://exercise.kingname.info/exercise_middleware_retry.html" target="_blank" rel="external">http://exercise.kingname.info/exercise_middleware_retry.html</a>这个练习页的内容为例，但是这一次不进行重试，只记录哪一页出现了问题。先看爬虫的代码，这一次在meta中把页数带上，如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-11-20-22-53-02.png" alt=""></p>
<p>爬虫里面如果发现了参数错误，就使用raise这个关键字人工抛出一个自定义的异常。在实际爬虫开发中，读者也可以在某些地方故意不使用try … except捕获异常，而是让异常直接抛出。例如XPath匹配处理的结果，直接读里面的值，不用先判断列表是否为空。这样如果列表为空，就会被抛出一个IndexError，于是就能让爬虫的流程进入到爬虫中间件的<code>process_spider_exception()</code>中。</p>
<p>在items.py里面创建了一个ErrorItem来记录哪一页出现了问题，如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-11-20-22-53-45.png" alt=""></p>
<p>接下来，在爬虫中间件中将出错的页面和当前时间存放到ErrorItem里面，并提交给pipeline，保存到MongoDB中，如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-11-20-22-54-41.png" alt=""></p>
<p>这样就实现了记录错误页数的功能，方便在后面对错误原因进行分析。由于这里会把item提交给pipeline，所以不要忘记在settings.py里面打开pipeline，并配置好MongoDB。储存错误页数到MongoDB的代码如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-11-20-22-55-43.png" alt=""></p>
<h3 id="激活爬虫中间件"><a href="#激活爬虫中间件" class="headerlink" title="激活爬虫中间件"></a>激活爬虫中间件</h3><p>爬虫中间件的激活方式与下载器中间件非常相似，在settings.py中，在下载器中间件配置项的上面就是爬虫中间件的配置项，它默认也是被注释了的，解除注释，并把自定义的爬虫中间件添加进去即可，如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-11-20-22-56-15.png" alt=""></p>
<p>Scrapy也有几个自带的爬虫中间件，它们的名字和顺序如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-11-20-22-57-03.png" alt=""></p>
<p>下载器中间件的数字越小越接近Scrapy引擎，数字越大越接近爬虫。如果不能确定自己的自定义中间件应该靠近哪个方向，那么就在500～700之间选择最为妥当。</p>
<h3 id="爬虫中间件输入-输出"><a href="#爬虫中间件输入-输出" class="headerlink" title="爬虫中间件输入/输出"></a>爬虫中间件输入/输出</h3><p>在爬虫中间件里面还有两个不太常用的方法，分别为<code>process_spider_input(response, spider)</code>和<code>process_spider_output(response, result, spider)</code>。其中，<code>process_spider_input(response, spider)</code>在下载器中间件处理完成后，马上要进入某个回调函数parse_xxx()前调用。<code>process_spider_output(response, result, output)</code>是在爬虫运行<code>yield item</code>或者<code>yield scrapy.Request()</code>的时候调用。在这个方法处理完成以后，数据如果是item，就会被交给pipeline；如果是请求，就会被交给调度器，然后下载器中间件才会开始运行。所以在这个方法里面可以进一步对item或者请求做一些修改。这个方法的参数result就是爬虫爬出来的item或者<code>scrapy.Request()</code>。由于yield得到的是一个生成器，生成器是可以迭代的，所以result也是可以迭代的，可以使用for循环来把它展开。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_spider_output</span><span class="params">(response, result, spider)</span>:</span></div><div class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> result:</div><div class="line">        <span class="keyword">if</span> isinstance(item, scrapy.Item):</div><div class="line">            <span class="comment"># 这里可以对即将被提交给pipeline的item进行各种操作</span></div><div class="line">            print(f<span class="string">'item将会被提交给pipeline'</span>)</div><div class="line">        <span class="keyword">yield</span> item</div></pre></td></tr></table></figure>
<p>或者对请求进行监控和修改：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_spider_output</span><span class="params">(response, result, spider)</span>:</span></div><div class="line">    <span class="keyword">for</span> request <span class="keyword">in</span> result:</div><div class="line">        <span class="keyword">if</span> <span class="keyword">not</span> isinstance(request, scrapy.Item):</div><div class="line">            <span class="comment"># 这里可以对请求进行各种修改</span></div><div class="line">            print(<span class="string">'现在还可以对请求对象进行修改。。。。'</span>)</div><div class="line">        request.meta[<span class="string">'request_start_time'</span>] = time.time()</div><div class="line">        <span class="keyword">yield</span> request</div></pre></td></tr></table></figure>
<blockquote>
<p>本文节选自我的新书《Python爬虫开发  从入门到实战》完整目录可以在京东查询到 <a href="https://item.jd.com/12436581.html" target="_blank" rel="external">https://item.jd.com/12436581.html</a></p>
</blockquote>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在前面两篇文章介绍了下载器中间件的使用，这篇文章将会介绍爬虫中间件（Spider Middleware）的使用。&lt;/p&gt;
    
    </summary>
    
      <category term="Python" scheme="https://www.kingname.info/categories/Python/"/>
    
    
      <category term="Python" scheme="https://www.kingname.info/tags/Python/"/>
    
      <category term="爬虫" scheme="https://www.kingname.info/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="Scrapy" scheme="https://www.kingname.info/tags/Scrapy/"/>
    
  </entry>
  
  <entry>
    <title>彻底搞懂Scrapy的中间件（二）</title>
    <link href="https://www.kingname.info/2018/11/18/know-middleware-of-scrapy-2/"/>
    <id>https://www.kingname.info/2018/11/18/know-middleware-of-scrapy-2/</id>
    <published>2018-11-18T15:41:24.000Z</published>
    <updated>2018-11-18T16:11:56.205Z</updated>
    
    <content type="html"><![CDATA[<p>在上一篇文章中介绍了下载器中间件的一些简单应用，现在再来通过案例说说如何使用下载器中间件集成Selenium、重试和处理请求异常。</p>
<a id="more"></a>
<h2 id="在中间件中集成Selenium"><a href="#在中间件中集成Selenium" class="headerlink" title="在中间件中集成Selenium"></a>在中间件中集成Selenium</h2><p>对于一些很麻烦的异步加载页面，手动寻找它的后台API代价可能太大。这种情况下可以使用Selenium和ChromeDriver或者Selenium和PhantomJS来实现渲染网页。</p>
<p>这是前面的章节已经讲到的内容。那么，如何把Scrapy与Selenium结合起来呢？这个时候又要用到中间件了。</p>
<p>创建一个SeleniumMiddleware，其代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> scrapy.http <span class="keyword">import</span> HtmlResponse</div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">SeleniumMiddleware</span><span class="params">(object)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></div><div class="line">        self.driver = webdriver.Chrome(<span class="string">'./chromedriver'</span>)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_request</span><span class="params">(self, request, spider)</span>:</span></div><div class="line">        <span class="keyword">if</span> spider.name == <span class="string">'seleniumSpider'</span>:</div><div class="line">            self.driver.get(request.url)</div><div class="line">            time.sleep(<span class="number">2</span>)</div><div class="line">            body = self.driver.page_source</div><div class="line">        <span class="keyword">return</span> HtmlResponse(self.driver.current_url,</div><div class="line">                           body=body,</div><div class="line">                           encoding=<span class="string">'utf-8'</span>,</div><div class="line">                           request=request)</div></pre></td></tr></table></figure>
<p>这个中间件的作用，就是对名为“seleniumSpider”的爬虫请求的网址，使用ChromeDriver先进行渲染，然后用返回的渲染后的HTML代码构造一个Response对象。如果是其他的爬虫，就什么都不做。在上面的代码中，等待页面渲染完成是通过time.sleep(2)来实现的，当然读者也可以使用前面章节讲到的等待某个元素出现的方法来实现。</p>
<p>有了这个中间件以后，就可以像访问普通网页那样直接处理需要异步加载的页面，如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-11-18-23-52-26.png" alt=""></p>
<h2 id="在中间件里重试"><a href="#在中间件里重试" class="headerlink" title="在中间件里重试"></a>在中间件里重试</h2><p>在爬虫的运行过程中，可能会因为网络问题或者是网站反爬虫机制生效等原因，导致一些请求失败。在某些情况下，少量的数据丢失是无关紧要的，例如在几亿次请求里面失败了十几次，损失微乎其微，没有必要重试。但还有一些情况，每一条请求都至关重要，容不得有一次失败。此时就需要使用中间件来进行重试。</p>
<p>有的网站的反爬虫机制被触发了，它会自动将请求重定向到一个<code>xxx/404.html</code>页面。那么如果发现了这种自动的重定向，就没有必要让这一次的请求返回的内容进入数据提取的逻辑，而应该直接丢掉或者重试。</p>
<p>还有一种情况，某网站的请求参数里面有一项，Key为date，Value为发起请求的这一天的日期或者发起请求的这一天的前一天的日期。例如今天是“2017-08-10”，但是这个参数的值是今天早上10点之前，都必须使用“2017-08-09”，在10点之后才能使用“2017-08-10”，否则，网站就不会返回正确的结果，而是返回“参数错误”这4个字。然而，这个日期切换的时间点受到其他参数的影响，有可能第1个请求使用“2017-08-10”可以成功访问，而第2个请求却只有使用“2017-08-09”才能访问。遇到这种情况，与其花费大量的时间和精力去追踪时间切换点的变化规律，不如简单粗暴，直接先用今天去试，再用昨天的日期去试，反正最多两次，总有一个是正确的。</p>
<p>以上的两种场景，使用重试中间件都能轻松搞定。</p>
<p>打开练习页面</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">http://exercise.kingname.info/exercise_middleware_retry.html。</div></pre></td></tr></table></figure>
<p>这个页面实现了翻页逻辑，可以上一页、下一页地翻页，也可以直接跳到任意页数，如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-11-18-23-53-12.png" alt=""></p>
<p>现在需要获取1～9页的内容，那么使用前面章节学到的内容，通过Chrome浏览器的开发者工具很容易就能发现翻页实际上是一个POST请求，提交的参数为“date”，它的值是日期“2017-08-12”，如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-11-18-23-53-37.png" alt=""></p>
<p>使用Scrapy写一个爬虫来获取1～9页的内容，运行结果如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-11-18-23-54-00.png" alt=""></p>
<p>从上图可以看到，第5页没有正常获取到，返回的结果是参数错误。于是在网页上看一下，发现第5页的请求中body里面的date对应的日期是“2017-08-11”，如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-11-18-23-54-22.png" alt=""></p>
<p>如果测试的次数足够多，时间足够长，就会发现以下内容。</p>
<ol>
<li>同一个时间点，不同页数提交的参数中，date对应的日期可能是今天的也可能是昨天的。</li>
<li>同一个页数，不同时间提交的参数中，date对应的日期可能是今天的也可能是昨天的。</li>
</ol>
<p>由于日期不是今天，就是昨天，所以针对这种情况，写一个重试中间件是最简单粗暴且有效的解决办法。中间件的代码如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-11-18-23-54-44.png" alt=""></p>
<p>这个中间件只对名为“middlewareSpider”的爬虫有用。由于middlewareSpider爬虫默认使用的是“今天”的日期，所以如果被网站返回了“参数错误”，那么正确的日期就必然是昨天的了。所以在这个中间件里面，第119行，直接把原来请求的body换成了昨天的日期，这个请求的其他参数不变。让这个中间件生效以后，爬虫就能成功爬取第5页了，如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-11-18-23-55-01.png" alt=""></p>
<p>爬虫本身的代码，数据提取部分完全没有做任何修改，如果不看中间件代码，完全感觉不出爬虫在第5页重试过。</p>
<p>除了检查网站返回的内容外，还可以检查返回内容对应的网址。将上面练习页后台网址的第1个参数“para”改为404，暂时禁用重试中间件，再跑一次爬虫。其运行结果如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-11-18-23-55-25.png" alt=""></p>
<p>此时，对于参数不正确的请求，网站会自动重定向到以下网址对应的页面：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">http://exercise.kingname.info/404.html</div></pre></td></tr></table></figure>
<p>由于Scrapy自带网址自动去重机制，因此虽然第3页、第6页和第7页都被自动转到了404页面，但是爬虫只会爬一次404页面，剩下两个404页面会被自动过滤。</p>
<p>对于这种情况，在重试中间件里面判断返回的网址即可解决，如下图12-21所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-11-18-23-55-47.png" alt=""></p>
<p>在代码的第115行，判断是否被自动跳转到了404页面，或者是否被返回了“参数错误”。如果都不是，说明这一次请求目前看起来正常，直接把response返回，交给后面的中间件来处理。如果被重定向到了404页面，或者被返回“参数错误”，那么进入重试的逻辑。如果返回了“参数错误”，那么进入第126行，直接替换原来请求的body即可重新发起请求。</p>
<p>如果自动跳转到了404页面，那么这里有一点需要特别注意：此时的请求，request这个对象对应的是向404页面发起的GET请求，而不是原来的向练习页后台发起的请求。所以，重新构造新的请求时必须把URL、body、请求方式、Headers全部都换一遍才可以。</p>
<p>由于request对应的是向404页面发起的请求，所以resquest.url对应的网址是404页面的网址。因此，如果想知道调整之前的URL，可以使用如下的代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">request.meta[<span class="string">'redirect_urls'</span>]</div></pre></td></tr></table></figure>
<p>这个值对应的是一个列表。请求自动跳转了几次，这个列表里面就有几个URL。这些URL是按照跳转的先后次序依次append进列表的。由于本例中只跳转了一次，所以直接读取下标为0的元素即可，也就是原始网址。</p>
<p>重新激活这个重试中间件，不改变爬虫数据抓取部分的代码，直接运行以后可以正确得到1～9页的全部内容，如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-11-18-23-56-15.png" alt=""></p>
<h2 id="在中间件里处理异常"><a href="#在中间件里处理异常" class="headerlink" title="在中间件里处理异常"></a>在中间件里处理异常</h2><p>在默认情况下，一次请求失败了，Scrapy会立刻原地重试，再失败再重试，如此3次。如果3次都失败了，就放弃这个请求。这种重试逻辑存在一些缺陷。以代理IP为例，代理存在不稳定性，特别是免费的代理，差不多10个里面只有3个能用。而现在市面上有一些收费代理IP提供商，购买他们的服务以后，会直接提供一个固定的网址。把这个网址设为Scrapy的代理，就能实现每分钟自动以不同的IP访问网站。如果其中一个IP出现了故障，那么需要等一分钟以后才会更换新的IP。在这种场景下，Scrapy自带的重试逻辑就会导致3次重试都失败。</p>
<p>这种场景下，如果能立刻更换代理就立刻更换；如果不能立刻更换代理，比较好的处理方法是延迟重试。而使用Scrapy_redis就能实现这一点。爬虫的请求来自于Redis，请求失败以后的URL又放回Redis的末尾。一旦一个请求原地重试3次还是失败，那么就把它放到Redis的末尾，这样Scrapy需要把Redis列表前面的请求都消费以后才会重试之前的失败请求。这就为更换IP带来了足够的时间。</p>
<p>重新打开代理中间件，这一次故意设置一个有问题的代理，于是可以看到Scrapy控制台打印出了报错信息，如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-11-18-23-56-34.png" alt=""></p>
<p>从上图可以看到Scrapy自动重试的过程。由于代理有问题，最后会抛出方框框住的异常，表示TCP超时。在中间件里面如果捕获到了这个异常，就可以提前更换代理，或者进行重试。这里以更换代理为例。首先根据上图中方框框住的内容导入TCPTimeOutError这个异常：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> twisted.internet.error <span class="keyword">import</span> TCPTimedOutError</div></pre></td></tr></table></figure>
<p>修改前面开发的重试中间件，添加一个process_exception()方法。这个方法接收3个参数，分别为request、exception和spider，如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-11-18-23-56-58.png" alt=""></p>
<p>process_exception()方法只对名为“exceptionSpider”的爬虫生效，如果请求遇到了TCPTimeOutError，那么就首先调用remove_broken_proxy()方法把失效的这个代理IP移除，然后返回这个请求对象request。返回以后，Scrapy会重新调度这个请求，就像它第一次调度一样。由于原来的ProxyMiddleware依然在工作，于是它就会再一次给这个请求更换代理IP。又由于刚才已经移除了失效的代理IP，所以ProxyMiddleware会从剩下的代理IP里面随机找一个来给这个请求换上。</p>
<p>特别提醒：图片中的remove_broken_proxy()函数体里面写的是pass，但是在实际开发过程中，读者可根据实际情况实现这个方法，写出移除失效代理的具体逻辑。</p>
<h2 id="下载器中间件功能总结"><a href="#下载器中间件功能总结" class="headerlink" title="下载器中间件功能总结"></a>下载器中间件功能总结</h2><p>能在中间件中实现的功能，都能通过直接把代码写到爬虫中实现。使用中间件的好处在于，它可以把数据爬取和其他操作分开。在爬虫的代码里面专心写数据爬取的代码；在中间件里面专心写突破反爬虫、登录、重试和渲染AJAX等操作。</p>
<p>对团队来说，这种写法能实现多人同时开发，提高开发效率；对个人来说，写爬虫的时候不用考虑反爬虫、登录、验证码和异步加载等操作。另外，写中间件的时候不用考虑数据怎样提取。一段时间只做一件事，思路更清晰。</p>
<blockquote>
<p>本文节选自我的新书《Python爬虫开发  从入门到实战》完整目录可以在京东查询到 <a href="https://item.jd.com/12436581.html" target="_blank" rel="external">https://item.jd.com/12436581.html</a></p>
</blockquote>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在上一篇文章中介绍了下载器中间件的一些简单应用，现在再来通过案例说说如何使用下载器中间件集成Selenium、重试和处理请求异常。&lt;/p&gt;
    
    </summary>
    
      <category term="Python" scheme="https://www.kingname.info/categories/Python/"/>
    
    
      <category term="Python" scheme="https://www.kingname.info/tags/Python/"/>
    
      <category term="爬虫" scheme="https://www.kingname.info/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="Scrapy" scheme="https://www.kingname.info/tags/Scrapy/"/>
    
  </entry>
  
  <entry>
    <title>彻底搞懂Scrapy的中间件（一）</title>
    <link href="https://www.kingname.info/2018/11/18/know-middleware-of-scrapy/"/>
    <id>https://www.kingname.info/2018/11/18/know-middleware-of-scrapy/</id>
    <published>2018-11-18T14:21:35.000Z</published>
    <updated>2018-11-18T15:18:55.444Z</updated>
    
    <content type="html"><![CDATA[<h2 id="中间件（Middleware）"><a href="#中间件（Middleware）" class="headerlink" title="中间件（Middleware）"></a>中间件（Middleware）</h2><p>中间件是Scrapy里面的一个核心概念。使用中间件可以在爬虫的请求发起之前或者请求返回之后对数据进行定制化修改，从而开发出适应不同情况的爬虫。</p>
<p>“中间件”这个中文名字和前面章节讲到的“中间人”只有一字之差。它们做的事情确实也非常相似。中间件和中间人都能在中途劫持数据，做一些修改再把数据传递出去。不同点在于，中间件是开发者主动加进去的组件，而中间人是被动的，一般是恶意地加进去的环节。中间件主要用来辅助开发，而中间人却多被用来进行数据的窃取、伪造甚至攻击。</p>
<p>在Scrapy中有两种中间件：下载器中间件（Downloader Middleware）和爬虫中间件（Spider Middleware）。</p>
<p>这一篇主要讲解下载器中间件的第一部分。</p>
<a id="more"></a>
<h2 id="下载器中间件"><a href="#下载器中间件" class="headerlink" title="下载器中间件"></a>下载器中间件</h2><p>Scrapy的官方文档中，对下载器中间件的解释如下。</p>
<blockquote>
<p>下载器中间件是介于Scrapy的request/response处理的钩子框架，是用于全局修改Scrapy request和response的一个轻量、底层的系统。</p>
</blockquote>
<p>这个介绍看起来非常绕口，但其实用容易理解的话表述就是：更换代理IP，更换Cookies，更换User-Agent，自动重试。</p>
<p>如果完全没有中间件，爬虫的流程如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-11-18-23-04-14.png" alt=""></p>
<p>使用了中间件以后，爬虫的流程如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-11-18-23-04-44.png" alt=""></p>
<h3 id="开发代理中间件"><a href="#开发代理中间件" class="headerlink" title="开发代理中间件"></a>开发代理中间件</h3><p>在爬虫开发中，更换代理IP是非常常见的情况，有时候每一次访问都需要随机选择一个代理IP来进行。</p>
<p>中间件本身是一个Python的类，只要爬虫每次访问网站之前都先“经过”这个类，它就能给请求换新的代理IP，这样就能实现动态改变代理。</p>
<p>在创建一个Scrapy工程以后，工程文件夹下会有一个middlewares.py文件，打开以后其内容如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-11-18-23-05-13.png" alt=""></p>
<p>Scrapy自动生成的这个文件名称为middlewares.py，名字后面的s表示复数，说明这个文件里面可以放很多个中间件。Scrapy自动创建的这个中间件是一个爬虫中间件，这种类型在第三篇文章会讲解。现在先来创建一个自动更换代理IP的中间件。</p>
<p>在middlewares.py中添加下面一段代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">ProxyMiddleware</span><span class="params">(object)</span>:</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_request</span><span class="params">(self, request, spider)</span>:</span></div><div class="line">        proxy = random.choice(settings[<span class="string">'PROXIES'</span>])</div><div class="line">        request.meta[<span class="string">'proxy'</span>] = proxy</div></pre></td></tr></table></figure>
<p>要修改请求的代理，就需要在请求的meta里面添加一个Key为proxy，Value为代理IP的项。</p>
<p>由于用到了random和settings，所以需要在middlewares.py开头导入它们：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> random</div><div class="line"><span class="keyword">from</span> scrapy.conf <span class="keyword">import</span> settings</div></pre></td></tr></table></figure>
<p>在下载器中间件里面有一个名为<code>process_request()</code>的方法，这个方法中的代码会在每次爬虫访问网页之前执行。</p>
<p>打开settings.py，首先添加几个代理IP：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">PROXIES = [<span class="string">'https://114.217.243.25:8118'</span>,</div><div class="line">          <span class="string">'https://125.37.175.233:8118'</span>,</div><div class="line">          <span class="string">'http://1.85.116.218:8118'</span>]</div></pre></td></tr></table></figure>
<p>需要注意的是，代理IP是有类型的，需要先看清楚是HTTP型的代理IP还是HTTPS型的代理IP。如果用错了，就会导致无法访问。</p>
<h3 id="激活中间件"><a href="#激活中间件" class="headerlink" title="激活中间件"></a>激活中间件</h3><p>中间件写好以后，需要去settings.py中启动。在settings.py中找到下面这一段被注释的语句：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Enable or disable downloader middlewares</span></div><div class="line"><span class="comment"># See http://scrapy.readthedocs.org/en/latest/topics/downloader-middleware.html</span></div><div class="line"><span class="comment">#DOWNLOADER_MIDDLEWARES = &#123;</span></div><div class="line"><span class="comment">#    'AdvanceSpider.middlewares.MyCustomDownloaderMiddleware': 543,</span></div><div class="line"><span class="comment">#&#125;</span></div></pre></td></tr></table></figure>
<p>解除注释并修改，从而引用ProxyMiddleware。修改为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">DOWNLOADER_MIDDLEWARES = &#123;</div><div class="line">  <span class="string">'AdvanceSpider.middlewares.ProxyMiddleware'</span>: <span class="number">543</span>,</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这其实就是一个字典，字典的Key就是用点分隔的中间件路径，后面的数字表示这种中间件的顺序。由于中间件是按顺序运行的，因此如果遇到后一个中间件依赖前一个中间件的情况，中间件的顺序就至关重要。</p>
<p>如何确定后面的数字应该怎么写呢？最简单的办法就是从543开始，逐渐加一，这样一般不会出现什么大问题。如果想把中间件做得更专业一点，那就需要知道Scrapy自带中间件的顺序，如图下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-11-18-23-05-42.png" alt=""></p>
<p>数字越小的中间件越先执行，例如Scrapy自带的第1个中间件<code>RobotsTxtMiddleware</code>，它的作用是首先查看settings.py中<code>ROBOTSTXT_OBEY</code>这一项的配置是<code>True</code>还是<code>False</code>。如果是<code>True</code>，表示要遵守Robots.txt协议，它就会检查将要访问的网址能不能被运行访问，如果不被允许访问，那么直接就取消这一次请求，接下来的和这次请求有关的各种操作全部都不需要继续了。</p>
<p>开发者自定义的中间件，会被按顺序插入到Scrapy自带的中间件中。爬虫会按照从100～900的顺序依次运行所有的中间件。直到所有中间件全部运行完成，或者遇到某一个中间件而取消了这次请求。</p>
<p>Scrapy其实自带了UA中间件（UserAgentMiddleware）、代理中间件（HttpProxyMiddleware）和重试中间件（RetryMiddleware）。所以，从“原则上”说，要自己开发这3个中间件，需要先禁用Scrapy里面自带的这3个中间件。要禁用Scrapy的中间件，需要在settings.py里面将这个中间件的顺序设为None：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">DOWNLOADER_MIDDLEWARES = &#123;</div><div class="line">  <span class="string">'AdvanceSpider.middlewares.ProxyMiddleware'</span>: <span class="number">543</span>,</div><div class="line">  <span class="string">'scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware'</span>: <span class="keyword">None</span>,</div><div class="line">  <span class="string">'scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware'</span>: <span class="keyword">None</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>为什么说“原则上”应该禁用呢？先查看Scrapy自带的代理中间件的源代码，如下图所示：</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-11-18-23-06-06.png" alt=""></p>
<p>从上图可以看出，如果Scrapy发现这个请求已经被设置了代理，那么这个中间件就会什么也不做，直接返回。因此虽然Scrapy自带的这个代理中间件顺序为750，比开发者自定义的代理中间件的顺序543大，但是它并不会覆盖开发者自己定义的代理信息，所以即使不禁用系统自带的这个代理中间件也没有关系。</p>
<p>完整地激活自定义中间件的settings.py的部分内容如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-11-18-23-06-31.png" alt=""></p>
<p>配置好以后运行爬虫，爬虫会在每次请求前都随机设置一个代理。要测试代理中间件的运行效果，可以使用下面这个练习页面：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">http://exercise.kingname.info/exercise_middleware_ip</div></pre></td></tr></table></figure>
<p>这个页面会返回爬虫的IP地址，直接在网页上打开，如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-11-18-23-06-48.png" alt=""></p>
<p>这个练习页支持翻页功能，在网址后面加上“/页数”即可翻页。例如第100页的网址为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">http://exercise.kingname.info/exercise_middleware_ip/100</div></pre></td></tr></table></figure>
<p>使用了代理中间件为每次请求更换代理的运行结果，如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-11-18-23-07-06.png" alt=""></p>
<p>代理中间件的可用代理列表不一定非要写在settings.py里面，也可以将它们写到数据库或者Redis中。一个可行的自动更换代理的爬虫系统，应该有如下的3个功能。</p>
<ol>
<li>有一个小爬虫ProxySpider去各大代理网站爬取免费代理并验证，将可以使用的代理IP保存到数据库中。</li>
<li>在ProxyMiddlerware的process_request中，每次从数据库里面随机选择一条代理IP地址使用。</li>
<li>周期性验证数据库中的无效代理，及时将其删除。<br>由于免费代理极其容易失效，因此如果有一定开发预算的话，建议购买专业代理机构的代理服务，高速而稳定。</li>
</ol>
<h3 id="开发UA中间件"><a href="#开发UA中间件" class="headerlink" title="开发UA中间件"></a>开发UA中间件</h3><p>开发UA中间件和开发代理中间件几乎一样，它也是从settings.py配置好的UA列表中随机选择一项，加入到请求头中。代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">UAMiddleware</span><span class="params">(object)</span>:</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_request</span><span class="params">(self, request, spider)</span>:</span></div><div class="line">        ua = random.choice(settings[<span class="string">'USER_AGENT_LIST'</span>])</div><div class="line">        request.headers[<span class="string">'User-Agent'</span>] = ua</div></pre></td></tr></table></figure>
<p>比IP更好的是，UA不会存在失效的问题，所以只要收集几十个UA，就可以一直使用。常见的UA如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">USER_AGENT_LIST = [</div><div class="line"><span class="string">"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.101 Safari/537.36"</span>,</div><div class="line">  <span class="string">"Dalvik/1.6.0 (Linux; U; Android 4.2.1; 2013022 MIUI/JHACNBL30.0)"</span>,</div><div class="line">  <span class="string">"Mozilla/5.0 (Linux; U; Android 4.4.2; zh-cn; HUAWEI MT7-TL00 Build/HuaweiMT7-TL00) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1"</span>,</div><div class="line">  <span class="string">"AndroidDownloadManager"</span>,</div><div class="line">  <span class="string">"Apache-HttpClient/UNAVAILABLE (java 1.4)"</span>,</div><div class="line">  <span class="string">"Dalvik/1.6.0 (Linux; U; Android 4.3; SM-N7508V Build/JLS36C)"</span>,</div><div class="line">  <span class="string">"Android50-AndroidPhone-8000-76-0-Statistics-wifi"</span>,</div><div class="line">  <span class="string">"Dalvik/1.6.0 (Linux; U; Android 4.4.4; MI 3 MIUI/V7.2.1.0.KXCCNDA)"</span>,</div><div class="line">  <span class="string">"Dalvik/1.6.0 (Linux; U; Android 4.4.2; Lenovo A3800-d Build/LenovoA3800-d)"</span>,</div><div class="line">  <span class="string">"Lite 1.0 ( http://litesuits.com )"</span>,</div><div class="line">  <span class="string">"Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0; .NET4.0C; .NET4.0E; .NET CLR 2.0.50727)"</span>,</div><div class="line">  <span class="string">"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/38.0.2125.122 Safari/537.36 SE 2.X MetaSr 1.0"</span>,</div><div class="line">  <span class="string">"Mozilla/5.0 (Linux; U; Android 4.1.1; zh-cn; HTC T528t Build/JRO03H) AppleWebKit/534.30 (KHTML, like Gecko) Version/4.0 Mobile Safari/534.30; 360browser(securitypay,securityinstalled); 360(android,uppayplugin); 360 Aphone Browser (2.0.4)"</span>,</div><div class="line">]</div></pre></td></tr></table></figure>
<p>配置好UA以后，在settings.py下载器中间件里面激活它，并使用UA练习页来验证UA是否每一次都不一样。练习页的地址为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">http://exercise.kingname.info/exercise_middleware_ua。</div></pre></td></tr></table></figure>
<p>UA练习页和代理练习页一样，也是可以无限制翻页的。</p>
<p>运行结果如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-11-18-23-07-41.png" alt=""></p>
<h3 id="开发Cookies中间件"><a href="#开发Cookies中间件" class="headerlink" title="开发Cookies中间件"></a>开发Cookies中间件</h3><p>对于需要登录的网站，可以使用Cookies来保持登录状态。那么如果单独写一个小程序，用Selenium持续不断地用不同的账号登录网站，就可以得到很多不同的Cookies。由于Cookies本质上就是一段文本，所以可以把这段文本放在Redis里面。这样一来，当Scrapy爬虫请求网页时，可以从Redis中读取Cookies并给爬虫换上。这样爬虫就可以一直保持登录状态。</p>
<p>以下面这个练习页面为例：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">http://exercise.kingname.info/exercise_login_success</div></pre></td></tr></table></figure>
<p>如果直接用Scrapy访问，得到的是登录界面的源代码，如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-11-18-23-08-14.png" alt=""></p>
<p>现在，使用中间件，可以实现完全不改动这个loginSpider.py里面的代码，就打印出登录以后才显示的内容。</p>
<p>首先开发一个小程序，通过Selenium登录这个页面，并将网站返回的Headers保存到Redis中。这个小程序的代码如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-11-18-23-08-34.png" alt=""></p>
<p>这段代码的作用是使用Selenium和ChromeDriver填写用户名和密码，实现登录练习页面，然后将登录以后的Cookies转换为JSON格式的字符串并保存到Redis中。</p>
<p>接下来，再写一个中间件，用来从Redis中读取Cookies，并把这个Cookies给Scrapy使用：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">LoginMiddleware</span><span class="params">(object)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></div><div class="line">        self.client = redis.StrictRedis()</div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_request</span><span class="params">(self, request, spider)</span>:</span></div><div class="line">        <span class="keyword">if</span> spider.name == <span class="string">'loginSpider'</span>:</div><div class="line">            cookies = json.loads(self.client.lpop(<span class="string">'cookies'</span>).decode())</div><div class="line">            request.cookies = cookies</div></pre></td></tr></table></figure>
<p>设置了这个中间件以后，爬虫里面的代码不需要做任何修改就可以成功得到登录以后才能看到的HTML，如图12-12所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-11-18-23-08-55.png" alt=""></p>
<p>如果有某网站的100个账号，那么单独写一个程序，持续不断地用Selenium和ChromeDriver或者Selenium 和PhantomJS登录，获取Cookies，并将Cookies存放到Redis中。爬虫每次访问都从Redis中读取一个新的Cookies来进行爬取，就大大降低了被网站发现或者封锁的可能性。</p>
<p>这种方式不仅适用于登录，也适用于验证码的处理。</p>
<p>这一篇就讲到这里，在下一篇，我们将会介绍如何在下载器中间件中集成Selenium，进行请求重试和处理异常。</p>
<blockquote>
<p>本文节选自我的新书《Python爬虫开发  从入门到实战》完整目录可以在京东查询到 <a href="https://item.jd.com/12436581.html" target="_blank" rel="external">https://item.jd.com/12436581.html</a></p>
</blockquote>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;中间件（Middleware）&quot;&gt;&lt;a href=&quot;#中间件（Middleware）&quot; class=&quot;headerlink&quot; title=&quot;中间件（Middleware）&quot;&gt;&lt;/a&gt;中间件（Middleware）&lt;/h2&gt;&lt;p&gt;中间件是Scrapy里面的一个核心概念。使用中间件可以在爬虫的请求发起之前或者请求返回之后对数据进行定制化修改，从而开发出适应不同情况的爬虫。&lt;/p&gt;
&lt;p&gt;“中间件”这个中文名字和前面章节讲到的“中间人”只有一字之差。它们做的事情确实也非常相似。中间件和中间人都能在中途劫持数据，做一些修改再把数据传递出去。不同点在于，中间件是开发者主动加进去的组件，而中间人是被动的，一般是恶意地加进去的环节。中间件主要用来辅助开发，而中间人却多被用来进行数据的窃取、伪造甚至攻击。&lt;/p&gt;
&lt;p&gt;在Scrapy中有两种中间件：下载器中间件（Downloader Middleware）和爬虫中间件（Spider Middleware）。&lt;/p&gt;
&lt;p&gt;这一篇主要讲解下载器中间件的第一部分。&lt;/p&gt;
    
    </summary>
    
      <category term="Python" scheme="https://www.kingname.info/categories/Python/"/>
    
    
      <category term="Python" scheme="https://www.kingname.info/tags/Python/"/>
    
      <category term="爬虫" scheme="https://www.kingname.info/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="Scrapy" scheme="https://www.kingname.info/tags/Scrapy/"/>
    
  </entry>
  
  <entry>
    <title>跳出任务管理的泥沼，拥抱甘特图的怀抱（完整版）</title>
    <link href="https://www.kingname.info/2018/10/17/use-gantt-enhanced/"/>
    <id>https://www.kingname.info/2018/10/17/use-gantt-enhanced/</id>
    <published>2018-10-17T12:36:39.000Z</published>
    <updated>2018-10-21T01:47:16.966Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/photo-1523958399470-c15bf82fcea9.jpeg" alt=""></p>
<p>写这篇文章，我不是要黑任何一个任务管理类的App或者方法论。相反，我是一个工具控，在试用各种任务管理类App上总是不遗余力。常见的Things 3，Todoist，Teambition，Trello，Any.do，Doit.im我都试用过。最后，我选择了<a href="https://todoist.com" target="_blank" rel="external">Todoist</a>，在Todoist上，我已经完成了1292个任务。如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-09-24-22-26-08.png" alt="我的Todoist任务记录"></p>
<a id="more"></a>
<h2 id="任务管理类App有什么问题"><a href="#任务管理类App有什么问题" class="headerlink" title="任务管理类App有什么问题"></a>任务管理类App有什么问题</h2><p>Things3，Todoist为首的任务管理App，核心功能就是记录<strong>未完成</strong>的任务，勾掉<strong>已完成</strong>的任务。至于分类，标签，自然语言识别之类的功能算是锦上添花。</p>
<p>他们有一个缺点，那就是你只知道一个任务没有做，或者已经做完了。但是你不知道在一群没有完成的任务中，哪些是正在做的。（当然，你可以创建一个分类，叫做“正在做”，然后把正在做的任务放进这个分类中。）</p>
<p>而Teambition与Trello稍微进步一点，引入了看板的概念，于是能够显示任务在各个阶段的状态，如下图所示。这张图是少数派的Trello看板，用来让作者选题。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-01-01-10-26-51.png" alt=""></p>
<p>在看板中，你可以知道哪些任务是计划中，哪些任务是准备做，哪些是正在做，哪些是已经完成。然而这样就够了吗？</p>
<p>看板比单纯的To do list类应用进了一步，能够关注任务的状态了。但它们的局限也在于此，因为他们关注的，只是每一个任务。</p>
<p>做一个比喻，修汽车需要拧螺丝，组装宜家的家具也需要拧螺丝。你如果只关注拧螺丝这个动作，那么修汽车和组装家具对你来说没有区别。组装宜家的家具，看一下说明书，一般人半个小时就搞定，但是你半个小时能学会修汽车吗？</p>
<p>如果只使用任务管理类的工具，你就会陷入一个怪圈：你做了很多任务，但是你不知道你做这些任务是为了什么。任务管理类App适合用来记录和追踪各种琐碎的任务和相关性不强的任务。就像是少数派的每一篇文章，文章与文章之间不是一个系列的关系，他们各自独立，谁都可以领选题写文章，哪个选题先写哪个选题后写，关系不大。</p>
<p>一旦要规划一个项目，对于规划项目的人和做项目的人，用任务管理类App都会让人觉得使不上劲。对于做任务的人，看到每一个独立的任务，对项目没有整体的概念；对于规划项目的人，不知道任务是不是已经切分得足够细，是否有遗漏。</p>
<p>假设你把一个项目拆分成了100个子任务，两周以后，你做完了其中的八十个子任务，请问你真的完成了这个项目80%的工作吗？项目的完成度能够单纯用子任务的数量来衡量吗？</p>
<p>如果你回答，项目的完成度，不能单纯用子任务的数量来衡量。那么继续思考下一个问题，是不是有一些子任务，就是比别的任务重要呢？</p>
<p>如果你回答，确实有一些子任务比别的任务都重要。那么继续思考下一个问题，是不是最重要的子任务必需优先完成呢？</p>
<p>如果你回答，确实最重要的子任务必需优先完成。那么继续思考下一个问题，最重要的子任务要优先多少呢？能单纯把最重要的子任务作为第一个完成的任务吗？它有前置任务吗？如果必需先把前置任务做完，才能做这个最重要的子任务，那么，是不是其实这个前置任务才是最重要的子任务呢？如此说来，能够单纯用时间先后顺序来标明任务的重要性吗？先做的总是比后做的重要吗？那如果这个先做的任务，它做完以后完全看不到产出，必需等后面的任务做完了才能看到效果，那么到底是先做的任务重要还是后做的任务重要？</p>
<p>上面还只是一个人做多个任务的情况，现在如果把一个项目拆分成100个任务，分给ABCDE5个人做同时做。每个人都有一些任务可以单独完成不依赖其他人。但是也有一些任务A依赖B的成果，B依赖C的成果，D可以帮B做一些工作，还有一些工作需要C和D要一起同时完成，还有一些工作，B和C可以先做一部分，剩下的一部分再一起完成……</p>
<p>好了，现在给你一个任务管理类的App，上面列了100个任务，其中有20个任务优先级最高，50个优先级一般，30个优先级低。你们五个人自己看着选任务做吧。两周以后项目上线。</p>
<p>13天后：</p>
<p>B：C你的后台接口怎么还没有写好，我等着跟你联合调试都等了三天了！<br>D：糟糕，有一个任务忘记做了，现在这个代码不能运行，等我把那边的服务搭建好才能测试。<br>A：嘿嘿我完成了30个任务，奖金我拿定了。<br>C：D你早应该搭建服务的，你忘了我也要用吗！<br>……</p>
<p>所以，单纯用优先级来排任务，你觉得靠谱吗？你不加班，谁来加班？</p>
<h2 id="寻找解决办法"><a href="#寻找解决办法" class="headerlink" title="寻找解决办法"></a>寻找解决办法</h2><h3 id="使用脑图拆分任务"><a href="#使用脑图拆分任务" class="headerlink" title="使用脑图拆分任务"></a>使用脑图拆分任务</h3><p>有项目经验的人，看到我上面举得例子，肯定会不屑一顾——难道在规划项目的时候就拿一张白纸，拍着脑袋想，这个项目需要做哪些工作，想到一个写一个？这样凭脑袋空想肯定会漏掉任务的。</p>
<p>用脑图来规划任务是一个不错的主意，首先把项目拆分成几个主要的组成模块。然后首先看第一个模块，又把它拆分成几个子模块。然后看第一个模块的第一个子模块，又拆分……第一个模块拆分好了，再来看第二个模块，把它又拆分成几个子模块……通过这样深度优先的方式把所有任务都拆分到可以完成的程度。如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/x3_project.png" alt="使用脑图拆分项目任务"></p>
<p>脑图解决了任务拆分的问题，使用脑图来拆分任务，理论上确实不容易漏掉任务。那么问题是，脑图如何确定任务的依赖关系？如何确定每个任务的完成时间？项目进行了若干天以后，如何知道当前项目进度怎么样了？在某一天，如何让所有人都一眼就知道，哪些任务没有按时完成，哪些任务已经提前完成了？</p>
<h3 id="使用时间轴确定进度"><a href="#使用时间轴确定进度" class="headerlink" title="使用时间轴确定进度"></a>使用时间轴确定进度</h3><p>现在回到任务管理的App中。如果把所有待完成的任务全部都用一个Excel写在第一列，然后在右侧用不同的色块标记任务从开始到结束的时间。那么可以得到下面这一张图。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/timeline.png" alt="使用Excel画一个时间轴"></p>
<p>其中，不同的颜色表示不同的人。每一行表示一个任务。从第二列开始，每一列表示一天。如果一个任务一天可以做完，就涂一个格子，如果需要三天才能做完，就涂三个格子。</p>
<p>这样一来，通过这些色块，就可以清楚地看到每个人需要做多少事情。例如B列，紫色这个人一天同时要做5个任务。但是这5个任务中有4个任务都是联系别的部门让他们提供接口。那么这四个任务应该可以很容易做完，于是可以放在一天完成。</p>
<p>又比如，红色这个人，他做的任务很困难，所以两个任务各要做三天。</p>
<p>又比如，绿色这个人，他先搭建ES系统。然后再搭建Kafka。任务的先后顺序也就有了。</p>
<p>如果在某一天，想知道按计划今天哪些人需要做哪些事，那么直接看这一天对应的这一列就可以了。</p>
<h3 id="压缩，组合"><a href="#压缩，组合" class="headerlink" title="压缩，组合"></a>压缩，组合</h3><p>用时间轴来表示任务的进度，可以更加直观地让人看到任务的进度。但前提是先把所有子任务确定好。也就是要先做一个脑图，然后根据脑图再做这个Excel。看任务的时候，要同时看两张图。</p>
<p>那有没有办法把这两张图合在一起呢？</p>
<p>实际上，脑图本质上就是一个层次结构，层次结构也可以写成大纲的形式，如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/outline.png" alt="脑图的大纲形式"></p>
<p>这个结构就可以放到Excel中了。如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/outlinewithtimeline.png" alt="简化版的甘特图"></p>
<p>到目前为止，你已经实现了一个简化版的甘特图了。</p>
<h2 id="什么是甘特图"><a href="#什么是甘特图" class="headerlink" title="什么是甘特图"></a>什么是甘特图</h2><p>甘特图是一张二维的图表，它的横轴是时间，纵轴是任务。从甘特图上可以一目了然看到一个任务从什么时候开始什么时候结束，不同任务之间是否有时间重叠，以及哪些任务可以同时做哪些任务必需有先后顺序。</p>
<p>我个人认为，在项目管理中，任务周期是非常重要的，任务的开始时间和结束时间一定要把控好。使用甘特图就可以实现这样一个目的。</p>
<p>对于规划任务的人，在用甘特图规划任务的时候，如果你发现一个任务时间太长，无论怎么调整都会和后面的任务有重叠，那么你就会发现这个任务可能需要拆分为更小的任务。而且由于甘特图立足于项目的整体，你也可以更容易发现是否有任务漏掉了。</p>
<p>对于做任务的人，甘特图也可以帮他们了解到他们所做的任务在整个项目中处于一个什么样的位置，从而让他们知道自己正在做的任务是不是非常重要必需按时完成。</p>
<p>如果你是要开发一个App，或者是要写一本书，或者是要做一个其他什么项目，只要它是由一系列不同的任务构成的，那么你就可以考虑使用甘特图来帮你提高效率。</p>
<p>下面这张图就是甘特图。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/gantt.png" alt=""></p>
<ul>
<li>不同的颜色表示不同的人</li>
<li>每一行表示一个任务</li>
<li>红色竖线表示今天应该完成的任务</li>
<li>任务与任务之间的黑色箭头表示任务之间的依赖关系，必需完成前面的才能完成后面的</li>
<li>带中心黑线的任务表示已经完成的任务</li>
</ul>
<p>通过这一张甘特图，我能一眼看出以下信息：</p>
<ol>
<li>今天谁应该做什么任务</li>
<li>这个任务从什么时候开始，到什么时候结束</li>
<li>一个人在一段时间有哪些任务</li>
<li>应该先做哪些任务再做哪些任务</li>
<li>哪些任务可以同时做</li>
<li>这个任务是否被其他任务依赖，如果是，那么这个任务就不能推迟，必需按时完成或者提前完成，否则会影响后面的任务</li>
<li>每个任务已经完成多少还剩多少</li>
<li>大任务下面有哪些子任务</li>
<li>任务的里程碑是什么时候</li>
</ol>
<h2 id="为什么要用甘特图"><a href="#为什么要用甘特图" class="headerlink" title="为什么要用甘特图"></a>为什么要用甘特图</h2><p>因为为了绘制出甘特图，你必需强迫自己完成以下几件事情：</p>
<ol>
<li>确定每一个任务的开始时间和结束时间</li>
<li>确定任务的依赖关系</li>
<li>分离可以同时运行的任务</li>
<li>确定不同人的任务间的时间关系</li>
</ol>
<p>当你根据以上的规则绘制好第一版甘特图以后，你会发现有些地方是可以继续调整的，但是这种调整，在你没有画图之前是不能发现的。于是你会在调整甘特图的过程中，让项目的规划越来越清晰。</p>
<h2 id="怎么做甘特图"><a href="#怎么做甘特图" class="headerlink" title="怎么做甘特图"></a>怎么做甘特图</h2><p>甘特图是一种项目管理工具，你可以在纸上画甘特图，也可以在Excel中画甘特图，也可以使用专门的甘特图软件来做甘特图。下面这张基于Excel的甘特图来自网络。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2017-12-31-23-20-03.png" alt=""></p>
<p>这是使用Excel做出来的效果，但是做起来稍显麻烦。</p>
<p>Omniplan和MS Project都是非常专业的甘特图制作软件，但是价格非常高。毕竟这是生产力软件，使用这个软件你是可以赚大钱的，自然软件本身就会比较贵。</p>
<p>开源的甘特图软件也有不少，不过不是功能不全就是界面丑陋。这里介绍一个相对比较完整的开源甘特图制作软件：GanttProject</p>
<p>GanttProject的官方网站为<a href="http://www.ganttproject.biz/" target="_blank" rel="external">http://www.ganttproject.biz/</a>，在这里你可以下载到macOS，Windows或者Linux版本的软件。</p>
<p>GanttProject运行以后的界面如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2017-12-31-23-47-11.png" alt=""></p>
<p>在左侧任务面板右键或者按下键盘<code>Command</code> + <code>T</code>就可以添加任务，Windows和Linux对应的快捷键为<code>Ctrl</code> + <code>T</code>。如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2017-12-31-23-48-11.png" alt=""></p>
<p>创建好了一个任务，它默认的开始时间和结束时间都是今天。在任务上面右键，选择<code>任务属性</code>，可以打开任务属性设置界面，在这里可以设置任务的开始时间和任务时长。但是你不能设置任务结束时间。因为任务结束时间会根据开始时间和任务时长自动计算。如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-01-01-00-03-16.png" alt=""></p>
<p>在这个界面，还可以设置任务的颜色，实现不同人不同颜色，或者不同项目不同颜色。也可以在这里更新任务进度。</p>
<p>创建多个任务，如果后面的任务依赖前面的任务，那么在右侧被依赖的任务色条上单击鼠标左键，按住并拖动到依赖它的任务上。依赖它的任务的起始时间自动就会变为被依赖任务的结束时间，如下图所示。此时，后一个任务只能设置任务的时长，不能修改任务的起始时间。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-01-01-00-08-17.png" alt=""></p>
<p>如果依赖关系设置错误，打开依赖任务的任务属性，定位到<code>前置任务</code>选项卡，在这里可以删除被依赖的任务或者修改被依赖任务。如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-01-01-00-11-10.png" alt=""></p>
<p>如果你需要移动任务的顺序，鼠标单击选中它，按下键盘上的<code>Alt</code> + <code>方向键上或下</code>即可移动任务。</p>
<p>我认为甘特图有一个非常重要的元素，就是竖直红线，它指向了今天的任务。要打开这跟红线，需要单击菜单栏的<code>编辑</code>-<code>设置</code>，定位到<code>甘特图设定</code>，在<code>将今天显示为红色</code>点选为<code>是</code>，如下图所示。<br><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-01-01-00-20-55.png" alt=""><br>单击确定回到甘特图的界面，可以看到图中出现了一条红色竖线。这条竖线指向了今天应该做的事情。如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-01-01-00-23-06.png" alt=""></p>
<p>每天打开甘特图，这根红线都会指向当天。</p>
<p>GanttProject可以把做好的甘特图导出为图片，CSV，HTML或者PDF文件。单击<code>项目</code>-<code>导出</code>，点选<code>Raster图像文件</code>，并单击<code>下一步</code>，如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-01-01-00-24-34.png" alt=""></p>
<p>设置保存路径和甘特图的日期范围即可导出为PNG文件，以方便分享。</p>
<h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>我非常喜欢使用甘特图来规划我的工作。我的第一本书<br>《Python爬虫开发 从入门到实战》已经在<a href="https://item.jd.com/12436581.html" target="_blank" rel="external">京东</a>、<a href="http://product.dangdang.com/25349717.html" target="_blank" rel="external">当当</a>、<a href="https://www.amazon.cn/dp/B07HGBRXFW" target="_blank" rel="external">亚马逊</a>在亚马逊上线。这本书的写作过程就是我用甘特图的最好实践。因为有了甘特图，我才能控制好写作过程中的每一个重要的时间节点，确保每一章都能够按时交付，让我能够兼顾工作，写书和自我成长。</p>
<p>甘特图并不是为了取代任务管理工具而存在的。甘特图的目的是为了规划项目，并且让你在项目的进行过程中知道自己处于什么位置。</p>
<p>你需要时刻记得，低头看任务管理工具，让你知道自己正在做什么。抬头看甘特图，让你知道你将能够做成什么。</p>
<p>我创建了一个微信群，用来交流各种效率工具和提高生产力的方法。有兴趣的同学可以进来和大家一起探讨。扫码关注公众号 <code>未闻Code</code>（或搜索ID：itskingname）回复：<code>生产力</code>即可获得入群方式。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/wechatplatform.jpg" alt=""></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/photo-1523958399470-c15bf82fcea9.jpeg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;写这篇文章，我不是要黑任何一个任务管理类的App或者方法论。相反，我是一个工具控，在试用各种任务管理类App上总是不遗余力。常见的Things 3，Todoist，Teambition，Trello，Any.do，Doit.im我都试用过。最后，我选择了&lt;a href=&quot;https://todoist.com&quot;&gt;Todoist&lt;/a&gt;，在Todoist上，我已经完成了1292个任务。如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-09-24-22-26-08.png&quot; alt=&quot;我的Todoist任务记录&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="项目管理" scheme="https://www.kingname.info/categories/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/"/>
    
    
      <category term="时间管理" scheme="https://www.kingname.info/tags/%E6%97%B6%E9%97%B4%E7%AE%A1%E7%90%86/"/>
    
      <category term="GTD" scheme="https://www.kingname.info/tags/GTD/"/>
    
      <category term="项目管理" scheme="https://www.kingname.info/tags/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>英文文档帮查&amp;翻译计划</title>
    <link href="https://www.kingname.info/2018/10/15/translate-help/"/>
    <id>https://www.kingname.info/2018/10/15/translate-help/</id>
    <published>2018-10-15T14:15:08.000Z</published>
    <updated>2018-10-16T00:10:21.175Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/photo-1512153472310-d72327c26cf0.jpeg" alt=""></p>
<p>以CSDN为首，知乎其次，cnblog带路的一大批博客上充斥着大量低质量的编程入门教程，代码粗制滥造，毫无缩进，没有高亮，东抄西抄。初学者如果长期参照这种垃圾博客来解决问题，将会适得其反，走入歧途。</p>
<p>其实，初学者最应该看的，是编程软件的<code>官方文档</code>，是软件工具的<code>官方文档</code>，是开源项目的<code>官方文档</code>……</p>
<p>但是鉴于有一些文档没有中文翻译，让不少不会英文的同学望而却步。</p>
<p>为此，我将会启动英文文档代查、翻译计划。</p>
<p>如果你想学习一门编程语言，但是它没有官方中文文档；如果你想实现一个功能，但是官方教程对API的描述是英文；如果你想用一个软件，但是这个软件没有中文说明书；如果你想参与一个开源项目，但是看不懂上面的英文讨论……那么你可以在这个公众号上获得帮助。</p>
<h2 id="如何寻求帮助​"><a href="#如何寻求帮助​" class="headerlink" title="如何寻求帮助​"></a>如何寻求帮助​</h2><p>扫描本文末尾的微信公众号二维码添加<code>未闻Code</code>，公众号私聊中，把你的诉求发送给我。我帮你寻找官方文档，帮你翻译，然后用公众号文章的形式发布出来，让更多人看到。</p>
<p>例如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">#文档翻译#我想知道Scrapy的下载器中间件中，process_response可以返回哪些数据。</div></pre></td></tr></table></figure>
<p>如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/IMG_1635.PNG" alt=""></p>
<h2 id="我接收哪些请求"><a href="#我接收哪些请求" class="headerlink" title="我接收哪些请求"></a>我接收哪些请求</h2><ul>
<li>StackOverflow上面具体某一个问题的回答。您可以把网址发送给我</li>
<li>编程语言具体功能</li>
<li>开源项目具体某个API的使用</li>
<li>Medium中具体某一篇文章的某一段落</li>
</ul>
<p>总之，你的需求越具体，我就越能找到你需要的内容并为你翻译。</p>
<p>当然，你也可以尝试给我发送一些非技术性的内容，例如《经济学人》《华盛顿邮报》中的具体<code>某个段落</code>，如果我有时间的话，也会帮你翻译。</p>
<h2 id="我拒接哪些请求"><a href="#我拒接哪些请求" class="headerlink" title="我拒接哪些请求"></a>我拒接哪些请求</h2><ul>
<li>请帮我翻译Python官方文档</li>
<li>请帮我翻译这一篇Quora下面的所有回答</li>
<li>请帮我翻译这个开源项目的官方文档</li>
</ul>
<h2 id="我怎么给你结果"><a href="#我怎么给你结果" class="headerlink" title="我怎么给你结果"></a>我怎么给你结果</h2><p>我会汇总每一周的请求，并在周六更新的公众号文章中，为你呈现你需要的结果。</p>
<h2 id="这个项目收费吗"><a href="#这个项目收费吗" class="headerlink" title="这个项目收费吗"></a>这个项目收费吗</h2><p>本计划完全免费。不会以任何形式收取任何费用。不收费不代表没有成本，因此请勿滥用。</p>
<h2 id="我为什么要启动这个项目"><a href="#我为什么要启动这个项目" class="headerlink" title="我为什么要启动这个项目"></a>我为什么要启动这个项目</h2><ol>
<li>我看不惯那些装逼货粗制滥造的博客。</li>
<li>我深深体会到阅读官方文档的重要性，因此我希望我能让更多的人能在遇到问题时首先想到官方文档而不是用百度搜索中文博客。</li>
<li>你们问的东西可能也是我不知道的，通过这个项目我可以学到更多好用的工具</li>
<li>把我的英语单词量扩展到10000词以上。</li>
</ol>
<h2 id="如何找到我"><a href="#如何找到我" class="headerlink" title="如何找到我"></a>如何找到我</h2><p>请扫描下面的二维码，添加我的微信公众号<code>未闻Code</code>。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/wechatplatform.jpg" alt=""></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/photo-1512153472310-d72327c26cf0.jpeg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;以CSDN为首，知乎其次，cnbl
    
    </summary>
    
      <category term="学习" scheme="https://www.kingname.info/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="翻译" scheme="https://www.kingname.info/tags/%E7%BF%BB%E8%AF%91/"/>
    
      <category term="开源" scheme="https://www.kingname.info/tags/%E5%BC%80%E6%BA%90/"/>
    
  </entry>
  
  <entry>
    <title>使用Docker Swarm搭建分布式爬虫集群</title>
    <link href="https://www.kingname.info/2018/10/13/use-docker-swarm/"/>
    <id>https://www.kingname.info/2018/10/13/use-docker-swarm/</id>
    <published>2018-10-13T13:23:51.000Z</published>
    <updated>2018-10-14T09:05:09.791Z</updated>
    
    <content type="html"><![CDATA[<p>在爬虫开发过程中，你肯定遇到过需要把爬虫部署在多个服务器上面的情况。此时你是怎么操作的呢？逐一SSH登录每个服务器，使用git拉下代码，然后运行？代码修改了，于是又要一个服务器一个服务器登录上去依次更新？</p>
<p>有时候爬虫只需要在一个服务器上面运行，有时候需要在200个服务器上面运行。你是怎么快速切换的呢？一个服务器一个服务器登录上去开关？或者聪明一点，在Redis里面设置一个可以修改的标记，只有标记对应的服务器上面的爬虫运行？</p>
<p>A爬虫已经在所有服务器上面部署了，现在又做了一个B爬虫，你是不是又得依次登录每个服务器再一次部署？</p>
<p>如果你确实是这么做的，那么你应该后悔没有早一点看到这篇文章。看完本文以后，你能够做到：</p>
<ul>
<li>2分钟内把一个新爬虫部署到50台服务器上：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">docker build -t localhost:8003/spider:0.01 .</div><div class="line">docker push localhost:8002/spider:0.01</div><div class="line">docker service create --name spider --replicas 50 --network host 45.77.138.242:8003/spider:0.01</div></pre></td></tr></table></figure>
<ul>
<li>30秒内把爬虫从50台服务器扩展到500台服务器：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker service scale spider=500</div></pre></td></tr></table></figure>
<ul>
<li>30秒内批量关闭所有服务器上的爬虫：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker service scale spider=0</div></pre></td></tr></table></figure>
<ul>
<li>1分钟内批量更新所有机器上的爬虫：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">docker build -t localhost:8003/spider:0.02 .</div><div class="line">docker push localhost:8003/spider:0.02</div><div class="line">docker service update --image 45.77.138.242:8003/spider:0.02 spider</div></pre></td></tr></table></figure>
<a id="more"></a>
<p>这篇文章不会教你怎么使用Docker，所以请确定你有一些Docker基础再来看本文。</p>
<h2 id="Docker-Swarm是什么"><a href="#Docker-Swarm是什么" class="headerlink" title="Docker Swarm是什么"></a>Docker Swarm是什么</h2><p>Docker Swarm是Docker自带的一个集群管理模块。他能够实现Docker集群的创建和管理。</p>
<h2 id="环境搭建"><a href="#环境搭建" class="headerlink" title="环境搭建"></a>环境搭建</h2><p>本文将会使用3台Ubuntu 18.04的服务器来进行演示。这三台服务器安排如下：</p>
<ul>
<li>Master：45.77.138.242</li>
<li>Slave-1：199.247.30.74</li>
<li>Slave-2：95.179.143.21</li>
</ul>
<p>Docker Swarm是基于Docker的模块，所以首先要在3台服务器上安装Docker。安装完成Docker以后，所有的操作都在Docker中完成。</p>
<h3 id="在Master上安装Docker"><a href="#在Master上安装Docker" class="headerlink" title="在Master上安装Docker"></a>在Master上安装Docker</h3><p>通过依次执行下面的命令，在Master服务器上安装Docker</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">apt-get update</div><div class="line">apt-get install -y apt-transport-https ca-certificates curl software-properties-common</div><div class="line">curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -</div><div class="line">add-apt-repository &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu bionic stable&quot;</div><div class="line">apt-get update</div><div class="line">apt-get install -y docker-ce</div></pre></td></tr></table></figure>
<h3 id="创建Manager节点"><a href="#创建Manager节点" class="headerlink" title="创建Manager节点"></a>创建Manager节点</h3><p>一个Docker Swarm集群需要Manager节点。现在初始化Master服务器，作为集群的Manager节点。运行下面一条命令。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker swarm init</div></pre></td></tr></table></figure>
<p>运行完成以后，可以看到的返回结果下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/docker_swarm_2.png" alt=""></p>
<p>这个返回结果中，给出了一条命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker swarm join --token SWMTKN-1-0hqsajb64iynkg8ocp8uruktii5esuo4qiaxmqw2pddnkls9av-dfj7nf1x3vr5qcj4cqiusu4pv 45.77.138.242:2377</div></pre></td></tr></table></figure>
<p>这条命令需要在每一个从节点（Slave）中执行。现在先把这个命令记录下来。</p>
<p>初始化完成以后，得到一个只有1台服务器的Docker 集群。执行如下命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker node ls</div></pre></td></tr></table></figure>
<p>可以看到当前这个集群的状态，如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/docker_swarm_3.png" alt=""></p>
<h3 id="创建私有源（可选）"><a href="#创建私有源（可选）" class="headerlink" title="创建私有源（可选）"></a>创建私有源（可选）</h3><p>创建私有源并不是一个必需的操作。之所以需要私有源，是因为项目的Docker镜像可能会涉及到公司机密，不能上传到DockerHub这种公共平台。如果你的镜像可以公开上传DockerHub，或者你已经有一个可以用的私有镜像源，那么你可以直接使用它们，跳过本小节和下一小节。</p>
<p>私有源本身也是一个Docker的镜像，先将拉取下来：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker pull registry:latest</div></pre></td></tr></table></figure>
<p>如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/docker_swarm_4.png" alt=""></p>
<p>现在启动私有源：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker run -d -p 8003:5000 --name registry -v /tmp/registry:/tmp/registry docker.io/registry:latest</div></pre></td></tr></table></figure>
<p>如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/docker_swarm_5.png" alt=""></p>
<p>在启动命令中，设置了对外开放的端口为8003端口，所以私有源的地址为：45.77.138.242:8003</p>
<blockquote>
<p>提示:<br>这样搭建的私有源是HTTP方式，并且没有权限验证机制，所以如果对公网开放，你需要再使用防火墙做一下IP白名单，从而保证数据的安全。</p>
</blockquote>
<h3 id="允许docker使用可信任的http私有源（可选）"><a href="#允许docker使用可信任的http私有源（可选）" class="headerlink" title="允许docker使用可信任的http私有源（可选）"></a>允许docker使用可信任的http私有源（可选）</h3><p>如果你使用上面一个小节的命令搭建了自己的私有源，由于Docker默认是不允许使用HTTP方式的私有源的，因此你需要配置Docker，让Docker信任它。</p>
<p>使用下面命令配置Docker：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">echo &apos;&#123; &quot;insecure-registries&quot;:[&quot;45.77.138.242:8003&quot;] &#125;&apos; &gt;&gt; /etc/docker/daemon.json</div></pre></td></tr></table></figure>
<p>然后使用下面这个命令重启docker。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">systemctl restart docker</div></pre></td></tr></table></figure>
<p>如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/docker_swarm_6.png" alt=""></p>
<p>重启完成以后，Manager节点就配置好了。</p>
<h2 id="创建子节点初始化脚本"><a href="#创建子节点初始化脚本" class="headerlink" title="创建子节点初始化脚本"></a>创建子节点初始化脚本</h2><p>对于Slave服务器来说，只需要做三件事情：</p>
<ol>
<li>安装Docker</li>
<li>加入集群</li>
<li>信任源</li>
</ol>
<p>从此以后，剩下的事情全部交给Docker Swarm自己管理，你再也不用SSH登录这个服务器了。</p>
<p>为了简化操作，可以写一个shell脚本来批量运行。在Slave-1和Slave-2服务器下创建一个<code>init.sh</code>文件，其内容如下。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">apt-get update</div><div class="line">apt-get install -y apt-transport-https ca-certificates curl software-properties-common</div><div class="line">curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -</div><div class="line">add-apt-repository &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu bionic stable&quot;</div><div class="line">apt-get update</div><div class="line">apt-get install -y docker-ce</div><div class="line">echo &apos;&#123; &quot;insecure-registries&quot;:[&quot;45.77.138.242:8003&quot;] &#125;&apos; &gt;&gt; /etc/docker/daemon.json</div><div class="line">systemctl restart docker </div><div class="line">docker swarm join --token SWMTKN-1-0hqsajb64iynkg8ocp8uruktii5esuo4qiaxmqw2pddnkls9av-dfj7nf1x3vr5qcj4cqiusu4pv 45.77.138.242:2377</div></pre></td></tr></table></figure>
<p>把这个文件设置为可自行文件，并运行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">chmod +x init.sh</div><div class="line">./init.sh</div></pre></td></tr></table></figure>
<p>如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/docker_swarm_7.png" alt=""></p>
<p>等待脚本运行完成以后，你就可以从Slave-1和Slave-2的SSH上面登出了。以后也不需要再进来了。</p>
<p>回到Master服务器，执行下面的命令，来确认现在集群已经有3个节点了：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker node ls</div></pre></td></tr></table></figure>
<p>看到现在集群中已经有3个节点了。如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/docker_swarm_9.png" alt=""></p>
<p>到止为止，最复杂最麻烦的过程已经结束了。剩下的就是体验Docker Swarm带来的便利了。</p>
<h2 id="创建测试程序"><a href="#创建测试程序" class="headerlink" title="创建测试程序"></a>创建测试程序</h2><h3 id="搭建测试Redis"><a href="#搭建测试Redis" class="headerlink" title="搭建测试Redis"></a>搭建测试Redis</h3><p>由于这里需要模拟一个分布式爬虫的运行效果，所以先使用Docker搭建一个临时的Redis服务：</p>
<p>在Master服务器上执行以下命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker run -d --name redis -p 7891:6379 redis --requirepass &quot;KingnameISHandSome8877&quot;</div></pre></td></tr></table></figure>
<p>这个Redis对外使用<code>7891</code>端口，密码为<code>KingnameISHandSome8877</code>，IP就是Master服务器的IP地址。</p>
<h3 id="编写测试程序"><a href="#编写测试程序" class="headerlink" title="编写测试程序"></a>编写测试程序</h3><p>编写一个简单的Python程序：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> time</div><div class="line"><span class="keyword">import</span> redis</div><div class="line"></div><div class="line"></div><div class="line">client = redis.Redis(host=<span class="string">'45.77.138.242'</span>, port=<span class="string">'7891'</span>, password=<span class="string">'KingnameISHandSome8877'</span>)</div><div class="line"></div><div class="line"><span class="keyword">while</span> <span class="keyword">True</span>:</div><div class="line">    data = client.lpop(<span class="string">'example:swarm:spider'</span>)</div><div class="line">    <span class="keyword">if</span> <span class="keyword">not</span> data:</div><div class="line">        <span class="keyword">break</span></div><div class="line">    print(f<span class="string">'我现在获取的数据为：&#123;data.decode()&#125;'</span>)</div><div class="line">    time.sleep(<span class="number">10</span>)</div></pre></td></tr></table></figure>
<p>这个Python每10秒钟从Redis中读取一个数，并打印出来。</p>
<h3 id="编写Dockerfile"><a href="#编写Dockerfile" class="headerlink" title="编写Dockerfile"></a>编写Dockerfile</h3><p>编写Dockerfile，基于Python3.6的镜像创建我们自己的镜像：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">from python:3.6</div><div class="line">label mantainer=&apos;contact@kingname.info&apos;</div><div class="line"></div><div class="line">user root</div><div class="line">ENV PYTHONUNBUFFERED=0</div><div class="line">ENV PYTHONIOENCODING=utf-8</div><div class="line"></div><div class="line">run python3 -m pip install redis</div><div class="line"></div><div class="line">copy spider.py spider.py</div><div class="line">cmd python3 spider.py</div></pre></td></tr></table></figure>
<h3 id="构建镜像"><a href="#构建镜像" class="headerlink" title="构建镜像"></a>构建镜像</h3><p>编写完成Dockerfile以后，执行下面的命令，开始构建我们自己的镜像：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker build -t localhost:8003/spider:0.01 .</div></pre></td></tr></table></figure>
<p>这里需要特别注意，由于我们要把这个镜像上传到私有源供Slave服务器上面的从节点下载，所以镜像的命名方式需要满足<code>localhost:8003/自定义名字:版本号</code>这样的格式。其中的<code>自定义名字</code>和<code>版本号</code>可以根据实际情况进行修改。在本文的例子中，我由于要模拟一个爬虫的程序，所以给它取名为spider，由于是第1次构建，所以版本号用的是0.01。</p>
<p>整个过程如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/docker_swarm_10.png" alt=""></p>
<h3 id="上传镜像到私有源"><a href="#上传镜像到私有源" class="headerlink" title="上传镜像到私有源"></a>上传镜像到私有源</h3><p>镜像构建完成以后，需要把它上传到私有源。此时需要执行命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker push localhost:8003/spider:0.01</div></pre></td></tr></table></figure>
<p>如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/docker_swarm_11.png" alt=""></p>
<p>大家记住这个构建和上传的命令，以后每一次更新代码，都需要使用这两条命令。</p>
<h2 id="创建服务"><a href="#创建服务" class="headerlink" title="创建服务"></a>创建服务</h2><p>Docker Swarm上面运行的是一个一个的服务，因此需要使用docker service命令创建服务。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker service create --name spider --network host 45.77.138.242:8003/spider:0.01</div></pre></td></tr></table></figure>
<p>这个命令创建了一个名为<code>spider</code>的服务。默认运行1个容器。运行情况如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/docker_swarm_12.png" alt=""></p>
<p>当然也可以一创建就用很多容器来运行，此时只需要添加一个<code>--replicas</code>参数即可。例如一创建服务就使用50个容器运行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker service create --name spider --replicas 50 --network host 45.77.138.242:8003/spider:0.01</div></pre></td></tr></table></figure>
<p>但是一般一开始的代码可能会有不少bug，所以建议先使用1个容器来运行，观察日志，发现没有问题以后再进行扩展。</p>
<p>回到默认1个容器的情况下，这个容器可能在目前三台机器在的任何一台上面。通过执行下面的命令来观察这一个默认的容器运行情况：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker service ps spider</div></pre></td></tr></table></figure>
<p>如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/docker_swarm_13.png" alt=""></p>
<h2 id="查看节点Log"><a href="#查看节点Log" class="headerlink" title="查看节点Log"></a>查看节点Log</h2><p>根据上图执行结果，可以看到这个运行中的容器的ID为<code>rusps0ofwids</code>，那么执行下面的命令动态查看Log：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker service logs -f 容器ID</div></pre></td></tr></table></figure>
<p>此时就会持续跟踪这一个容器的Log。如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/docker_swarm_14.png" alt=""></p>
<h2 id="横向扩展"><a href="#横向扩展" class="headerlink" title="横向扩展"></a>横向扩展</h2><p>现在，只有1台服务器运行了一个容器，我想使用3台服务器运行这个爬虫，那么我需要执行一条命令即可：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker service scale spider=3</div></pre></td></tr></table></figure>
<p>运行效果如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/docker_swarm_15.png" alt=""></p>
<p>此时，再一次查看爬虫的运行情况，可以发现三台机器上面会各自运行一个容器。如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/docker_swarm_16.png" alt=""></p>
<p>现在，我们登录slave-1机器上，看看是不是真的有一个任务在运行。如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/docker_swarm_17.png" alt=""></p>
<p>可以看到确实有一个容器在上面运行着。这是Docker Swarm自动分配过来的。</p>
<p>现在我们使用下面的命令强行把slave-1上面的Docker给关了，再来看看效果。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">systemctl stop docker</div></pre></td></tr></table></figure>
<p>回到master服务器，再次查看爬虫的运行效果，如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/docker_swarm_18.png" alt=""></p>
<p>可以看到，Docker Swarm探测到Slave-1掉线以后，他就会自动重新找个机器启动任务，保证始终有3个任务在运行。在这一次的例子中，Docker Swarm自动在master机器上启动了2个spider容器。</p>
<p>如果机器性能比较好，甚至可以在3每台机器上面多运行几个容器：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker service scale spider=10</div></pre></td></tr></table></figure>
<p>此时，就会启动10个容器来运行这些爬虫。这10个爬虫之间互相隔离。</p>
<p>如果想让所有爬虫全部停止怎么办？非常简单，一条命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker service scale spider=0</div></pre></td></tr></table></figure>
<p>这样所有爬虫就会全部停止。</p>
<h2 id="同时查看多个容器的日志"><a href="#同时查看多个容器的日志" class="headerlink" title="同时查看多个容器的日志"></a>同时查看多个容器的日志</h2><p>如果想同时看所有容器怎么办呢？可以使用如下命令查看所有容器的最新的20行日志：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker service ps robot | grep Running | awk &apos;&#123;print $1&#125;&apos; | xargs -i docker service logs --tail 20 &#123;&#125;</div></pre></td></tr></table></figure>
<p>这样，日志就会按顺序显示出来了。如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/docker_swarm_19.png" alt=""></p>
<h2 id="更新爬虫"><a href="#更新爬虫" class="headerlink" title="更新爬虫"></a>更新爬虫</h2><p>如果你的代码做了修改。那么你需要更新爬虫。</p>
<p>先修改代码，重新构建，重新提交新的镜像到私有源中。如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/docker_swarm_20.png" alt=""></p>
<p>接下来需要更新服务中的镜像。更新镜像有两种做法。一种是先把所有爬虫关闭，再更新。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">docker service scale spider=0</div><div class="line">docker service update --image 45.77.138.242:8003/spider:0.02 spider</div><div class="line">docker service scale spider=3</div></pre></td></tr></table></figure>
<p>第二种是直接执行更新命令。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker service update --image 45.77.138.242:8003/spider:0.02 spider</div></pre></td></tr></table></figure>
<p>他们的区别在于，直接执行更新命令时，正在运行的容器会一个一个更新。</p>
<p>运行效果如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/docker_swarm_21.png" alt=""></p>
<h2 id="你可以用Docker-Swarm做更多事情"><a href="#你可以用Docker-Swarm做更多事情" class="headerlink" title="你可以用Docker Swarm做更多事情"></a>你可以用Docker Swarm做更多事情</h2><p>本文使用的是一个模拟爬虫的例子，但是显然，任何可以批量运行的程序都能够用Docker Swarm来运行，无论你用Redis还是Celery来通信，无论你是否需要通信，只要能批量运行，就能用Docker Swarm。</p>
<p>在同一个Swarm集群里面，可以运行多个不同的服务，各个服务之间互不影响。真正做到了搭建一次Docker Swarm集群，然后就再也不用管了，以后的所有操作你都只需要在Manager节点所在的这个服务器上面运行。</p>
<h2 id="广告时间"><a href="#广告时间" class="headerlink" title="广告时间"></a>广告时间</h2><p>本文是多种部署分布式爬虫方法中的一种，其他方法，可以参阅我的新书《Python爬虫开发 从入门到实战》。现已在京东、当当、亚马逊上架。</p>
<ul>
<li>京东：<a href="https://item.jd.com/12436581.html" target="_blank" rel="external">https://item.jd.com/12436581.html</a></li>
<li>当当：<a href="http://product.m.dangdang.com/25349717.html" target="_blank" rel="external">http://product.m.dangdang.com/25349717.html</a></li>
<li>亚马逊：<a href="https://www.amazon.cn/dp/B07HGBRXFW" target="_blank" rel="external">https://www.amazon.cn/dp/B07HGBRXFW</a></li>
</ul>
<p>本书读者交流群也已经开通，扫码添加公众号，回复：读者交流 即可获得加群方式。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/wechatplatform.jpg" alt=""></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在爬虫开发过程中，你肯定遇到过需要把爬虫部署在多个服务器上面的情况。此时你是怎么操作的呢？逐一SSH登录每个服务器，使用git拉下代码，然后运行？代码修改了，于是又要一个服务器一个服务器登录上去依次更新？&lt;/p&gt;
&lt;p&gt;有时候爬虫只需要在一个服务器上面运行，有时候需要在200个服务器上面运行。你是怎么快速切换的呢？一个服务器一个服务器登录上去开关？或者聪明一点，在Redis里面设置一个可以修改的标记，只有标记对应的服务器上面的爬虫运行？&lt;/p&gt;
&lt;p&gt;A爬虫已经在所有服务器上面部署了，现在又做了一个B爬虫，你是不是又得依次登录每个服务器再一次部署？&lt;/p&gt;
&lt;p&gt;如果你确实是这么做的，那么你应该后悔没有早一点看到这篇文章。看完本文以后，你能够做到：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;2分钟内把一个新爬虫部署到50台服务器上：&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;docker build -t localhost:8003/spider:0.01 .&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;docker push localhost:8002/spider:0.01&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;docker service create --name spider --replicas 50 --network host 45.77.138.242:8003/spider:0.01&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;30秒内把爬虫从50台服务器扩展到500台服务器：&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;docker service scale spider=500&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;30秒内批量关闭所有服务器上的爬虫：&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;docker service scale spider=0&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;1分钟内批量更新所有机器上的爬虫：&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;docker build -t localhost:8003/spider:0.02 .&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;docker push localhost:8003/spider:0.02&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;docker service update --image 45.77.138.242:8003/spider:0.02 spider&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="Docker" scheme="https://www.kingname.info/categories/Docker/"/>
    
    
      <category term="Docker" scheme="https://www.kingname.info/tags/Docker/"/>
    
      <category term="Swarm" scheme="https://www.kingname.info/tags/Swarm/"/>
    
  </entry>
  
  <entry>
    <title>如果你不知道做什么，那就学一门杂学吧</title>
    <link href="https://www.kingname.info/2018/10/01/my-new-book/"/>
    <id>https://www.kingname.info/2018/10/01/my-new-book/</id>
    <published>2018-10-01T10:31:11.000Z</published>
    <updated>2018-10-30T16:24:19.818Z</updated>
    
    <content type="html"><![CDATA[<h2 id="序言"><a href="#序言" class="headerlink" title="序言"></a>序言</h2><p>这篇文章没有代码，请放心阅读。</p>
<p>多年以后，面对人工智能研究员那混乱不堪的代码，我会想起第一次和S君相见的那个遥远的下午。那时的B公司，还是一个仅有6个人的小团队，Mac和显示器在桌上依次排开，大家坐在一起，不需要称呼姓名，转过脸去，对方就知道你在和他说话。一切看起来都那么美好，我们所有人，都希望自己和这个公司能够一起成长。</p>
<p>彼时S君刚从加拿大回来，老板把他介绍给我们，于是S君作为数据产品经理跟我有了项目上的接触。</p>
<p>创业公司里面，每一个人都需要会很多的技艺，于是S君开始自学Python。</p>
<p>有一天，S君问我：“你玩MineCraft吗？“</p>
<p>“玩，但我更喜欢在B站上看别人的世界。”我答道。</p>
<p>“我觉得我现在写程序，像是在玩我的世界。”S君笑着说道。</p>
<p>“是不是觉得你已经掌握了Python的基本语法，看着别人把Python用的溜溜转，而你自己却不知道用它来做什么？”</p>
<p>“是这样的，你懂我。”</p>
<p>“那你学一门杂学吧。”</p>
<p>于是S君被我诱拐过来跟我一起写爬虫。</p>
<p>后来，S君离开了B公司。</p>
<p>三个月后，我也离开了。</p>
<p>从此，我们再也没有见过。</p>
<a id="more"></a>
<h2 id="编程最重要的能力是变通"><a href="#编程最重要的能力是变通" class="headerlink" title="编程最重要的能力是变通"></a>编程最重要的能力是变通</h2><p>S君是一个老实孩子。</p>
<p>在开发一个爬虫的过程中，网站接口返回给他的数据看起来是JSON格式，于是他就用Python自带的JSON库去解析。结果解析失败了。因为这些所谓的看起来像JSON的东西，竟然没有双引号。</p>
<p>难道是JSON的超集？S君一通搜索，发现用YMAL库也许可以解析这种数据。于是安装YMAL库，一解析又报错。</p>
<p>难道这些数据直接就是Python的字典？于是S君用上了邪恶的eval。又报错，因为里面有null和小写的true。</p>
<p>“你为什么不试一试直接用正则表达式呢？”我对S君说。</p>
<p>“靠！”S君一拍桌子，旁边的老板吓得把搪瓷杯子里面的快乐水洒在了白衬衣上。</p>
<p>然后S君用正则表达式花了10秒钟结束了战斗。</p>
<h2 id="写爬虫与三峡大坝"><a href="#写爬虫与三峡大坝" class="headerlink" title="写爬虫与三峡大坝"></a>写爬虫与三峡大坝</h2><p>有一天，S君兴冲冲地跑来跟我说：“我体会到三峡大坝的伟大功能了！”</p>
<p>“你是爬虫工程师还是水利工程师？”</p>
<p>“你知道吗，不管上游的水势多么凶猛，从大坝出来以后总是安全而稳定。”S君并没有回答我的问题，而是自顾自地说道。</p>
<p>“原来你开始用Kafka。不错，孺子可教。”</p>
<p>S君吐了一下舌头：“还是师傅教导有方。”</p>
<p>前不久，S君的爬虫刚刚达到了日产数据千万条的目标。然而他只高兴了一天。因为他发现，数据写到数据库以后，读起来很麻烦。</p>
<p>S君有多个数据分析的系统需要从数据库里面读取爬虫爬好的数据，但是从每天千万量级的数据中寻找特定的数据是一个很慢的过程。如果程序遇到异常导致崩溃，又得从头开始读。</p>
<p>S君问我：“现在我每一个数据分析的脚本都要从数据库里面读一次数据，做了太多重复的工作，单机单节点的数据库快要撑不住了。我是不是要去学习分库分表搭建集群啊？”</p>
<p>我告诉S君：“这个后面你自然是需要去做的。但现在，你可以先试一试Kafka，我已经搭建好了一个Kafka的集群了，你这样使用……”。</p>
<p>后来，S君让所有爬虫把爬到的数据到直接送进了Kafka，然后再从Kafka里面读数据出来，一个Group用来备份原始数据，一份Group用来生成中间表，一份Group用来监控报警，一份Group用来绘制DashBoard。无论爬虫塞给Kafka的数据有多少，有多快，从Kafka读数据的地方都能按照自己的节奏来消费和使用。</p>
<h2 id="既然收集了数据就要让它发光发热"><a href="#既然收集了数据就要让它发光发热" class="headerlink" title="既然收集了数据就要让它发光发热"></a>既然收集了数据就要让它发光发热</h2><p>S君在加拿大留学时学的专业是金融数学和统计。所以他对数据分析也很有兴趣。在他爬虫收集的数据够用以后，我跟他讲了如何使用Pandas来分析数据。</p>
<p>S君把他分析的酒店价格变化数据给分享给了我们。不愧是金融+数学+统计学背景的高级知识分子 + 超级强大的Pandas + 超级好用的Jupyter。这份数据不仅完美再现了过去一年的价格走势，还预测了未来的任何变化，多达四十六张图表似乎穷尽了所有的组合。</p>
<h2 id="草木竹石皆可破敌"><a href="#草木竹石皆可破敌" class="headerlink" title="草木竹石皆可破敌"></a>草木竹石皆可破敌</h2><p>S君曾经遇到过一个特别简单的电商网站。页面几乎像素级抄袭淘宝，但是完全没有任何反爬虫的机制。以S君的水平，从审查元素，到开发完成，仅仅用了半个小时。爬虫安全平稳又顺利地运行了三个星期。</p>
<p>然后，有一天早上，爬虫死掉了。</p>
<p>S君用尽毕生所学，无法再从这个网站上爬到任何有价值的信息。这个网站似乎请来了一个机器行为对抗的大神级人物。人用浏览器一点问题都没有，但S君的任何隐藏爬虫的手段都被轻易识破。</p>
<p>S君找到我：“师傅，这个网站我搞不定。”</p>
<p>“你能搞定。动动脑子。”</p>
<p>“我会的所有技术都用上了，完全看不出破解他反爬虫机制的方法。”S君已经失去了信心。</p>
<p>“那就，不要用技术去对抗。用你的脑子。”</p>
<p>S君抱着显示器用头一遍一遍的撞。</p>
<p>我问S君：“你有没有思考一个问题，这个网站模仿了淘宝的皮，却又毫无反爬虫机制。你觉得他的老板是一个什么样的人？你听过那个段子吗？”</p>
<p>S君突然一跃而起：“我给你一万元，你帮我做一个网站吧。你想要什么样的网站？很简单，就淘宝那样的。你是说这个段子吗？”</p>
<p>“对。”</p>
<p>S君突然之间荣光焕发：“有办法了！”</p>
<p>只见S君重新在浏览器打开了这个网站，找到了客户服务热线。电话一拨通他就开始一通污言秽语骂起来：“……你们网站到底在搞什么？为什么今天一会能登录一会不能登录？找你们老板来！我来教他怎么做网站！……”</p>
<p>半小时以后，网站反爬虫机制全部解除。</p>
<p>此刻，S君面向西面双手合十，自言自语：“兄弟，对不起了，只有让你来背这个锅了。”</p>
<h2 id="你小学上课传过纸条吗"><a href="#你小学上课传过纸条吗" class="headerlink" title="你小学上课传过纸条吗"></a>你小学上课传过纸条吗</h2><p>“我现在能体会那些半路拦截纸条的人是什么心态了。”这是S君第一次使用Charles时对我说的话。</p>
<p>从此以后，我很少看到S君分析网页了。因为他学会了在爬虫开发的过程中，首先通过中间人攻击技术分析微信小程序和手机App。这种方式往往能够直接获得数据，拿到数据以后就能直接储存，再也不用写烦人的XPath或者长的跟表情符号一样的正则表达式了。</p>
<p>有一天，我在玩一个网页版的黑客解密游戏，在网页上寻找某个地方隐藏起来的密码，然后输入每一关的回答框中，答对才能进入下一关。</p>
<p>游戏有12关，而我卡在了第6关。只见S君拿着电脑走到我面前，指着第12关的通关页面跟我炫耀。</p>
<p>“你是不是用MITMProxy替换了这个网站的Js文件？”</p>
<p>“果然还是瞒不过师傅你啊。”</p>
<p>“你拦截了别人的纸条，做了修改，然后又叠好继续传下去，你有考虑过发纸条的人和收纸条的人的感受吗？”</p>
<p>“我小学时候不传纸条，都是妹子直接约我的。”</p>
<h2 id="加密？不存在的"><a href="#加密？不存在的" class="headerlink" title="加密？不存在的"></a>加密？不存在的</h2><p>“前端没有秘密”。S君在成功逆向了一个网站的Js文件以后如是对我说。</p>
<p>“那是因为这个网站的Js代码就赤裸裸地放在你面前，完全没有混淆。”我对S君说道。</p>
<p>“不怕，我可以用Node.js来运行混淆过的代码。我已经搭建好Node.js服务了，只要把Js代码传进去，他就会把结果给我返回回来。”S君对此似乎一脸自行。</p>
<p>“你什么时候学会的Node.js？”</p>
<p>“这不是师傅你说过技多不压身吗？既然做爬虫需要动JavaScript，那我顺手就把Node.js给学了。”S君毫不畏惧的表情，似乎证明他已经猜透了我要问什么。</p>
<p>“那如果目标没有网站，只有App呢？”</p>
<p>“不怕，Android 逆向工程我也顺便研究了一点。Java我也看得懂。”</p>
<p>“看来这些已经不需要我再教你了。”</p>
<h2 id="我一根指头就能捏死你，但我不想伤害你"><a href="#我一根指头就能捏死你，但我不想伤害你" class="headerlink" title="我一根指头就能捏死你，但我不想伤害你"></a>我一根指头就能捏死你，但我不想伤害你</h2><p>S君有一天问我：“假设你现在在小学课堂上，前面的同学让你把纸条传给后面的女生，你会怎么做？”</p>
<p>我说：“查看复制/修改删除/拦截丢弃”。</p>
<p>S君嘿嘿一笑：“比如说，前后三次的纸条分别为‘听说你奶奶生病了，我们周末一起去看望她吧‘，’今晚我爸妈不在，去我家玩吗？’， ‘我刚拿到这个月压岁钱，老师一下课我们就去吃好吃的。’”</p>
<p>我说：“女孩漂亮的话，我改一下第二张纸条，改成‘今晚我爸妈不在，我们一起去青南家玩吗？’”。</p>
<p>S君露出了嫌弃的眼神：“师傅，你可是说过你最讨厌技术含量低的事情啊，你涂改了纸条，别人不会发现？你笔迹都不一样啊！”。</p>
<p>我问S君：“那你有何高见？”</p>
<p>S君抬头仰望这窗外的天空：“如果是我，那么我会临摹第一张纸条上面的<code>生病了</code> <code>去看望</code> <code>她</code> <code>我</code>，第二张纸条上面的<code>爸妈</code>，第三张纸条上面的<code>拿</code> <code>钱</code> <code>老师</code>这些字的笔迹。然后改换一下顺序就变成了：<code>爸妈，我老师生病了，我拿钱去看望她</code>。最后我把这张伪造的纸条拿去找写纸条的那个同学他爸妈要钱。”</p>
<p>“我猜，你想用中间人攻击截取别人的Cookies，然后用这些Cookies偷偷登录网站，进行你的不可告人的目的。”</p>
<p>S君笑道：“哈哈哈，我想想都害怕。但是每当我想到，我拥有一种可怕的力量，而我还能控制住这种力量。我就知道我和街上的普通人不一样了。”</p>
<h2 id="你肯定薅了直播答题的羊毛吧"><a href="#你肯定薅了直播答题的羊毛吧" class="headerlink" title="你肯定薅了直播答题的羊毛吧"></a>你肯定薅了直播答题的羊毛吧</h2><p>去年年底的直播答题着实火了一把。那个时候，我和S君分开已经有一段时间了。我相信，在全民答题的每一个夜晚，S君的电脑上一定连着不少于六台安卓手机。这些手机运行着不同的答题平台，能够自动读取屏幕上的问题并自动选择答案。</p>
<p>我把安卓自动化测试技术教给S君，本来是让他结合爬虫，实现群控从而抓取一些难以处理的数据，但我相信他肯定会用来答题。</p>
<p>变通，这一点他学的越来越好了。</p>
<p>只希望他不要成为羊毛党。</p>
<h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>后来，我再也没有见过S君这样有趣的人。所以我把我教给S君的东西，写成了一本书：《Python爬虫开发 从入门到实战》，现在已在京东，当当与亚马逊上架。希望你也能变成S君一样有趣而又厉害的人。</p>
<ul>
<li>京东：<a href="https://item.jd.com/12436581.html" target="_blank" rel="external">https://item.jd.com/12436581.html</a></li>
<li>当当：<a href="http://product.m.         dangdang.com/25349717.html" target="_blank" rel="external">http://product.m.dangdang.com/25349717.html</a></li>
<li>亚马逊：<a href="https://www.amazon.cn/dp/       B07HGBRXFW" target="_blank" rel="external">https://www.amazon.cn/dp/B07HGBRXFW</a></li>
</ul>
<p>爬虫是一门杂学。因为在一个完整的开发过程中，需要涉及到的知识可以包括但不限于：Python，HTML，JavaScript，正则表达式，XPath，数据库，Redis，消息队列，Docker，ELK，Hadoop，数据分析，ETL，中间人攻击，自动化测试技术，可视化……</p>
<p>这其中的任何一项，在一个大公司里面都可以让很多人来做。</p>
<p>爬虫开发，就像这篇文章里面反复出现的一个词：变通——只要能够获得数据，任何技术都可以使用。所谓草木竹石皆可为剑。爬虫不应该是一个枯燥的一成不变的模式化的工作。而是一个充满了创意和挑战，能够让旁观者大呼“我X还能这样搞”的工作。</p>
<p>爬虫开发，绝对不仅仅是Scrapy，PySpider，requests这些框架或者库的使用。所以在这本书里面，我也刻意减少了框架使用说明的部分，而把重点放在了各种突破反爬虫机制或者使用变通的方法绕过反爬虫机制的方法论和实践中。</p>
<p>通过学习爬虫，你最后不一定选择爬虫工程师这个岗位，但是在学习爬虫的过程中，你将会接触到的各种工具，方法，服务组件，都会在你以后的生活和工作中帮到你，让你知道，在遇到一个问题的时候，解决方法在哪个地方。</p>
<p>**</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;序言&quot;&gt;&lt;a href=&quot;#序言&quot; class=&quot;headerlink&quot; title=&quot;序言&quot;&gt;&lt;/a&gt;序言&lt;/h2&gt;&lt;p&gt;这篇文章没有代码，请放心阅读。&lt;/p&gt;
&lt;p&gt;多年以后，面对人工智能研究员那混乱不堪的代码，我会想起第一次和S君相见的那个遥远的下午。那时的B公司，还是一个仅有6个人的小团队，Mac和显示器在桌上依次排开，大家坐在一起，不需要称呼姓名，转过脸去，对方就知道你在和他说话。一切看起来都那么美好，我们所有人，都希望自己和这个公司能够一起成长。&lt;/p&gt;
&lt;p&gt;彼时S君刚从加拿大回来，老板把他介绍给我们，于是S君作为数据产品经理跟我有了项目上的接触。&lt;/p&gt;
&lt;p&gt;创业公司里面，每一个人都需要会很多的技艺，于是S君开始自学Python。&lt;/p&gt;
&lt;p&gt;有一天，S君问我：“你玩MineCraft吗？“&lt;/p&gt;
&lt;p&gt;“玩，但我更喜欢在B站上看别人的世界。”我答道。&lt;/p&gt;
&lt;p&gt;“我觉得我现在写程序，像是在玩我的世界。”S君笑着说道。&lt;/p&gt;
&lt;p&gt;“是不是觉得你已经掌握了Python的基本语法，看着别人把Python用的溜溜转，而你自己却不知道用它来做什么？”&lt;/p&gt;
&lt;p&gt;“是这样的，你懂我。”&lt;/p&gt;
&lt;p&gt;“那你学一门杂学吧。”&lt;/p&gt;
&lt;p&gt;于是S君被我诱拐过来跟我一起写爬虫。&lt;/p&gt;
&lt;p&gt;后来，S君离开了B公司。&lt;/p&gt;
&lt;p&gt;三个月后，我也离开了。&lt;/p&gt;
&lt;p&gt;从此，我们再也没有见过。&lt;/p&gt;
    
    </summary>
    
      <category term="Python" scheme="https://www.kingname.info/categories/Python/"/>
    
    
      <category term="Python" scheme="https://www.kingname.info/tags/Python/"/>
    
      <category term="爬虫" scheme="https://www.kingname.info/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="学习方法" scheme="https://www.kingname.info/tags/%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>正则表达式re.sub替换不完整的问题现象及其根本原因</title>
    <link href="https://www.kingname.info/2018/08/27/re-sandthepositionofparaminsub/"/>
    <id>https://www.kingname.info/2018/08/27/re-sandthepositionofparaminsub/</id>
    <published>2018-08-27T13:48:22.000Z</published>
    <updated>2018-09-25T13:33:27.443Z</updated>
    
    <content type="html"><![CDATA[<h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>问题的起因来自于一段正则替换。为了从一段HTML代码里面提取出正文，去掉所有的HTML标签和属性，可以写一个Python函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> re</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">remove_tag</span><span class="params">(html)</span>:</span></div><div class="line">    text = re.sub(<span class="string">'&lt;.*?&gt;'</span>, <span class="string">''</span>, html, re.S)</div><div class="line">    <span class="keyword">return</span> text</div></pre></td></tr></table></figure>
<p>这段代码的使用了正则表达式的替换功能<code>re.sub</code>。这个函数的第一个参数表示需要被替换的内容的正则表达式，由于HTML标签都是使用尖括号包起来的，因此使用<code>&lt;.*?&gt;</code>就可以匹配所有<code>&lt;xxx yyy=&quot;zzz&quot;&gt;</code>和<code>&lt;/xxx&gt;</code>。</p>
<p>第二个参数表示被匹配到的内容将要被替换成什么内容。由于我需要提取正文，那么只要把所有HTML标签都替换为空字符串即可。第三个参数就是需要被替换的文本，在这个例子中是HTML源代码段。</p>
<p>至于<code>re.S</code>，在4年前的一篇文章中我讲到了它的用法：<a href="https://www.kingname.info/2014/12/21/Python%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E4%B8%AD%E7%9A%84re-S/">Python正则表达式中的re.S</a>。</p>
<p>现在使用一段HTML代码来测试一下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> re</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">remove_tag</span><span class="params">(html)</span>:</span></div><div class="line">    text = re.sub(<span class="string">'&lt;.*?&gt;'</span>, <span class="string">''</span>, html, re.S)</div><div class="line">    <span class="keyword">return</span> text</div><div class="line"></div><div class="line"></div><div class="line">source_1 = <span class="string">'''</span></div><div class="line">&lt;div class="content"&gt;今天的主角是&lt;a href="xxx"&gt;kingname&lt;/a&gt;，我们掌声欢迎！&lt;/div&gt;</div><div class="line">'''</div><div class="line"></div><div class="line"></div><div class="line">text = remove_tag(source_1)</div><div class="line">print(text)</div></pre></td></tr></table></figure>
<p>运行效果如下图所示，功能完全符合预期</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-08-27-22-22-54.png" alt=""></p>
<p>再来测试一下代码中有换行符的情况：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> re</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">remove_tag</span><span class="params">(html)</span>:</span></div><div class="line">    text = re.sub(<span class="string">'&lt;.*?&gt;'</span>, <span class="string">''</span>, html, re.S)</div><div class="line">    <span class="keyword">return</span> text</div><div class="line"></div><div class="line">source_2 = <span class="string">'''</span></div><div class="line">&lt;div class="content"&gt;</div><div class="line">    今天的主角是</div><div class="line">    &lt;a href="xxx"&gt;kingname&lt;/a&gt;</div><div class="line">    ，我们掌声欢迎！</div><div class="line">&lt;/div&gt;</div><div class="line">'''</div><div class="line">text = remove_tag(source_2)</div><div class="line">print(text)</div></pre></td></tr></table></figure>
<p>运行效果如下图所示，完全符合预期。<br><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-08-27-22-25-29.png" alt=""></p>
<p>经过测试，在绝大多数情况下，能够从的HTML代码段中提取出正文。但也有例外。</p>
<a id="more"></a>
<h2 id="例外情况"><a href="#例外情况" class="headerlink" title="例外情况"></a>例外情况</h2><p>有一段HTML代码段比较长，内容如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&lt;img&gt;&lt;/span&gt;&lt;span&gt;遇见kingname&lt;/span&gt;&lt;/a &gt;&lt;a  &gt;&lt;span class=&apos;url-icon&apos;&gt;&lt; img &apos;&gt;&lt;/span&gt;&lt;span &gt;温柔&lt;/span&gt;&lt;/a &gt;&lt;a  &gt;&lt;span &gt;#青南#&lt;/span&gt;&lt;/a &gt; &lt;br /&gt;就在这里…&lt;br /&gt;我的小侯爷呢？？？</div></pre></td></tr></table></figure>
<p>运行效果如下图所示，最后两个HTML标签替换失败。<br><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-08-27-22-31-59.png" alt=""></p>
<p>一开始我以为是HTML里面的空格或者引号引起的问题，于是我把HTML代码进行简化：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&lt;img&gt;&lt;/span&gt;&lt;span&gt;遇见kingname&lt;/span&gt;&lt;/a&gt;&lt;a&gt;&lt;span&gt;&lt;img&gt;&lt;/span&gt;&lt;span&gt;温柔&lt;/span&gt;&lt;/a&gt;&lt;a&gt;&lt;span&gt;#青南#&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;就在这里…&lt;br/&gt;我的小侯爷呢</div></pre></td></tr></table></figure>
<p>问题依然存在，如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-08-27-22-36-14.png" alt=""></p>
<p>而且更令人惊讶的是，如果把第一个标签<code>&lt;img&gt;</code>删了，那么替换结果里面就少了一个标签，如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-08-27-22-45-09.png" alt=""></p>
<p>实际上，不仅仅是删除第一个标签，前面任意一个标签删了都可以减少结果里面的一个标签。如果删除前面两个或以上标签，那么结果就正常了。</p>
<h2 id="答疑解惑"><a href="#答疑解惑" class="headerlink" title="答疑解惑"></a>答疑解惑</h2><p>这个看起来很奇怪的问题，根本原因在re.sub的第4个参数。从函数原型可以看到：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">def sub(pattern, repl, string, count=0, flags=0)</div></pre></td></tr></table></figure>
<p>第四个参数是count表示替换个数，re.S如果要用，应该作为第五个参数。所以如果把<code>remove_tag</code>函数做一些修改，那么结果就正确了:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">def remove_tag(html):</div><div class="line">    text = re.sub(&apos;&lt;.*?&gt;&apos;, &apos;&apos;, html, flags=re.S)</div><div class="line">    return text</div></pre></td></tr></table></figure>
<p>那么问题来了，把re.S放在count的位置，为什么代码没有报错？难道<code>re.S</code>是数字？实际上，如果打印一下就会发现，<code>re.S</code>确实可以作为数字：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; import re</div><div class="line">&gt;&gt;&gt; print(int(re.S))</div><div class="line">16</div></pre></td></tr></table></figure>
<p>现在回头数一数出问题的HTML代码，发现最后多出来的两个<code>&lt;br&gt;</code>标签，刚刚好是第17和18个标签，而由于<code>count</code>填写的<code>re.S</code>可以当做16来处理，那么Python就会把前16个标签替换为空字符串，从而留下最后两个。</p>
<p>至此问题的原因搞清楚了。</p>
<p>这个问题没有被及早发现，有以下几个原因：</p>
<ol>
<li>被替换的HTML代码是代码段，大多数情况下HTML标签不足16个，所以问题被隐藏。</li>
<li><code>re.S</code>是一个对象，但也是数字，count接收的参数刚好也是数字。在很多编程语言里面，常量都会使用数字，然后用一个有意义的大写字母来表示。</li>
<li><code>re.S</code> 处理的情况是<code>&lt;div class=&quot;123&quot; \n&gt;</code> 而不是<code>&lt;div class=&quot;123&quot;&gt;\n&lt;/div&gt;</code>但测试的代码段标签都是第二种情况，所以在代码段里面实际上加不加<code>re.S</code>效果是一样的。</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;问题描述&quot;&gt;&lt;a href=&quot;#问题描述&quot; class=&quot;headerlink&quot; title=&quot;问题描述&quot;&gt;&lt;/a&gt;问题描述&lt;/h2&gt;&lt;p&gt;问题的起因来自于一段正则替换。为了从一段HTML代码里面提取出正文，去掉所有的HTML标签和属性，可以写一个Python函数：&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; re&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;remove_tag&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(html)&lt;/span&gt;:&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    text = re.sub(&lt;span class=&quot;string&quot;&gt;&#39;&amp;lt;.*?&amp;gt;&#39;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&#39;&#39;&lt;/span&gt;, html, re.S)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; text&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;这段代码的使用了正则表达式的替换功能&lt;code&gt;re.sub&lt;/code&gt;。这个函数的第一个参数表示需要被替换的内容的正则表达式，由于HTML标签都是使用尖括号包起来的，因此使用&lt;code&gt;&amp;lt;.*?&amp;gt;&lt;/code&gt;就可以匹配所有&lt;code&gt;&amp;lt;xxx yyy=&amp;quot;zzz&amp;quot;&amp;gt;&lt;/code&gt;和&lt;code&gt;&amp;lt;/xxx&amp;gt;&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;第二个参数表示被匹配到的内容将要被替换成什么内容。由于我需要提取正文，那么只要把所有HTML标签都替换为空字符串即可。第三个参数就是需要被替换的文本，在这个例子中是HTML源代码段。&lt;/p&gt;
&lt;p&gt;至于&lt;code&gt;re.S&lt;/code&gt;，在4年前的一篇文章中我讲到了它的用法：&lt;a href=&quot;https://www.kingname.info/2014/12/21/Python%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E4%B8%AD%E7%9A%84re-S/&quot;&gt;Python正则表达式中的re.S&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;现在使用一段HTML代码来测试一下：&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;11&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;12&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;13&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;14&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;15&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; re&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;remove_tag&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(html)&lt;/span&gt;:&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    text = re.sub(&lt;span class=&quot;string&quot;&gt;&#39;&amp;lt;.*?&amp;gt;&#39;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&#39;&#39;&lt;/span&gt;, html, re.S)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; text&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;source_1 = &lt;span class=&quot;string&quot;&gt;&#39;&#39;&#39;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;lt;div class=&quot;content&quot;&amp;gt;今天的主角是&amp;lt;a href=&quot;xxx&quot;&amp;gt;kingname&amp;lt;/a&amp;gt;，我们掌声欢迎！&amp;lt;/div&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&#39;&#39;&#39;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;text = remove_tag(source_1)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;print(text)&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;运行效果如下图所示，功能完全符合预期&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-08-27-22-22-54.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;再来测试一下代码中有换行符的情况：&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;11&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;12&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;13&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;14&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;15&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;16&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; re&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;remove_tag&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(html)&lt;/span&gt;:&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    text = re.sub(&lt;span class=&quot;string&quot;&gt;&#39;&amp;lt;.*?&amp;gt;&#39;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&#39;&#39;&lt;/span&gt;, html, re.S)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; text&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;source_2 = &lt;span class=&quot;string&quot;&gt;&#39;&#39;&#39;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;lt;div class=&quot;content&quot;&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    今天的主角是&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;lt;a href=&quot;xxx&quot;&amp;gt;kingname&amp;lt;/a&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    ，我们掌声欢迎！&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;lt;/div&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&#39;&#39;&#39;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;text = remove_tag(source_2)&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;print(text)&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;运行效果如下图所示，完全符合预期。&lt;br&gt;&lt;img src=&quot;https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-08-27-22-25-29.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;经过测试，在绝大多数情况下，能够从的HTML代码段中提取出正文。但也有例外。&lt;/p&gt;
    
    </summary>
    
      <category term="Python" scheme="https://www.kingname.info/categories/Python/"/>
    
    
      <category term="Python" scheme="https://www.kingname.info/tags/Python/"/>
    
      <category term="正则表达式" scheme="https://www.kingname.info/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>技巧收集-M1806</title>
    <link href="https://www.kingname.info/2018/06/21/tweet-201806/"/>
    <id>https://www.kingname.info/2018/06/21/tweet-201806/</id>
    <published>2018-06-21T14:36:39.000Z</published>
    <updated>2018-09-25T13:33:27.427Z</updated>
    
    <content type="html"><![CDATA[<h2 id="2018-05"><a href="#2018-05" class="headerlink" title="2018.05"></a>2018.05</h2><p>grep持续监控Log：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">tail <span class="_">-f</span> file | grep --line-buffered my_pattern</div></pre></td></tr></table></figure></p>
<hr>
<p>列表和deque的区别：</p>
<ul>
<li>根据index读list，时间复杂度为O(1)但deque是O(n)</li>
<li>在两头插入数据，deque的时间复杂度为O(1), list为O(n)</li>
<li>deque是一个双向链表，所以操作头尾非常简单。</li>
<li>随机往中间插入数据，deque与list的时间复杂度都是O(n)</li>
</ul>
<a id="more"></a>
<h2 id="2018-04"><a href="#2018-04" class="headerlink" title="2018.04"></a>2018.04</h2><p>MongoDB的聚合查询中，<code>$substr</code>只能匹配ASCII的数据，对于中文要使用<code>$substrCP</code></p>
<hr>
<p>Flask的上下文对象current_app只能在请求线程里存在，因此它的生命周期也是在应用上下文里，离开了应用上下文也就无法使用。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">app = Flask(<span class="string">'__name__'</span>)</div><div class="line">print(current_app.name)</div></pre></td></tr></table></figure></p>
<p>会报错：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">RuntimeError: working outside of application context</div></pre></td></tr></table></figure></p>
<p>此时可以手动创建应用上下文：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">with</span> app.app_context():</div><div class="line">    print(current_app.name)</div></pre></td></tr></table></figure></p>
<hr>
<p>扩展AWS的磁盘空间：</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-06-21-22-31-04.png" alt=""></p>
<p>点击<code>修改卷</code>增加磁盘配额，SSH进入服务器，输入以下代码：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">lsblk  <span class="comment">#这条命令用来确定当前可用的磁盘空间小于磁盘配额</span></div><div class="line">sudo growpart /dev/xvda 1</div><div class="line">sudo resize2fs /dev/xvda1</div></pre></td></tr></table></figure>
<p>再次执行<code>df -h</code>可以看到已经使用了新的空间</p>
<h2 id="2018-03"><a href="#2018-03" class="headerlink" title="2018.03"></a>2018.03</h2><p>在Docker查看正在运行的容器是通过什么命令启动的：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker ps -a --no-trunc</div></pre></td></tr></table></figure></p>
<hr>
<p>在全新的Ubuntu中安装pip：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">sudo apt-get update</div><div class="line">sudo apt-get upgrade</div><div class="line">sudo apt-get install python3-pip</div><div class="line">sudo apt-get install build-essential libssl-dev libffi-dev python3-dev</div></pre></td></tr></table></figure></p>
<hr>
<p>tar压缩文件的时候排除特定文件和文件夹：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">tar --exclude=&apos;./folder&apos; --exclude=&apos;./upload/folder2&apos; -zcvf /backup/filename.tgz .</div></pre></td></tr></table></figure></p>
<h2 id="2018-02"><a href="#2018-02" class="headerlink" title="2018.02"></a>2018.02</h2><p>在MongoDB使用自带的mongodump备份数据的时候，如果数据库设置了密码，那么在指定mongodump的<code>--password 密码</code>参数的同时，还必须指定<code>--authenticationDatabase admin</code></p>
<h2 id="2018-01"><a href="#2018-01" class="headerlink" title="2018.01"></a>2018.01</h2><p>使用grep持续监控Log：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">tail <span class="_">-f</span> file | grep --line-buffered my_pattern</div></pre></td></tr></table></figure></p>
<hr>
<p>使用rsync通过SSH从服务器拉取数据：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">rsync -avzP ubuntu@xx.xxx.xx.xxx:Projects/sample.csv ~/sample.csv</div></pre></td></tr></table></figure></p>
<p>如果有SSH Key的话，使用下面的命令：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">rsync -avzP <span class="_">-e</span> <span class="string">"ssh -i ~/sshkey.pem"</span> ubuntu@xx.xxx.xx.xxx:Projects/sample.csv ~/sample.csv</div></pre></td></tr></table></figure></p>
<hr>
<p>在Ubuntu中修改时区：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo timedatectl <span class="built_in">set</span>-timezone Asia/Shanghai</div></pre></td></tr></table></figure></p>
<hr>
<p>使用XPath获取名称包含特定字符的属性的属性值：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">//span/img/@*[contains(name(), <span class="string">"src"</span>)]</div></pre></td></tr></table></figure></p>
<hr>
<p>AWS在一年免费期间内，换机房不用给钱。先在老的实例生成AMI，再把AMI复制到新的城市，再从新城市的AMI创建实例。然后把老城市的实例彻底终结，取消老城市和新城市的AMI。全程不收费。</p>
<hr>
<p>在Python中执行Shell命令并获取返回结果：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> subprocess</div><div class="line">shell_result = subprocess.check_output(<span class="string">'ps -ef | grep 进程名 | grep -v grep'</span>, shell=<span class="keyword">True</span>).decode().strip().split(<span class="string">'\n)</span></div></pre></td></tr></table></figure></p>
<p>如果命令本身没有返回，则会抛出一个<code>subprocess.CalledProcessError</code></p>
<hr>
<p>在Shell中判断一个进程是否存在：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> ps -ef | grep 进程名 | grep -v grep &gt; /dev/null</div><div class="line"><span class="keyword">then</span></div><div class="line">    <span class="built_in">echo</span> <span class="string">"进程存在"</span></div><div class="line"><span class="keyword">else</span></div><div class="line">    <span class="built_in">echo</span> <span class="string">"进程不存在"</span></div><div class="line"><span class="keyword">fi</span></div></pre></td></tr></table></figure></p>
<h2 id="2017-12"><a href="#2017-12" class="headerlink" title="2017.12"></a>2017.12</h2><p>firewalld对特定IP开放特定端口：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">firewall-cmd --permanent --zone=public --add-rich-rule=&apos;rule family=&quot;ipv4&quot; source address=&quot;特定IP&quot; port protocol=&quot;tcp&quot; port=&quot;特定端口&quot; accept&apos;</div></pre></td></tr></table></figure></p>
<hr>
<p>生成文件树并过滤特定文件或文件夹：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">tree -I <span class="string">'__pycache__|pyc|Logs'</span></div></pre></td></tr></table></figure></p>
<hr>
<p>统计代码行数：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">find . -name <span class="string">"*.py"</span> | xargs wc <span class="_">-l</span></div></pre></td></tr></table></figure></p>
<hr>
<p>为pip设置代理：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pip3.6 --proxy http://代理IP:端口 install -r requirements.txt</div></pre></td></tr></table></figure></p>
<hr>
<p>为Git设置代理：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">RUN git config --global http.proxy http://代理IP:端口</div><div class="line">RUN git config --global http.sslverify <span class="string">"false"</span></div></pre></td></tr></table></figure></p>
<hr>
<p>为Ubuntu的<code>apt-get</code>设置代理：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">vim /etc/apt/apt.conf.d/01turnkey</div></pre></td></tr></table></figure></p>
<p>在里面插入一行：<br><code>Acquire::http::Proxy &quot;http://your.proxy.here:port/&quot;;</code><br>保存以后，下一次执行<code>apt-get</code>命令就会使用代理了。</p>
<h2 id="2017-11"><a href="#2017-11" class="headerlink" title="2017.11"></a>2017.11</h2><p>修改Elasticsearch默认的数据文件地址到/mnt/es文件夹，需要首先创建这个文件夹，然后为elasticsearch这个用户添加这个文件夹的权限:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Chown -R elasticsearch:elasticsearch /mnt/es/</div></pre></td></tr></table></figure></p>
<p>然后再修改elasticsearch的配置文件。</p>
<hr>
<p>在postgres中，占位符是<code>$1</code>, <code>$2</code>而不是MySQL中的<code>？</code></p>
<h2 id="2017-10"><a href="#2017-10" class="headerlink" title="2017.10"></a>2017.10</h2><p>使用<code>urlpare</code>从URL中获取Host：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlparse</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>url = <span class="string">'https://nanjirenlk.tmall.com/shop/view_shop.htm'</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>x = urlparse(url)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>x.netloc</div><div class="line"><span class="string">'nanjirenlk.tmall.com'</span></div></pre></td></tr></table></figure></p>
<hr>
<p>解压<code>tar.gz</code>压缩文件：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">tar zxvf 文件名</div></pre></td></tr></table></figure>
<hr>
<p>根据进程名字在Linux里杀进程。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ps -ef | grep <span class="string">"进程关键字"</span> | grep -v grep | awk <span class="string">'&#123;print $2&#125;'</span> | xargs <span class="built_in">kill</span> -9</div></pre></td></tr></table></figure>
<hr>
<p>在Python 的<code>try ... except Exception ...</code>中显示tracebook:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> traceback</div><div class="line"><span class="keyword">try</span>:</div><div class="line">    <span class="number">1</span> + <span class="string">'a'</span></div><div class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</div><div class="line">    tb = traceback.format_exc()</div><div class="line">    print(tb)</div></pre></td></tr></table></figure>
<p>输出如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">Traceback (most recent call last):</div><div class="line">  File <span class="string">"&lt;stdin&gt;"</span>, line <span class="number">2</span>, <span class="keyword">in</span> &lt;module&gt;</div><div class="line">TypeError: unsupported operand type(s) <span class="keyword">for</span> +: <span class="string">'int'</span> <span class="keyword">and</span> <span class="string">'str'</span></div></pre></td></tr></table></figure>
<p>这个功能在多层<code>try ... except Exception ...</code> 嵌套的时候特别有用。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;2018-05&quot;&gt;&lt;a href=&quot;#2018-05&quot; class=&quot;headerlink&quot; title=&quot;2018.05&quot;&gt;&lt;/a&gt;2018.05&lt;/h2&gt;&lt;p&gt;grep持续监控Log：&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;tail &lt;span class=&quot;_&quot;&gt;-f&lt;/span&gt; file | grep --line-buffered my_pattern&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;列表和deque的区别：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;根据index读list，时间复杂度为O(1)但deque是O(n)&lt;/li&gt;
&lt;li&gt;在两头插入数据，deque的时间复杂度为O(1), list为O(n)&lt;/li&gt;
&lt;li&gt;deque是一个双向链表，所以操作头尾非常简单。&lt;/li&gt;
&lt;li&gt;随机往中间插入数据，deque与list的时间复杂度都是O(n)&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="Craft" scheme="https://www.kingname.info/categories/Craft/"/>
    
    
      <category term="Python" scheme="https://www.kingname.info/tags/Python/"/>
    
      <category term="Linux" scheme="https://www.kingname.info/tags/Linux/"/>
    
      <category term="Craft" scheme="https://www.kingname.info/tags/Craft/"/>
    
      <category term="MongoDB" scheme="https://www.kingname.info/tags/MongoDB/"/>
    
      <category term="Docker" scheme="https://www.kingname.info/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>使用生成器把Kafka写入速度提高1000倍</title>
    <link href="https://www.kingname.info/2018/04/13/the-suitable-situation-for-yield/"/>
    <id>https://www.kingname.info/2018/04/13/the-suitable-situation-for-yield/</id>
    <published>2018-04-13T13:35:09.000Z</published>
    <updated>2018-09-25T13:33:27.419Z</updated>
    
    <content type="html"><![CDATA[<p>通过本文你会知道Python里面什么时候用yield最合适。本文不会给你讲生成器是什么，所以你需要先了解Python的yield，再来看本文。</p>
<a id="more"></a>
<h2 id="疑惑"><a href="#疑惑" class="headerlink" title="疑惑"></a>疑惑</h2><p>多年以前，当我刚刚开始学习Python协程的时候，我看到绝大多数的文章都举了一个生产者-消费者的例子，用来表示在生产者内部可以随时调用消费者，达到和多线程相同的效果。这里凭记忆简单还原一下当年我看到的代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> time</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">consumer</span><span class="params">()</span>:</span></div><div class="line">    product = <span class="keyword">None</span></div><div class="line">    <span class="keyword">while</span> <span class="keyword">True</span>:</div><div class="line">        <span class="keyword">if</span> product <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">            print(<span class="string">'consumer: &#123;&#125;'</span>.format(product))</div><div class="line">        product = <span class="keyword">yield</span> <span class="keyword">None</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">producer</span><span class="params">()</span>:</span></div><div class="line">    c = consumer()</div><div class="line">    next(c)</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</div><div class="line">        c.send(i)</div><div class="line"></div><div class="line">start = time.time()</div><div class="line">producer()</div><div class="line">end = time.time()</div><div class="line">print(f<span class="string">'直到把所有数据塞入Kafka，一共耗时：&#123;end - start&#125;秒'</span>)</div></pre></td></tr></table></figure>
<p>运行效果如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-04-13-23-05-55.png" alt=""></p>
<p>这些文章的说法，就像统一好了口径一样，说这样写可以减少线程切换开销，从而大大提高程序的运行效率。但是当年我始终想不明白，这种写法与直接调用函数有什么区别，如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-04-13-21-51-37.png" alt=""></p>
<p>直到后来我需要操作Kafka的时候，我明白了使用yield的好处。</p>
<h2 id="探索"><a href="#探索" class="headerlink" title="探索"></a>探索</h2><p>为了便于理解，我会把实际场景做一些简化，以方便说明事件的产生发展和解决过程。事件的起因是我需要把一些信息写入到Kafka中，我的代码一开始是这样的：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> time</div><div class="line"><span class="keyword">from</span> pykafka <span class="keyword">import</span> KafkaClient</div><div class="line"></div><div class="line">client = KafkaClient(hosts=<span class="string">"127.0.0.1:9092"</span>)</div><div class="line">topic = client.topics[<span class="string">b'test'</span>]</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">consumer</span><span class="params">(product)</span>:</span></div><div class="line">    <span class="keyword">with</span> topic.get_producer(delivery_reports=<span class="keyword">True</span>) <span class="keyword">as</span> producer:</div><div class="line">        producer.produce(str(product).encode())</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">feed</span><span class="params">()</span>:</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</div><div class="line">        consumer(i)</div><div class="line"></div><div class="line"></div><div class="line">start = time.time()</div><div class="line">feed()</div><div class="line">end = time.time()</div><div class="line">print(f<span class="string">'直到把所有数据塞入Kafka，一共耗时：&#123;end - start&#125;秒'</span>)</div></pre></td></tr></table></figure>
<p>这段代码的运行效果如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/witoutyield1.png" alt=""></p>
<p>写入10条数据需要100秒，这样的龟速显然是有问题的。问题就出在这一句代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">with</span> topic.get_producer(delivery_reports=<span class="keyword">True</span>) <span class="keyword">as</span> producer</div></pre></td></tr></table></figure>
<p>获得Kafka生产者对象是一个非常耗费时间的过程，每获取一次都需要10秒钟才能完成。所以写入10个数据就获取十次生产者对象。这消耗的100秒主要就是在获取生产者对象，而真正写入数据的时间短到可以忽略不计。</p>
<p>由于生产者对象是可以复用的，于是我对代码作了一些修改：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> time</div><div class="line"><span class="keyword">from</span> pykafka <span class="keyword">import</span> KafkaClient</div><div class="line"></div><div class="line">client = KafkaClient(hosts=<span class="string">"127.0.0.1:9092"</span>)</div><div class="line">topic = client.topics[<span class="string">b'test'</span>]</div><div class="line">products = []</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">consumer</span><span class="params">(product_list)</span>:</span></div><div class="line">    <span class="keyword">with</span> topic.get_producer(delivery_reports=<span class="keyword">True</span>) <span class="keyword">as</span> producer:</div><div class="line">        <span class="keyword">for</span> product <span class="keyword">in</span> product_list:</div><div class="line">            producer.produce(str(product).encode())</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">feed</span><span class="params">()</span>:</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</div><div class="line">        products.append(i)</div><div class="line">    consumer(products)</div><div class="line"></div><div class="line"></div><div class="line">start = time.time()</div><div class="line">feed()</div><div class="line">end = time.time()</div><div class="line">print(f<span class="string">'直到把所有数据塞入Kafka，一共耗时：&#123;end - start&#125;秒'</span>)</div></pre></td></tr></table></figure>
<p>首先把所有数据存放在一个列表中，最后再一次性给consumer函数。在一个Kafka生产者对象中展开列表，再把数据一条一条塞入Kafka。这样由于只需要获取一次生产者对象，所以需要耗费的时间大大缩短，如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/witoutyield2.png" alt=""></p>
<p>这种写法在数据量小的时候是没有问题的，但数据量一旦大起来，如果全部先放在一个列表里面的话，服务器内存就爆了。</p>
<p>于是我又修改了代码。每100条数据保存一次，并清空暂存的列表：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> time</div><div class="line"><span class="keyword">from</span> pykafka <span class="keyword">import</span> KafkaClient</div><div class="line"></div><div class="line">client = KafkaClient(hosts=<span class="string">"127.0.0.1:9092"</span>)</div><div class="line">topic = client.topics[<span class="string">b'test'</span>]</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">consumer</span><span class="params">(product_list)</span>:</span></div><div class="line">    <span class="keyword">with</span> topic.get_producer(delivery_reports=<span class="keyword">True</span>) <span class="keyword">as</span> producer:</div><div class="line">        <span class="keyword">for</span> product <span class="keyword">in</span> product_list:</div><div class="line">            producer.produce(str(product).encode())</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">feed</span><span class="params">()</span>:</span></div><div class="line">    products = []</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1003</span>):</div><div class="line">        products.append(i)</div><div class="line">        <span class="keyword">if</span> len(products) &gt;= <span class="number">100</span>:</div><div class="line">            consumer(products)</div><div class="line">            products = []</div><div class="line"></div><div class="line">    <span class="keyword">if</span> products:</div><div class="line">        consumer(products)</div><div class="line"></div><div class="line"></div><div class="line">start = time.time()</div><div class="line">feed()</div><div class="line">end = time.time()</div><div class="line">print(f<span class="string">'直到把所有数据塞入Kafka，一共耗时：&#123;end - start&#125;秒'</span>)</div></pre></td></tr></table></figure>
<p>由于最后一轮循环可能无法凑够100条数据，所以<code>feed</code>函数里面，循环结束以后还需要判断<code>products</code>列表是否为空，如果不为空，还要再消费一次。这样的写法，在上面这段代码中，一共1003条数据，每100条数据获取一次生产者对象，那么需要获取11次生产者对象，耗时至少为110秒。</p>
<p>显然，要解决这个问题，最直接的办法就是减少获取Kafka生产者对象的次数并最大限度复用生产者对象。如果读者举一反三的能力比较强，那么根据开关文件的两种写法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 写法一</span></div><div class="line"><span class="keyword">with</span> open(<span class="string">'test.txt'</span>, <span class="string">'w'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</div><div class="line">    f.write(<span class="string">'xxx'</span>)</div><div class="line">    </div><div class="line"><span class="comment"># 写法二</span></div><div class="line">f = open(<span class="string">'test.txt'</span>, <span class="string">'w'</span>, encoding=<span class="string">'utf-8'</span>)</div><div class="line">f.write(<span class="string">'xxx'</span>)</div><div class="line">f.close()</div></pre></td></tr></table></figure>
<p>可以推测出获取Kafka生产者对象的另一种写法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 写法二</span></div><div class="line">producer = topic.get_producer(delivery_reports=<span class="keyword">True</span>)</div><div class="line">producer.produce(<span class="string">b'xxxx'</span>)</div><div class="line">producer.close()</div></pre></td></tr></table></figure>
<p>这样一来，只要获取一次生产者对象并把它作为全局变量就可以一直使用了。</p>
<p>然而，pykafka的官方文档中使用的是第一种写法，通过上下文管理器<code>with</code>来获得生产者对象。暂且不论第二种方式是否会报错，只从写法上来说，第二种方式必需要手动关闭对象。开发者经常会出现开了忘记关的情况，从而导致很多问题。而且如果中间出现了异常，使用上下文管理器的第一种方式会自动关闭生产者对象，但第二种方式仍然需要开发者手动关闭。</p>
<h2 id="函数VS生成器"><a href="#函数VS生成器" class="headerlink" title="函数VS生成器"></a>函数VS生成器</h2><p>但是如果使用第一种方式，怎么能在一个上下文里面接收生产者传进来的数据呢？这个时候才是yield派上用场的时候。</p>
<p>首先需要明白，使用yield以后，函数就变成了一个生成器。生成器与普通函数的不同之处可以通过下面两段代码来进行说明：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">funciton</span><span class="params">(i)</span>:</span></div><div class="line">    print(<span class="string">'进入'</span>)</div><div class="line">    print(i)</div><div class="line">    print(<span class="string">'结束'</span>)</div><div class="line"></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5</span>):</div><div class="line">    funciton(i)</div></pre></td></tr></table></figure>
<p>运行效果如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-04-13-22-29-40.png" alt=""></p>
<p>函数在被调用的时候，函数会从里面的第一行代码一直运行到某个<code>return</code>或者函数的最后一行才会退出。</p>
<p>而生成器可以从中间开始运行，从中间跳出。例如下面的代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">generator</span><span class="params">()</span>:</span></div><div class="line">    print(<span class="string">'进入'</span>)</div><div class="line">    i = <span class="keyword">None</span></div><div class="line">    <span class="keyword">while</span> <span class="keyword">True</span>:</div><div class="line">        <span class="keyword">if</span> i <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">            print(i)</div><div class="line">        print(<span class="string">'跳出'</span>)</div><div class="line">        i = <span class="keyword">yield</span> <span class="keyword">None</span></div><div class="line"></div><div class="line">g = generator()</div><div class="line">next(g)</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5</span>):</div><div class="line">    g.send(i)</div></pre></td></tr></table></figure>
<p>运行效果如下图所示。<br><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-04-13-23-09-43.png" alt=""></p>
<p>从图中可以看到，<code>进入</code>只打印了一次。代码运行到<code>i = yield None</code>后就跳到外面，外面的数据可以通过<code>g.send(i)</code>的形式传进生成器，生成器内部拿到外面传进来的数据以后继续执行下一轮<code>while</code>循环，打印出被传进来的内容，然后到<code>i = yield None</code>的时候又跳出。如此反复。</p>
<p>所以回到最开始的Kafka问题。如果把<code>with topic.get_producer(delivery_reports=True) as producer</code>写在上面这一段代码的<code>print(&#39;进入&#39;)</code>这个位置上，那岂不是只需要获取一次Kafka生产者对象，然后就可以一直使用了？</p>
<p>根据这个逻辑，设计如下代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> time</div><div class="line"><span class="keyword">from</span> pykafka <span class="keyword">import</span> KafkaClient</div><div class="line"></div><div class="line">client = KafkaClient(hosts=<span class="string">"127.0.0.1:9092"</span>)</div><div class="line">topic = client.topics[<span class="string">b'test'</span>]</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">consumer</span><span class="params">()</span>:</span></div><div class="line">    <span class="keyword">with</span> topic.get_producer(delivery_reports=<span class="keyword">True</span>) <span class="keyword">as</span> producer:</div><div class="line">        print(<span class="string">'init finished..'</span>)</div><div class="line">        next_data = <span class="string">''</span></div><div class="line">        <span class="keyword">while</span> <span class="keyword">True</span>:</div><div class="line">            <span class="keyword">if</span> next_data:</div><div class="line">                producer.produce(str(next_data).encode())</div><div class="line">            next_data = <span class="keyword">yield</span> <span class="keyword">True</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">feed</span><span class="params">()</span>:</span></div><div class="line">    c = consumer()</div><div class="line">    next(c)</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>):</div><div class="line">        c.send(i)</div><div class="line"></div><div class="line">start = time.time()</div><div class="line">feed()</div><div class="line">end = time.time()</div><div class="line">print(f<span class="string">'直到把所有数据塞入Kafka，一共耗时：&#123;end - start&#125;秒'</span>)</div></pre></td></tr></table></figure>
<p>这一次直接插入1000条数据，总共只需要10秒钟，相比于每插入一次都获取一次Kafka生产者对象的方法，效率提高了1000倍。运行效果如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/withyield.png" alt=""></p>
<h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>读者如果仔细对比第一段代码和最后一段代码，就会发现他们本质上是一回事。但是第一段代码，也就是网上很多人讲yield的时候举的生产者-消费者的例子之所以会让人觉得毫无用处，就在于他们的消费者几乎就是秒运行，这样看不出和函数调用的差别。而我最后这一段代码，它的消费者分成两个部分，第一部分是获取Kafka生产者对象，这个过程非常耗时；第二部分是把数据通过Kafka生产者对象插入Kafka，这一部分运行速度极快。在这种情况下，使用生成器把这个消费者代码分开，让耗时长的部分只运行一次，让耗时短的反复运行，这样就能体现出生成器的优势。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;通过本文你会知道Python里面什么时候用yield最合适。本文不会给你讲生成器是什么，所以你需要先了解Python的yield，再来看本文。&lt;/p&gt;
    
    </summary>
    
      <category term="Python" scheme="https://www.kingname.info/categories/Python/"/>
    
    
      <category term="Python" scheme="https://www.kingname.info/tags/Python/"/>
    
      <category term="经验" scheme="https://www.kingname.info/tags/%E7%BB%8F%E9%AA%8C/"/>
    
  </entry>
  
  <entry>
    <title>从Workflowy到印象笔记</title>
    <link href="https://www.kingname.info/2018/03/17/from-workflowy-to-evernote/"/>
    <id>https://www.kingname.info/2018/03/17/from-workflowy-to-evernote/</id>
    <published>2018-03-17T02:05:54.000Z</published>
    <updated>2018-09-25T13:33:27.414Z</updated>
    
    <content type="html"><![CDATA[<p>Workflowy是一个极简风格的大纲写作工具，使用它提供的无限层级缩进和各种快捷键，可以非常方便的理清思路，写出一个好看而实用的大纲。如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-03-17-10-17-58.png" alt=""></p>
<p>印象笔记更是家喻户晓，无人不知的跨平台笔记应用。虽然有很多竞争产品在和印象笔记争抢市场，但是印象笔记强大的搜索功能还是牢牢抓住了不少用户。</p>
<p>如果能够把用Workflowy写大纲的便利性，与印象笔记强大的搜索功能结合起来，那岂不是如虎添翼？如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-03-17-10-21-31.png" alt=""></p>
<p>EverFlowy就是这样一个小工具。它可以自动把Workflowy上面的条目拉下来再同步到印象笔记中。如果Workflowy有更新，再运行一下这个小工具，它就会同步更新印象笔记上面的内容。Workflowy负责写，印象笔记负责存，各尽其能，各得其所。</p>
<a id="more"></a>
<h2 id="工具介绍"><a href="#工具介绍" class="headerlink" title="工具介绍"></a>工具介绍</h2><p>Everflowy基于Python 3开发，代码托管在Github中，地址为：<a href="https://github.com/kingname/EverFlowy" target="_blank" rel="external">https://github.com/kingname/EverFlowy</a>这个小工具在持续开发中，目前可以实现Workflowy单向同步到印象笔记和差异更新。由于印象笔记的Oauth验证方式需要申请才能对正式的账号使用，但它又不会通过这种个人小工具的申请，所以目前暂时使用开发者Token。关于如何申请开通正式账号的开发者Token，在后文会有详细的说明。</p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>首先需要保证电脑中安装了Python 3，否则无法运行这个小工具。代码的依赖关系使用Pipenv来管理，所以需要首先使用pip安装pipenv：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">python3 -m pip install pipenv</div></pre></td></tr></table></figure>
<p>有了Pipenv以后，使用Git把代码拉到本地再安装依赖：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">git <span class="built_in">clone</span> https://github.com/kingname/EverFlowy.git</div><div class="line"><span class="built_in">cd</span> EverFlowy</div><div class="line">pipenv install</div><div class="line">pipenv shell</div></pre></td></tr></table></figure>
<p>运行了上面的4条命令以后，你的终端窗口应该如下图类似。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-03-17-10-43-11.png" alt=""></p>
<p>Pipenv会自动创建一个基于Virtualenv的虚拟环境，然后把EverFlowy依赖的第三方库自动安装到这个虚拟环境中，再自动激活这个虚拟环境。</p>
<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>在代码的根目录，有一个config.json文件，打开以后如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-03-17-10-46-26.png" alt=""></p>
<p>你需要修改三个地方，分别是<code>username</code>，<code>password</code>和<code>dev_token</code>。其中<code>username</code>和<code>password</code>分别对应了Workflowy的用户名和密码，而<code>dev_token</code>是印象笔记的开发者Token。</p>
<p>这里需要说明一下印象笔记的开发者Token。印象笔记的开发者Token有两套，分别是沙盒环境的开发者Token和生产环境的开发者Token。所谓沙盒环境，就是一个测试开发环境，这个环境是专门为了快速开发印象笔记App而设计的，它的地址为：<a href="https://sandbox.evernote.com" target="_blank" rel="external">https://sandbox.evernote.com</a>。打开这个网址，可以看到页面上弹出了警告，如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-03-17-10-56-01.png" alt=""></p>
<p>无论你之前是否有印象笔记的账号，要使用沙盒环境，都必需重新注册。注册完成以后，通过访问<a href="https://sandbox.evernote.com/api/DeveloperToken.action" target="_blank" rel="external">https://sandbox.evernote.com/api/DeveloperToken.action</a>获取沙盒环境的开发者Token。</p>
<p>关于印象笔记的沙盒环境，我将另外开一篇文章来说明。本文主要介绍如何申请生产环境的开发者Token，从而可以使用正式的印象笔记账号。</p>
<p>在2017年6月以后，印象笔记关闭了生产环境开发者Token的申请通道，如果打开申请网址：<a href="https://app.yinxiang.com/api/DeveloperToken.action" target="_blank" rel="external">https://app.yinxiang.com/api/DeveloperToken.action</a>，你会发现申请的按钮是灰色的且无法点击。要解决这个问题，就需要让印象笔记的客服帮忙。</p>
<p>登录自己的印象笔记正式账号，打开印象笔记首页，把页面拉到最下面，可以看到有一个“联系我们”，如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-03-17-11-13-41.png" alt=""></p>
<p>进入“联系我们”，点击“联系客服”，如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-03-17-11-14-06.png" alt=""></p>
<p>在联系客服的页面填写如下信息，最后一项“简要描述问题”填写“我需要基于印象笔记API开发，请帮我开通生产环境开发者Token”并提交。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-03-17-11-17-01.png" alt=""></p>
<p>大约24小时内，就可以受到客服回复的邮件，如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-03-17-11-19-02.png" alt=""></p>
<p>此时再次打开<a href="https://app.yinxiang.com/api/DeveloperToken.action" target="_blank" rel="external">https://app.yinxiang.com/api/DeveloperToken.action</a>就可以申请开发者Token了，如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-03-17-11-20-23.png" alt=""></p>
<p>需要注意的是，开发者Token只会显示一次，所以你需要立刻把它记录下来。</p>
<h2 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h2><p>有了生产环境的开发者Token以后，把它填写到config.json中，配置就算完成了。在终端输入命令：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">python3 EverFlowy.py</div></pre></td></tr></table></figure>
<p>程序就可以开始同步Workflowy的数据到印象笔记了。</p>
<p>同步完成以后，你会发现程序的根目录出现了一个history.db文件。这是一个sqllite的文件，里面就是你在Workflowy中的所有大纲内容和对应的印象笔记GUID和enml格式的内容。这是为了实现数据的差异更新而生成的。你可以使用各种能够浏览sqllite的工具来查看里面的内容。</p>
<h2 id="已知问题"><a href="#已知问题" class="headerlink" title="已知问题"></a>已知问题</h2><ul>
<li>如果删除了history.db，那么再次运行Everflowy，Workflowy中的所有内容都会再次写入印象笔记。</li>
<li>如果单独删除了EverFlowy写入印象笔记中的某一条目，却不删除history.db中的对应条目，WorkFlowy会因为找不到GUID而抛出异常。</li>
<li>没有测试国际版印象笔记账号是否可用。</li>
<li>如过你想测试沙盒环境的开发者账号，请修改<code>evernote_util/EverNoteUtil.py</code>第98行，把</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">client = EvernoteClient(token=self.dev_token, sandbox=<span class="keyword">False</span>, service_host=<span class="string">'app.yinxiang.com'</span>)</div></pre></td></tr></table></figure>
<p>修改为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">client = EvernoteClient(token=self.dev_token)</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Workflowy是一个极简风格的大纲写作工具，使用它提供的无限层级缩进和各种快捷键，可以非常方便的理清思路，写出一个好看而实用的大纲。如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-03-17-10-17-58.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;印象笔记更是家喻户晓，无人不知的跨平台笔记应用。虽然有很多竞争产品在和印象笔记争抢市场，但是印象笔记强大的搜索功能还是牢牢抓住了不少用户。&lt;/p&gt;
&lt;p&gt;如果能够把用Workflowy写大纲的便利性，与印象笔记强大的搜索功能结合起来，那岂不是如虎添翼？如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-03-17-10-21-31.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;EverFlowy就是这样一个小工具。它可以自动把Workflowy上面的条目拉下来再同步到印象笔记中。如果Workflowy有更新，再运行一下这个小工具，它就会同步更新印象笔记上面的内容。Workflowy负责写，印象笔记负责存，各尽其能，各得其所。&lt;/p&gt;
    
    </summary>
    
      <category term="Craft" scheme="https://www.kingname.info/categories/Craft/"/>
    
    
      <category term="Python" scheme="https://www.kingname.info/tags/Python/"/>
    
      <category term="Workflowy" scheme="https://www.kingname.info/tags/Workflowy/"/>
    
      <category term="Evernote" scheme="https://www.kingname.info/tags/Evernote/"/>
    
  </entry>
  
  <entry>
    <title>任务管理，项目管理和目标管理</title>
    <link href="https://www.kingname.info/2018/01/01/task-project-target/"/>
    <id>https://www.kingname.info/2018/01/01/task-project-target/</id>
    <published>2018-01-01T02:11:14.000Z</published>
    <updated>2018-09-25T13:33:27.404Z</updated>
    
    <content type="html"><![CDATA[<p>我是一个工具控，经常尝试各种生产力工具。我发现任务管理App汗牛充栋，项目管理工具乏善可陈，而目标管理App更是少得可怜。</p>
<a id="more"></a>
<h2 id="任务管理App"><a href="#任务管理App" class="headerlink" title="任务管理App"></a>任务管理App</h2><p>任务管理App，包括常见的Things 3，Todoist，Teambition，Trello。其中Things 3和Todoist，本质上就像是一个增强版的提醒工具，你要做什么事情，填上去，设置好Deadline，事情做完了勾掉。如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-01-01-10-22-53.png" alt=""></p>
<p>但这种类型的App有一个缺点——任务只有<code>未做</code>和<code>完成</code>两个状态，没有<code>正在做</code>的状态。</p>
<p>而Teambition与Trello稍微进步一点，引入了看板的概念，于是能够显示任务在各个阶段的状态，如下图所示。这张图是少数派的Trello看板，用来让作者选题。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-01-01-10-26-51.png" alt=""></p>
<p>这种类型的App有一个很大的问题：你做了很多任务，但是你不知道你做这些任务是为了什么。任务管理类App适合用来记录和追踪各种琐碎的任务和相关性不强的任务。就像是少数派的每一篇文章，文章与文章之间不是一个系列的关系，他们各自独立，谁都可以领选题写文章，哪个选题先写哪个选题后写，关系不大。</p>
<p>一旦要规划一个项目，对于规划项目的人和做项目的人，用任务管理类App都会让人觉得使不上劲。对于做任务的人，看到每一个独立的任务，对项目没有整体的概念；对于规划项目的人，不知道任务是不是已经切分得足够细，是否有遗漏。举一个例子，下面是一些任务：</p>
<ul>
<li>找IT申请服务器</li>
<li>配置Dockerfile</li>
<li>配置Docker Swarm</li>
<li>搭建Jenkins</li>
<li>配置Github Hook</li>
<li>选择三个Repo测试</li>
</ul>
<p>现在看到上面的几个任务，你知道我是想做什么吗？我想实现持续集成（CI），实现开发人员把代码一推到Github，系统自动使用Jenkins把代码拉到测试服务器，检查代码风格，做单元测试，做功能测试，自动生成Code Review申请发送给相关人员，Code Review以后自动把代码集成到主干并部署。但是对于做任务的人，却很难根据上面的任务发现要做这个事情。对于规划任务的人，也很难发现是否漏掉了任务，以及是否其中的一个或者多个任务可以继续拆分。</p>
<p>再一个问题，在为每一个任务设定时间的时候，任务一旦多，很难把控每个任务的具体时长。也难以发现哪些任务可以同时做，哪些任务有依赖必需先做这个再做那个，前置任务必需按时完成。即使设置了任务优先级，但是对于同级的任务谁先做谁后做，你却无法把控，只有看App上哪个排前面就先做哪个。</p>
<p>我曾经有一篇文章，就是因为考虑到Teambition的这个问题，所以把Teambition与大纲工具Workflowy结合起来使用。文章地址为：<a href="https://kingname.info/2017/10/03/teamflowy/" target="_blank" rel="external">TeamFlowy——结合Teambition与Workflowy
</a></p>
<h2 id="项目管理"><a href="#项目管理" class="headerlink" title="项目管理"></a>项目管理</h2><p>正是由于任务管理App存在诸多不便，于是在规划一个项目的时候，必需使用一些项目管理的方法或者软件来提高效率。</p>
<p>关于项目管理，我个人最推崇使用甘特图。在我的另一篇文章<a href="https://kingname.info/2017/12/31/you-should-use-gantt/" target="_blank" rel="external">不用甘特图，你做什么项目管理</a>中，我讲到了从一张甘特图里面，你将会额外获得哪些信息。</p>
<p>甘特图是一张二维的图表，它的横轴是时间，纵轴是任务。从甘特图上可以一目了然看到一个任务从什么时候开始什么时候结束，不同任务之间是否有时间重叠，以及哪些任务可以同时做哪些任务必需有先后顺序。</p>
<p>我个人认为，在项目管理中，任务周期是非常重要的，任务的开始时间和结束时间一定要把控好。使用甘特图就可以实现这样一个目的。</p>
<p>对于规划任务的人，在用甘特图规划任务的时候，如果你发现一个任务时间太长，无论怎么调整都会和后面的任务有重叠，那么你就会发现这个任务可能需要拆分为更小的任务。而且由于甘特图立足于项目的整体，你也可以更容易发现是否有任务漏掉了。</p>
<p>对于做任务的人，甘特图也可以帮他们了解到他们所做的任务在整个项目中处于一个什么样的位置，从而让他们知道自己正在做的任务是不是非常重要必需按时完成。</p>
<p>如果你是要开发一个App，或者是要写一本书，或者是要做一个其他什么项目，只要它是由一系列不同的任务构成的，那么你就可以考虑使用甘特图来帮你提高效率。</p>
<h2 id="目标管理"><a href="#目标管理" class="headerlink" title="目标管理"></a>目标管理</h2><p>今天是2018年第一天，不知道有多少人把2017年第一天许下的新年愿望原封不动的搬到了今天。为什么很多人的目标总是不能实现呢？因为他们没有做好目标管理。</p>
<p>关于目标管理，我推崇的是OKR系统。这虽然是一个发源于Intel后被Google发扬光大的企业管理系统，但是对个人依然有用。OKR的意思是<code>Objective and Key Results</code>目标和关键成果。很多人的目标之所以没有实现，是因为他们只设定目标，却不设定成果检查。例如一个人的目标是打算学好英语，但是由于没有设定结果，那么他在设定目标的第二天背了三个单词，在他的潜意识里面就会认为自己已经完成了这个任务，自然后面就会越来越松懈。但如果一个人设定目标为学好英语，再设定几个关键成果，例如：</p>
<ul>
<li>4月1之前，与10个以上美国人聊天</li>
<li>在3月10日节之前，单词书随意翻开一页，这一页的单词至少认识90%</li>
<li>在4月1日前面试三个国外的公司，不为工作就为面着玩</li>
</ul>
<p>这样的目标，就更容易实现了。</p>
<p>使用OKR方法，用纸和笔就可以完成，在设定目标关键结果的时候，一定要使用<code>Smart</code>法则：</p>
<ul>
<li>Specific-具体的</li>
<li>Measurable-可衡量的</li>
<li>Attainable-可实现的</li>
<li>Relevant-相关的</li>
<li>Time-based-有时限的</li>
</ul>
<p>关键结果要足够具体，这样它才是可衡量的。而所谓的可衡量，自然就是可以量化的，可以用数字来定量的检查这个关键结果是否完成，如果没有完全完成，那么完成了多少。如果目标是学好英语，那么关键结果里面肯定不能是“每个月吃一次素菜”。因为这个关键结果和这个目标无关。最后也是非常重要的一点，设定Deadline，防止拖延。</p>
<p>如果你基于OKR系统订好了几个目标和他们的关键结果，然后你100%完成了所有目标。那么恭喜你，你的这个OKR系统是<code>不成功</code>的。100%完成的基于OKR系统的目标对你的帮助不会太大，因为你设定得太简单了。一个完美的<code>OKR</code>系统，应该是在你用尽全力绞尽脑汁的情况下，完成了70%的目标。这样它才会促使你不断挑战自己的极限，不断变得更好。</p>
<p>基于OKR系统的目标，时间也不应该设置太长，以季度为节点检查一次，增加新的目标或者关键结果。最长也需要保证半年至少检查一次，否则很容易出现赶Deadline的情况。</p>
<h2 id="结合"><a href="#结合" class="headerlink" title="结合"></a>结合</h2><p>一个目标，最终会被拆分为一个或者多个项目，每个项目又会被拆分为一个或者多个具体的任务。所以在我自己的实践中，我会把本文讲到的三个东西结合起来。通过OKR系统制定我的目标，使用甘特图来规划我的项目，而使用Todoist来做任务管理。</p>
<p>当我形成了这样一个工作流以后，我发现他们之间可以合作得很好，并不会让人手忙脚乱。我在季度开始的时候制定OKR，然后每周检查一次。在绘制好甘特图以后，我每天也只在下班的时候看一次，更新好项目进度，然后把明天要做的任务添加到Todoist里面。所以我每天使用最多的，更新得最多的还是Todoist。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;我是一个工具控，经常尝试各种生产力工具。我发现任务管理App汗牛充栋，项目管理工具乏善可陈，而目标管理App更是少得可怜。&lt;/p&gt;
    
    </summary>
    
      <category term="经验" scheme="https://www.kingname.info/categories/%E7%BB%8F%E9%AA%8C/"/>
    
    
      <category term="生产力" scheme="https://www.kingname.info/tags/%E7%94%9F%E4%BA%A7%E5%8A%9B/"/>
    
      <category term="效率" scheme="https://www.kingname.info/tags/%E6%95%88%E7%8E%87/"/>
    
  </entry>
  
  <entry>
    <title>不用甘特图，你做什么项目管理</title>
    <link href="https://www.kingname.info/2017/12/31/you-should-use-gantt/"/>
    <id>https://www.kingname.info/2017/12/31/you-should-use-gantt/</id>
    <published>2017-12-31T14:45:55.000Z</published>
    <updated>2018-09-25T13:33:27.450Z</updated>
    
    <content type="html"><![CDATA[<p>我非常喜欢使用甘特图来做项目管理。不用甘特图的公司，我觉得很奇怪。<br><a id="more"></a></p>
<h2 id="什么是甘特图"><a href="#什么是甘特图" class="headerlink" title="什么是甘特图"></a>什么是甘特图</h2><p>什么是甘特图呢？下面这张图就是甘特图。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2017-12-31-22-53-21.png" alt=""></p>
<p>这张图是我12月离职做交接时候的甘特图。</p>
<ul>
<li>不同的颜色表示不同的人</li>
<li>每一行表示一个任务</li>
<li>红色竖线表示今天应该完成的任务</li>
<li>任务与任务之间的黑色箭头表示任务之间的依赖关系，必需完成前面的才能完成后面的</li>
<li>带中心黑线的任务表示已经完成的任务</li>
</ul>
<p>通过这一张甘特图，我能一眼看出以下信息：</p>
<ol>
<li>今天谁应该做什么任务</li>
<li>这个任务从什么时候开始，到什么时候结束</li>
<li>一个人在一段时间有哪些任务</li>
<li>应该先做哪些任务再做哪些任务</li>
<li>哪些任务可以同时做</li>
<li>这个任务是否被其他任务依赖，如果是，那么这个任务就不能推迟，必需按时完成或者提前完成，否则会影响后面的任务</li>
<li>每个任务已经完成多少还剩多少</li>
<li>大任务下面有哪些子任务</li>
<li>任务的里程碑是什么时候</li>
</ol>
<h2 id="为什么要用甘特图"><a href="#为什么要用甘特图" class="headerlink" title="为什么要用甘特图"></a>为什么要用甘特图</h2><p>因为为了绘制出甘特图，你必需强迫自己完成以下几件事情：</p>
<ol>
<li>确定每一个任务的开始时间和结束时间</li>
<li>确定任务的依赖关系</li>
<li>分离可以同时运行的任务</li>
<li>确定不同人的任务间的时间关系</li>
</ol>
<p>当你根据以上的规则绘制好第一版甘特图以后，你会发现有些地方是可以继续调整的，但是这种调整，在你没有画图之前是不能发现的。于是你会在调整甘特图的过程中，让项目的规划越来越清晰。</p>
<h2 id="怎么做甘特图"><a href="#怎么做甘特图" class="headerlink" title="怎么做甘特图"></a>怎么做甘特图</h2><p>你可以在纸上做甘特图，也可以用Excel来做。下面这张图是来自网络。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2017-12-31-23-20-03.png" alt=""></p>
<p>这是使用Excel做出来的效果，但是做起来稍显麻烦。</p>
<p>Omniplan和MS Project都是非常专业的甘特图制作软件，但是价格非常高。毕竟这是生产力软件，使用这个软件你是可以赚大钱的，自然软件本身就会比较贵。</p>
<p>开源的甘特图软件也有不少，不过不是功能不全就是界面丑陋。这里介绍一个相对比较完整的甘特图制作软件：GanttProject</p>
<p>GanttProject的官方网站为<a href="http://www.ganttproject.biz/" target="_blank" rel="external">http://www.ganttproject.biz/</a>，在这里你可以下载到macOS，Windows或者Linux版本的软件。</p>
<p>GanttProject运行以后的界面如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2017-12-31-23-47-11.png" alt=""></p>
<p>在左侧任务面板右键或者按下键盘<code>Command</code> + <code>T</code>就可以添加任务，Windows和Linux对应的快捷键为<code>Ctrl</code> + <code>T</code>。如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2017-12-31-23-48-11.png" alt=""></p>
<p>创建好了一个任务，它默认的开始时间和结束时间都是今天。在任务上面右键，选择<code>任务属性</code>，可以打开任务属性设置界面，在这里可以设置任务的开始时间和任务时长。但是你不能设置任务结束时间。因为任务结束时间会根据开始时间和任务时长自动计算。如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-01-01-00-03-16.png" alt=""></p>
<p>在这个界面，还可以设置任务的颜色，实现不同人不同颜色，或者不同项目不同颜色。也可以在这里更新任务进度。</p>
<p>创建多个任务，如果后面的任务依赖前面的任务，那么在右侧被依赖的任务色条上单击鼠标左键，按住并拖动到依赖它的任务上。依赖它的任务的起始时间自动就会变为被依赖任务的结束时间，如下图所示。此时，后一个任务只能设置任务的时长，不能修改任务的起始时间。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-01-01-00-08-17.png" alt=""></p>
<p>如果依赖关系设置错误，打开依赖任务的任务属性，定位到<code>前置任务</code>选项卡，在这里可以删除被依赖的任务或者修改被依赖任务。如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-01-01-00-11-10.png" alt=""></p>
<p>如果你需要移动任务的顺序，鼠标单击选中它，按下键盘上的<code>Alt</code> + <code>方向键上或下</code>即可移动任务。</p>
<p>我认为甘特图有一个非常重要的元素，就是竖直红线，它指向了今天的任务。要打开这跟红线，需要单击菜单栏的<code>编辑</code>-<code>设置</code>，定位到<code>甘特图设定</code>，在<code>将今天显示为红色</code>点选为<code>是</code>，如下图所示。<br><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-01-01-00-20-55.png" alt=""><br>单击确定回到甘特图的界面，可以看到图中出现了一条红色竖线。这条竖线指向了今天应该做的事情。如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-01-01-00-23-06.png" alt=""></p>
<p>每天打开甘特图，这根红线都会指向当天。</p>
<p>GanttProject可以把做好的甘特图导出为图片，CSV，HTML或者PDF文件。单击<code>项目</code>-<code>导出</code>，点选<code>Raster图像文件</code>，并单击<code>下一步</code>，如下图所示。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/2018-01-01-00-24-34.png" alt=""></p>
<p>设置保存路径和甘特图的日期范围即可导出为PNG文件，以方便分享。</p>
<p>GanttProject还有更多功能，你可以安装以后慢慢研究。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;我非常喜欢使用甘特图来做项目管理。不用甘特图的公司，我觉得很奇怪。&lt;br&gt;
    
    </summary>
    
      <category term="经验" scheme="https://www.kingname.info/categories/%E7%BB%8F%E9%AA%8C/"/>
    
    
      <category term="经验" scheme="https://www.kingname.info/tags/%E7%BB%8F%E9%AA%8C/"/>
    
      <category term="甘特图" scheme="https://www.kingname.info/tags/%E7%94%98%E7%89%B9%E5%9B%BE/"/>
    
  </entry>
  
</feed>
